\documentclass{article}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb,graphicx,enumerate,bbm,hyperref,xcolor,latexsym,theorem,tabularx}

%%%%%%%%%% Start TeXmacs macros
\catcode`\<=\active \def<{
\fontencoding{T1}\selectfont\symbol{60}\fontencoding{\encodingdefault}}
\catcode`\>=\active \def>{
\fontencoding{T1}\selectfont\symbol{62}\fontencoding{\encodingdefault}}
\newcommand{\TeXmacs}{T\kern-.1667em\lower.5ex\hbox{E}\kern-.125emX\kern-.1em\lower.5ex\hbox{\textsc{m\kern-.05ema\kern-.125emc\kern-.05ems}}}
\newcommand{\coloneq}{:=}
\newcommand{\eqqcolon}{=:}
\newcommand{\cdot}{\cdot}
\newcommand{\citetexmacs}[1]{This document has been written using GNU {\TeXmacs} \cite{#1}.}
\newcommand{\comma}{{,}}
\newcommand{\mathrm{d}}{\mathrm{d}}
\newcommand{\nin}{\not\in}
\newcommand{\nobracket}{}
\newcommand{\nosymbol}{}
\newcommand{\textdots}{...}
\newcommand{\tmcolor}[2]{{\color{#1}{#2}}}
\newcommand{\tmdummy}{$\mbox{}$}
\newcommand{\emph}[1]{{\em #1\/}}
\newcommand{\tmfolded}[2]{\trivlist{\item[$\bullet$]\mbox{}#1}}
\newcommand{\tmfoldedplain}[2]{\trivlist{\item[]\mbox{}#1}}
\newcommand{\tminput}[2]{\trivlist{\item[\color{rgb:black,10;red,9;green,4;yellow,2}{#1}]{\color{blue!50!black}\mbox{}#2}}}
\newcommand{\tmnote}[1]{\thanks{\textit{Note:} #1}}
\newcommand{\tmop}[1]{\ensuremath{\operatorname{#1}}}
\newcommand{\tmoutput}[1]{#1}
\newcommand{\tmscript}[1]{\text{\scriptsize{$#1$}}}
\newcommand{\tmsession}[3]{{\tt#3}}
\newcommand{\tmstrong}[1]{\textbf{#1}}
\newcommand{\textbf}[1]{\text{{\bfseries{#1}}}}
\newcommand{\tmtextit}[1]{\text{{\itshape{#1}}}}
\newcommand{\tmunfoldedio}[3]{\trivlist{\item[\color{rgb:black,10;red,9;green,4;yellow,2}{#1}]\mbox{}{\color{blue!50!black}#2}\item[]\mbox{}#3}}
\newcommand{\tmunfoldedplain}[2]{\trivlist{\item[]\mbox{}#1\\\item[]\mbox{}#2}}
\newenvironment{enumerate}{\begin{enumerate}[a{\textup{)}}] }{\end{enumerate}}
\newenvironment{enumeratenumeric}{\begin{enumerate}[1.] }{\end{enumerate}}
\newenvironment{enumerate}{\begin{enumerate}[i.] }{\end{enumerate}}
\newenvironment{itemize}{\begin{itemize} \renewcommand{\labelitemi}{$\bullet$}\renewcommand{\labelitemii}{$\bullet$}\renewcommand{\labelitemiii}{$\bullet$}\renewcommand{\labelitemiv}{$\bullet$}}{\end{itemize}}
\newenvironment{itemizeminus}{\begin{itemize} \renewcommand{\labelitemi}{$-$}\renewcommand{\labelitemii}{$-$}\renewcommand{\labelitemiii}{$-$}\renewcommand{\labelitemiv}{$-$}}{\end{itemize}}
\newenvironment{proof}{\noindent\textbf{Proof\ }}{\hspace*{\fill}$\Box$\medskip}
\newenvironment{proof*}[1]{\noindent\textbf{#1\ }}{\hspace*{\fill}$\Box$\medskip}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
{\theorembodyfont{\rmfamily}\newtheorem{example}{Example}}
\newcounter{nnexample}
\def\thennexample{\unskip}
{\theorembodyfont{\rmfamily}\newtheorem{example*}[nnexample]{Example}}
\newcounter{nnexercise}
\def\thennexercise{\unskip}
{\theorembodyfont{\rmfamily\small}\newtheorem{exercise*}[nnexercise]{Exercise}}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
{\theorembodyfont{\rmfamily}\newtheorem{remark}{Remark}}
\newtheorem{theorem}{Theorem}
%%%%%%%%%% End TeXmacs macros

\newcommand{\CI}{I}
\newcommand{\CC}{C}
\newcommand{\CD}{D}
\newcommand{\CA}{A}
\newcommand{\CB}{B}
\newcommand{\CS}{S}
\newcommand{\CF}{F}
\newcommand{\DD}{D}
\newcommand{\LL}{L}
\newcommand{\CX}{X}
\newcommand{\CM}{M}
\newcommand{\CN}{N}
\newcommand{\CP}{P}
\newcommand{\CT}{T}
\newcommand{\CQ}{Q}
\newcommand{\CR}{R}
\newcommand{\CK}{K}
\newcommand{\fs}{s}
\newcommand{\bone}{\ensuremath{\1}}
\newcommand{\1}{\1}
\newcommand{\indep}{\mathrel{}}
\newcommand{\renderexercise}[2]{{\paddednormal{0.5fn}{0.5fn}{{\exercisename{#1{\exercisesep}}}#2}}}

\begin{document}

\

\title{
  Stochastics III: Stochastic Analysis
  \tmnote{{\citetexmacs{TeXmacs:website}}}
}

\author{Lucio Galeati}

\date{January 14, 2025}

\maketitle

\footnote{These lecture notes are based on the ones given by Prof. Nicolas
Perkowski in the WS 2022-23 and I'm very thankful to him for sharing them with
me. If you spot any typo, please email me ( lgaleati@zedat.fu-berlin.de );
thanks to all who send comments.}

{\tableofcontents}

\section*{Introduction and motivation}

Stochastic analysis is the analysis of continuous time stochastic processes.

In Stochastics~II, you already encountered discrete time processes as models
for random phenomena that evolve in discrete time steps. Such processes can be
constructed mathematically (Kolmogorov's criterion) and you have likely
already seen some of the most important classes of processes (martingales,
Markov chains), as well as some of the most fundamental results on their
behavior (martingale convergence, martingale inequalities, fundamental theorem
of Markov chains, Donsker's invariance principle, etc.).

But of course it is also be interesting to study continuous time phenomena,
which do not evolve in clearly separated time steps. This is more complex: in
discrete time, one time is following after the next one, and to describe
stochastic processes we only have to understand how they transition from one
step to the next. In continuous time there is no ``next step'', we can go from
$t$ to $t + 1$, but also to $t + \frac{1}{2}$ or $t + \frac{\pi}{100}$.
Therefore, we will need many new mathematical tools to describe and analyze
continuous time stochastic processes.

As a motivation, let us look at some examples where continuous time stochastic
processes arise:

\begin{example*}[Stock price]
  The pictures of stock price trajectories typically look very irregular,
  bouncing up and down constantly. As toy model for the evolution of a stock
  price, we can consider a Brownian motion (which already appeared in
  Stochastik~II). Brownian motion is a continuous time stochastic
  process $(B_t)_{t \geqslant 0}$ with continuous trajectories, such that $B_t
  \sim \mathcal{N} (0, t)$ for all $t \geqslant 0$, where $\mathcal{N} (0, t)$
  denotes the normal distribution with mean $0$ and variance $t$, and such
  that $B_{t + s} - B_t$ is independent of $(B_r)_{0 \leqslant r \leqslant
  t}$.
  
  The intuition behind this model is that there are many small traders, who
  all independently of each other try to buy or sell the stock. Each time a
  small trader buys, the stock price moves up a bit. Each time they sell, it
  moves down a bit. The fact that the increments are normally distributed thus
  follows from the central limit theorem. Moreover, if we assume that the
  decisions of each trader is independent of all previous decisions by all the
  other traders, then we get the independence of $B_{t + s} - B_t$ and
  $(B_r)_{0 \leqslant r \leqslant t}$.
  
  We will see later in the lecture how to construct the Brownian motion and
  that the description above characterizes it uniquely. And we will study some
  of its path properties to see that it indeed behaves quite wildly and it
  resembles the familiar pictures of stock price trajectories.
  
  \begin{figure}[h]
    \resizebox{0.7\columnwidth}{!}{\includegraphics{StochAna-ongoing-1.pdf}}
    \caption{\label{fig:bm}A typical realization of a Brownian motion.}
  \end{figure}
  
  For example, the Brownian motion has no isolated zeros, meaning that if $B_t
  = 0$ for some $t$, then in any small interval $[t - \varepsilon, t +
  \varepsilon]$ there are infinitely many $s$ with $B_s = 0$. We will also see
  that $B$ is nowhere differentiable and behaves roughly speaking like
  \[ |B_{t + \mathrm{d} t} - B_t | \simeq \sqrt{\mathrm{d} t} . \]
  Of course, this is not a mathematical statement and part of the work will be
  to find a suitable mathematical statement that we can actually prove.
\end{example*}

\tmcolor{blue}{\begin{exercise*}
  Throughout the text there will be small exercises like this one, marked in
  blue. You should think about the exercises and try to solve them before the
  next lecture. Some of them will be elementary and only require you to
  revisit the definitions and make sure that you understood everything. Some
  others might be a bit more involved and might need some inspiration. It is
  no problem if you cannot solve an exercise, but you should always at least
  try.
  
  Look at the $y$-axis of Figure~\ref{fig:bm}. Do these numbers make you think
  of a stock price? If not, can you think of a simple transformation that we
  could do in order to obtain a more reasonable candidate for the price
  process?
\end{exercise*}}

\begin{example*}[Stochastic differential equations from Donker's invariance
principle]
  The following difference equation is a prototypical example of a random
  discrete time evolution:
  \begin{equation}
    \label{eq:difference-eq} X_{n + 1} = X_n + b (X_n) + \sigma (X_n) Y_n,
  \end{equation}
  where $Y_n$ is random influence, ``noise''. More concretely, one could
  consider for example a (stochastic) Malthusian population growth model,
  where $X_n$ is the size of a population and
  \[ X_{n + 1} = X_n + b X_n + X_n Y_n, \]
  where $b \in \mathbb{R}$ is the deterministic growth rate and $(Y_n)_{n \in
  \mathbb{N}}$ is a centered family of independent and identically distributed
  (i.i.d.) random variables that models randomly occurring deviations from the
  deterministic growth rate.
  
  If we assume that the $(Y_n)_{n \in \mathbb{N}}$ are a centered family of
  i.i.d. random variables with finite variance, then Donsker's invariance
  principle (which you might have seen in Stochastik~ II) asserts that $S_n =
  \sum_{k = 1}^n Y_k$ can be rescaled so that it converges to a Brownian
  motion. $S$ is evolving in discrete time steps, but under the rescaling for
  Donsker's theorem the transition times between the steps become infinitely
  small, and in the limit one finds a continuous time variable.
  
  It then seems reasonable to expect (and under suitable assumptions it can be
  proven) that $X$ can be rescaled in such a way that it converges to a
  process $(Z_t)_{t \geqslant 0}$ satisfying for $t \geqslant 0$ and $h > 0$
  \[ Z_{t + h} = Z_t + b (Z_t) h + \sigma (Z_t) (B_{t + h} - B_t), \]
  where $B$ is a Brownian motion. Bringing $Z_t$ to the left hand side,
  dividing by $h$ and letting $h \rightarrow 0$, we formally obtain
  \[ \partial_t Z_t = b (Z_t) + \sigma (Z_t) \partial_t B_t . \]
  But $B$ is not differentiable in time, so it is not clear how to interpret
  this equation! To make sense of such ``stochastic differential equations'',
  and to this end first of ``stochastic integrals'', will be one of the main
  goals of the lecture.
\end{example*}

\begin{example*}[Noise to model unresolved influences]
  Another situation where stochastic differential equations appear is the
  following: applied scientists often model time-evolving systems by ordinary
  differential equations (ODEs)
  \[ \dot{X}_t = b (X_t) . \]
  However, in reality the modelled system might not be isolated from its
  environment. To model influences of the environment, we have two choices:
  \begin{enumerate}
    \item We increase the dimension of our system by attempting to also model
    the environment; however this ultimately leads to an infinite-dimensional
    system, and often is unfeasible because nature is just too complex.
    
    \item We try to find a ``random'' model for the influence of the
    environment. Under suitable assumptions we should be able to invoke the
    central limit theorem, so that these random influences should be centered
    Gaussians.
  \end{enumerate}
  In the second scenario, in many situations it is also reasonable to assume
  that the random influences are stationary in time, and independent for
  different times. So formally we end up with the equation
  \[ \dot{X}_t = b (X_t) + \xi_t, \]
  where $(\xi_t)_{t \geqslant 0}$ is an i.i.d. family of centered Gaussian
  variables. It turns out that this equation does not make sense, because it
  is not possible to construct ``a version'' of $\xi$ that has measurable
  trajectories and thus it is not clear how to interpret the equation. The
  solution to this problem is to formally assume that $\xi_t$ has infinite
  variance for fixed times. We will see how to make this rigorous and how to
  model an ODE forced by ``white noise'' (which turns out to be, intuitively,
  the ``time derivative'' of Brownian motion).
\end{example*}

\begin{example*}[A toy model for Earth's climate]
  A more concrete version of this example is a particle in a double well
  potential: Consider $b (x) = - U' (x)$ for $U (x) = \frac{1}{4} x^4 -
  \frac{1}{2} x^2$. One can easily verify that there are three fixed points
  for the dynamics $\dot{X}_t = - U' (X_t)$ (imagine a ball rolling down the
  potential $U$, except damping at the bottom): two stable fixed points $\{-
  1, 1\}$ and one unstable fixed point $\{0\}$.
  
  \begin{figure}[h]
    \scalebox{0.3}{\includegraphics{StochAna-ongoing-2.pdf}}
    \caption{Double well potential $U$.}
  \end{figure}
  
  So if we start in $x < 0$ the solution will converge to $- 1$ for $t
  \rightarrow \infty$, and if we start in $x > 0$ it will converge to $1$.
  
  The ODE $\dot{X}_t = - U' (X_t)$ could serve as a qualitative toy model for
  the earth's climate: Assume $- 1$ represents an ice age and $+ 1$ a warm
  period. These two states are quite stable for the climate, after all we are
  not constantly switching between ice ages and warm periods. But from time to
  time there are transitions, and in the ODE model we never see them. But if
  we add a very small random forcing of white noise type, as described above,
  then the forcing can ``kick'' (rarely) the solution over the hill into the
  domain of attraction of the other stable fixed point. It might then be
  interesting to calculate how long this will typically take.
\end{example*}

\begin{example*}[Stochastic gradient descent, we didn't cover it in the
lectures]
  In many applied problems, e.g. statistical estimation or training of
  artificial neural networks in machine learning, we are interested in finding
  the minimum of a function of the form
  \[ F (x) = \frac{1}{n} \sum_{i = 1}^n f_i (x), \]
  where typically $n$ is very large. A gradient descent would solve
  the ODE
  \[ \dot{X}_t = - \nabla F (X_t) \]
  and for $t \rightarrow \infty$ the solution would converge to a local
  minimum of $F$ (note that $\partial_t F (X_t) = - | \nabla F (X_t) |^2 < 0$;
  compare also with the double well example from above). We can implement a
  gradient descent on the computer with a simple Euler scheme:
  \[ X_{k + 1} = X_k - \eta \nabla F (X_k) = X_k - \eta \frac{1}{n} \sum_{i =
     1}^n \nabla f_i (X_k), \]
  where $\eta > 0$ is a small parameter, called the learning rate. However, in
  practice one usually uses the following \tmtextit{stochastic gradient
  descent} instead: At each step pick $i \in \{ 1, \ldots, n \}$ uniformly at
  random and set
  \[ X_{k + 1} = X_k - \eta \nabla f_i (X_k) . \]
  This has two advantages: if $n$ is large, the stochastic gradient descent is
  much cheaper to compute. And by introducing randomness into the algorithm it
  is no longer a pure descent and transitions to $X_{k + 1}$ with $F (X_{k +
  1}) > F (X_k)$ are possible. This means that we may exit the domain of
  attraction of a local minimum, and by carefully tuning the algorithm we
  might hope to converge to a global minimum. Sometimes it is argued that the
  stochastic gradient descent is similar to
  \[ X_{k + 1} = X_k - \eta \nabla F (X_k) + \text{``noise''}, \]
  which by similar arguments as above is a discretization of the differential
  equation
  \[ \partial_t X_t = - \nabla F (X_t) + \partial_t B_t . \]
  So if we understand the behavior of this SDE for $t \rightarrow \infty$,
  then we may learn something about stochastic gradient descents.
\end{example*}

\begin{example*}[Brownian motion and PDEs]
  If $B$ is a Brownian motion, then for $t > 0$ the random variable $B_t$ has
  the density
  \[ p (t, x) = \frac{1}{\sqrt{2 \pi t}} \exp \left( - \frac{x^2}{2 t} \right)
     . \]
  It is a simple exercise to verify that $p$ solves the \tmtextit{heat
  equation}:
  \[ \partial_t p (t, x) = \frac{1}{2} \partial^2_{xx} p (t, x) \]
  for all $t > 0$ and $x \in \mathbb{R}$. As a consequence, we get for any
  ``nice'' $\varphi$ (i.e. nice enough so that the following manipulations are
  admissible) that the function
  \[ u (t, x) \coloneq \mathbb{E} [\varphi (x + B_t)] \]
  solves
  
  \begin{align*}
    \partial_t u (t, x) & = \partial_t \left( \int_{\mathbb{R}} \varphi (x +
    y) p (t, y) d y \right) = \int_{\mathbb{R}} \varphi (x + y)  \frac{1}{2}
    \partial^2_{yy} p (t, y) d y\\
    & = \int_{\mathbb{R}} \frac{1}{2} \partial^2_{yy} \varphi (x + y) p (t,
    y) d y = \int_{\mathbb{R}} \frac{1}{2} \partial^2_{xx} \varphi (x + y) p
    (t, y) d y = \frac{1}{2} \partial^2_{xx} u (t, x),
  \end{align*}
  
  where we applied integration by parts to shift $\partial^2_{yy}$ from $p$ to
  $\varphi$. Moreover, $u$ obviously has the initial condition $u (0, x) =
  \varphi (x)$, so that we found a solution to the equation
  \[ \partial_t u = \partial^2_{xx} u, \qquad u (0) = \varphi . \]
  This suggests a link between stochastic processes and partial differential
  equations (PDEs), and in fact this link is quite deep and powerful. For
  example, if for $x \in \mathbb{R}$ the process $X^x$ solves the stochastic
  differential equation
  \[ \partial_t X^x_t = b (X^x_t) + \sigma (X^x_t) \partial_t B_t, \qquad X_0
     = x, \]
  then $u (t, x) =\mathbb{E} [\varphi (X^x_t)]$ solves the (one-dimensional)
  PDE
  \[ \partial_t u (t, x) = b (x) \partial_x u (t, x) + \frac{1}{2} \sigma^2
     (x) \partial^2_{xx} u (t, x), \qquad u (0) = \varphi, \]
  and conversely the PDE can be used to characterize the law of $X^x$.
\end{example*}

\begin{example*}[Diffusion Monte Carlo]
  In many applications we have to sample from a measure
  \[ \mu (\mathrm{d} x) = \frac{1}{Z} \exp (- V (x)) \mathrm{d} x \]
  on $\mathbb{R}^d$, where $V : \mathbb{R}^d \rightarrow \mathbb{R}$ is a
  differentiable function with $\int_{\mathbb{R}^d} \exp (- V (x)) \mathrm{d} x <
  \infty$ and $Z = \int_{\mathbb{R}^d} \exp (- V (x)) \mathrm{d} x$ is chosen so
  that $\mu$ is a probability measure. This is a very difficult problem,
  especially if $d$ is large or $V$ is complicated. One way of obtaining
  approximate samples from $\mu$ is to find a stochastic process with
  invariant measure $\mu$. The most famous such process is the {\emph{Langevin
  diffusion}}, which solves the stochastic differential equation
  \[ \partial_t X_t = - \nabla V (X_t) + \sqrt{2} \partial_t B_t . \]
\end{example*}

Hopefully these examples show that there are many interesting questions to be
asked and problems to be studied. We will now start to develop the basic tools
and methods of stochastic analysis.

\subsection*{Literature}

Large parts of the lecture are inspired by or directly taken from Le Gall's
beautiful notes {\cite{LeGall2016}}. There is much more material in Le Gall's
notes than we can cover in the lecture and they are a useful resource for
further details. Further good references are the lecture notes by Jacod
{\cite{Jacod2008}}, the classic monographs
{\cite{Karatzas1988,Revuz1999,Oksendal2003,Jacod2003,Ethier1986}}, or the
great ``almost sure'' blog
\href{https://almostsure.wordpress.com/}{https://almostsure.wordpress.com/}.
The monograph {\cite{Morters2010}} is nearly entirely devoted to the Brownian
motion, and it provides a much more detailed picture of its fascinating path
properties than we can obtain in the lecture. In the beginning of the notes we
repeat some material from Stochastics I \& II, and good additional references
are {\cite{Klenke2008,Durrett2010,Stroock2011}} and some chapters of
{\cite{Ethier1986}}.

\subsection*{Notation and conventions}

\begin{itemize}
  \item Unless explicitly mentioned otherwise, we always assume that $(\Omega,
  \mathcal{F}, \mathbb{P})$ is a given probability space.
  
  \item $\mathbb{N}= \{1, 2, \ldots\}$, $\mathbb{N}_0 =\mathbb{N} \cup \{0\}$,
  $\mathbb{R}_+ = [0, \infty)$, $\mathbb{Q}_+ =\mathbb{R}_+ \cap \mathbb{Q}$.
  
  \item $x \cdot y = \sum_{j = 1}^d x_j y_j$, $A^T$ is the transpose of the
  matrix $A$.
  
  \item $x^+ = \max \{ x, 0 \}$ and $x^- = \max \{ - x, 0 \}$.
  
  \item $\lim_{s \downarrow t} f (s) = \lim_{\tmscript{\begin{array}{c}
    \varepsilon \rightarrow 0^+
  \end{array}}} f (t + \varepsilon)$ and $\lim_{s \uparrow t} f (s) =
  \lim_{\tmscript{\begin{array}{c}
    \varepsilon \rightarrow 0^+
  \end{array}}} f (t - \varepsilon)$.
  
  \item $X_{s, t} \coloneq X_t - X_s$.
  
  \item The indicator function of a set $A$ is denoted by $\1_A$.
  
  \item $\mathcal{B} (S)$ is the Borel $\sigma$-algebra of the topological
  space $S$. $2^{\Omega}$ are the subsets of $\Omega$.
  
  \item If we do not specify it, we always assume an underlying probability
  space $(\Omega, \mathcal{F}, \mathbb{P})$ as given.
  
  \item $a \lesssim b$ means there exists some $C > 0$, independent of the
  relevant variables under consideration, such that $a \leqslant Cb$. For
  example, $(x + y)^2 \leqslant 2 (y^2 + y^2)$, so we would write $(x + y)^2
  \lesssim x^2 + y^2$.
\end{itemize}

\section{Gaussian processes, pre-Brownian motion and white noise}

Some background with probability theory from a measure theoretic perspective
will be assumed throughout the course; ideally all you need are things learned
from Stochastik~I and~II. For convenience, some material is recalled in
Appendices~\ref{app:gaussian} and~\ref{app:dynkin}; this material will not be
examinable, but it will be at the basis of many of the results we will
develop, so please have a proper look at it to understand if you are already
familiar enough with it.

\subsection{Gaussian processes}

The star of this lecture is the Brownian motion, which is a particular
{\emph{Gaussian process}}. Recall that for $d \in \mathbb{N}$ a random
variable $X$ with values in $\mathbb{R}^d$ is called {\emph{(centered)
Gaussian}} or {\emph{(centered) normal}} if for any $u \in \mathbb{R}^d$ the
linear combination
\[ u \cdot X = \sum_{j = 1}^d u_j X_j \]
of the entries of $X$ has a one-dimensional (centered) Gaussian distribution.
We also call $(X_1, \ldots, X_d)$ {\emph{jointly Gaussian}}.

Equivalently, there exist $m \in \mathbb{R}^d$ and a symmetric positive
semi-definite matrix $C \in \mathbb{R}^{d \times d}$ such that $X$ has the
characteristic function
\[ \mathbb{E} [e^{iu \cdot X}] = e^{iu \cdot m - (u^T Cu) / 2}, \qquad u \in
   \mathbb{R}^d . \]
Moreover,
\[ \mathbb{E} [u \cdot X] = u \cdot m, \qquad \operatorname{var} (u \cdot X) =
   u^T Cu. \]
We write $X \sim \mathcal{N} (m, C)$.

\begin{definition}
  Let $\mathbb{T} \neq \varnothing$ be an index set. A real-valued stochastic
  process $X = (X_t)_{t \in \mathbb{T}}$ is called a {\emph{(centered)
  Gaussian process}} if for every finite subset $I \subset \mathbb{T}$ and for
  all $(\alpha_t)_{t \in I} \in \mathbb{R}^I$ the random variable $\sum_{t \in
  I} \alpha_t X_t$ is a real-valued (centered) Gaussian random variable.
\end{definition}

\tmcolor{blue}{\begin{exercise*}
  Show that $X = (X_1, \ldots, X_d)$ is a $d$-dimensional Gaussian random
  variable if and only if $(X_t)_{t \in \mathbb{T}}$ with $\mathbb{T}= \{ 1,
  \ldots, d \}$ is a $d$-dimensional Gaussian process indexed by $\mathbb{T}$.
\end{exercise*}}

Equivalently, $X$ is (centered) Gaussian if for any finite $I \subset
\mathbb{T}$ the vector $(X_t)_{t \in I}$ is an $|I|$-dimensional Gaussian
random variable. There exist two functions $m : \mathbb{T} \rightarrow
\mathbb{R}$ and $\Gamma : \mathbb{T} \times \mathbb{T} \rightarrow \mathbb{R}$
such that $\mathbb{E} [X_t] = m (t)$ for all $t \in \mathbb{T}$ and
$\operatorname{cov} (X_s, X_t) = \Gamma (s, t)$ for all $s, t \in \mathbb{T}$.
Moreover, the finite-dimensional distributions (and thus the law) of $X$ are
uniquely determined by $m$ and $\Gamma$, and $\Gamma$ is symmetric
(i.e. $\Gamma (s, t) = \Gamma (t, s)$ for all $s, t \in \mathbb{T}$) and
positive semi-definite}, i.e. for any finite $I \subset \mathbb{T$
and any $ (\alpha_t)_{t \in I} \in \mathbb{R}^I$ we have
\[ \sum_{(s, t) \in I \times I} \alpha_s \alpha_t \Gamma (s, t) = \operatorname{var}
   \left( \sum_{t \in I} \alpha_t X_t \right) \geqslant 0. \]
We say that $X$ has \textit{mean $m$} and \textit{covariance $\Gamma$}.

We can construct Gaussian random variables on $\mathbb{R}^d$ with a given mean
$m$ and covariance $C$ by transforming a ``standard'' $d$-dimensional random
variable $Y \sim \mathcal{N} (0, \mathbb{I})$ via $X = m + \sqrt{C} Y$. It is
not clear how to adapt this construction to infinite $\mathbb{T}$, so given
$m$ and $\Gamma$ we need more sophisticated tools to construct a Gaussian
process with mean $m$ and covariance $\Gamma$. We achieve this with
Kolmogorov's extension theorem:

\begin{proposition}
  Let $\mathbb{T} \neq \varnothing$ be an index set, let $m : \mathbb{T}
  \rightarrow \mathbb{R}$, and let $\Gamma : \mathbb{T} \times \mathbb{T} \to
  \mathbb{R}$ be a symmetric and positive semi-definite function. Then there
  exists a Gaussian process $X$ with mean $m$ and covariance $\Gamma$, and the
  law of $X$ is uniquely determined by $m$ and $\Gamma$.
\end{proposition}

\begin{proof}[Skipped in class, because of possible overlap with
Stochastics~II]
  This follows from Kolmogorov's extension theorem. For any finite subset $I
  \subset \mathbb{T}$ let $\mathbb{P}_I$ be the law of a $\mathcal{N} ((m
  (t))_{t \in I}, (\Gamma (s, t))_{s, t \in I})$ random variable. For $J
  \supset I$ let $\pi_{J I} : \mathbb{R}^J \rightarrow \mathbb{R}^I$ be the
  projection $\pi_{J I} ((x_t)_{t \in J}) = (x_t)_{t \in I}$. The existence of
  $X$ follows from Kolmogorov's extension criterion once we show the
  consistency condition $\mathbb{P}_J \circ \pi_{J I}^{- 1} =\mathbb{P}_I$.
  For $u \in \mathbb{R}^I$ we have
  
  \begin{align*}
    \int_{\mathbb{R}^I} e^{i u \cdot x} \mathbb{P}_J \circ \pi_{J I}^{- 1}
    (\mathrm{d} x) & = \int_{\mathbb{R}^J} e^{i \sum_{t \in I} u (t) x (t)}
    \mathbb{P}_J (\mathrm{d} x) = e^{i \sum_{t \in I} u (t) m (t) - \frac{1}{2}
    \sum_{s, t \in I} u (s) \Gamma (s, t) u (t)}\\
    & = \int_{\mathbb{R}^I} e^{i \sum_{t \in I} u (t) x (t)} \mathbb{P}_I
    (\mathrm{d} x) .
  \end{align*}
  
  So $\mathbb{P}_J \circ \pi_{J I}^{- 1}$ and $\mathbb{P}_I$ have the same
  characteristic function, and thus the two measures agree and the proof is
  complete.
\end{proof}

\

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on October 16}
  \hrulefill\hrulefill
\end{center}

\

\begin{example}[Pre-Brownian motion]
  Let $\mathbb{T}=\mathbb{R}_+ = [0, \infty)$, $m (t) = 0$ and $\Gamma (s, t)
  = s \wedge t \coloneq \min \{ s, t \}$. Then $\Gamma$ is obviously symmetric.
  It is also positive semi-definite: For $n \in \mathbb{N}$ and $t_1, \ldots,
  t_n \geqslant 0$ and $\alpha_1, \ldots, \alpha_n \in \mathbb{R}$ we have
  \[ \sum_{i, j = 1}^n \alpha_i \alpha_j \Gamma (t_i, t_j) = \sum_{i, j = 1}^n
     \alpha_i \alpha_j \int_0^{\infty} \1_{[0, t_i]} (s)
     \1_{[0, t_j]} (s) \mathrm{d} s = \int_0^{\infty} \left( \sum_{i =
     1}^n \alpha_i \1_{[0, t_i]} (s) \right)^2 \mathrm{d} s \geqslant 0.
  \]
  The Gaussian process $B$ with mean $m$ and covariance $\Gamma$ is called a
  pre-Brownian motion.
\end{example}

Later, we will \ define a Brownian motion as a pre-Brownian motion with
continuous trajectories.

\tmfoldedplain{\begin{lemma}[Alternative characterization of the pre-Brownian
motion]
  \label{lem:pre-Brownian}Let $(B_t)_{t \geqslant 0}$ be a real-valued
  stochastic process. Then $B$ is a pre-Brownian motion if and only if the
  following conditions are satisfied:
  \begin{enumerate}
    \item $B_0 = 0$ almost surely;
    
    \item for all $0 \leqslant s < t$ the random variable $B_t - B_s$ is
    independent of the variables $(B_r)_{0 \leqslant r \leqslant s}$;
    
    \item for all $0 \leqslant s < t$ we have $B_t - B_s \sim \mathcal{N} (0,
    t - s)$.
  \end{enumerate}
\end{lemma}}{\ }

\tmcolor{blue}{\begin{exercise*}
  Prove the above lemma.
\end{exercise*}}

\begin{example}[pre-Fractional Brownian motion, or pre-fBm for short]
  Let $H \in (0, 1)$, let $\mathbb{T}=\mathbb{R}_+$ and $m (t) = 0$ and
  \[ \Gamma^H (s, t) = \frac{1}{2} (t^{2 H} + s^{2 H} - | t - s |^{2 H}) . \]
  $\Gamma$ is obviously symmetric, but it is not so easy to see that it is
  positive semi-definite. One way of showing it is similar to our argument for
  pre-Brownian motion: one can show that
  \[ \Gamma^H (s, t) = \int_{\mathbb{R}} \Phi (s, r) \Phi (t, r) \mathrm{d} r \]
  for
  \[ \Phi (s, r) \coloneq \frac{1}{\gamma (H + 1 / 2)} ((s - r)_+^{H - 1 / 2} -
     (- r)_+^{H - 1 / 2}), \]
  where $\gamma$ is the Gamma function and (just for this time) we set $x_+
  \coloneq x^+ = \max \{ x, 0 \}$. Therefore
  \[ \sum_{i, j = 1}^n \alpha_i \alpha_j \Gamma^H (t_i, t_j) = \sum_{i, j =
     1}^n \alpha_i \alpha_j \int_{\mathbb{R}} \Phi (t_i, r) \Phi (t_j, r)
     \mathrm{d} r = \int_{\mathbb{R}} \left( \sum_{i = 1}^n \alpha_i \Phi (t_i, r)
     \right)^2 \mathrm{d} r \geqslant 0. \]
  The Gaussian process $B^H$ with mean $m \equiv 0$ and covariance $\Gamma^H$
  is called the fractional pre-Brownian motion with \tmtextit{Hurst
  index} $H$. In other words, pre-fBm of parameter $H \in (0, 1)$ is
  characterized by being a Gaussian process $(B^H_t)_{t \geqslant 0}$ with
  \[ \mathbb{E} [B^H_t] = 0, \qquad \mathbb{E} [B^H_t B^H_s] = \frac{1}{2}
     (t^{2 H} + s^{2 H} - | t - s |^{2 H}) . \]
\end{example}

\tmcolor{blue}{\begin{exercise*}
  Show that for $H = 1 / 2$ the process $B^H$ is a pre-Brownian motion.
\end{exercise*}}

One can show that $B^H$ becomes more and more irregular if we decrease $H$.

\begin{figure}[h]
  \resizebox{0.5\columnwidth}{!}{\includegraphics{StochAna-ongoing-3.pdf}}\resizebox{.5\columnwidth}{!}{\includegraphics{StochAna-ongoing-4.pdf}}
  \caption{Fractional Brownian motion with Hurst index $H = 0.2$ and $H =
  0.8$, respectively.}
\end{figure}

\begin{example}[pre-Brownian bridge]
  Let $\mathbb{T}= [0, 1]$ and $m (t) = 0$ and $\Gamma (s, t) = s \wedge t - s
  t$. This $\Gamma$ is symmetric and in the exercise below you show that it is
  positive semi-definite. The centered Gaussian process with covariance
  function $\Gamma$ is called the (pre-){\emph{Brownian bridge}}, and it looks
  like a Brownian motion on $[0, 1]$, except that at time $1$ it ends up in
  $0$ instead of being ``free'' like the end-point of the Brownian motion on
  $[0, 1]$. To understand this, we plot 20 samples of the Brownian motion and
  20 samples of the Brownian bridge and compare the results.
\end{example}

\tmcolor{blue}{\begin{exercise*}
  Let $(B_t)_{t \geqslant 0}$ be a pre-Brownian motion and let $X_t = B_t - t
  B_1$, $t \in [0, 1]$. Show that $X$ is a pre-Brownian bridge. In particular,
  $\Gamma$ is positive semi-definite because it is the covariance function of
  $X$.
\end{exercise*}}

20 Samples of Brownian motion:

\tmsession{python}{default}{
  \tmoutput{Python 3.7.4 [/opt/anaconda3/bin/python3]
  
  Python plugin for TeXmacs.
  
  Please see the documentation in Help -> Plugins -> Python}
  \tmunfoldedio{>>> }{import numpy as np
  
  import matplotlib.pyplot as plt
  
  \
  
  T, h = 1, 1e-3
  
  n = int(T/h)
  
  k = 20
  
  \
  
  time = np.arange(0,T+h,h)
  
  dB = np.sqrt(h)*(np.random.randn(k,n))
  
  BM = np.zeros((k,n+1))
  
  BM[:,1:] = np.cumsum(dB, axis=1)
  
  \
  
  plt.clf()
  
  \ \ \
  
  for i in range(k):
  
  \ \ \ plt.plot(time,BM[i,:])
  
  \
  
  pdf\_out(plt.gcf())}{\raisebox{-6.08522644886627e-4\height}{\includegraphics[width=9.20064279155188cm,height=6.89838318247409cm]{StochAna-ongoing-5.pdf}}}
  Next, we plot 20 samples of the Brownian bridge:
  \tmunfoldedio{>>> }{BB = np.zeros((k,n+1))
  
  BB[:,1:] = np.cumsum(dB, axis=1) - np.outer(BM[:,n], time[1:])
  
  \
  
  plt.clf()
  
  \ \ \
  
  for i in range(k):
  
  \ \ \ plt.plot(time,BB[i,:])
  
  \
  
  pdf\_out(plt.gcf())}{\raisebox{-6.08522644886627e-4\height}{\includegraphics[width=9.20064279155188cm,height=6.89838318247409cm]{StochAna-ongoing-6.pdf}}}
  \tminput{>>> }{\ }
}

\subsection{White noise and Brownian motion}

\begin{example}[Naive white noise]
  In the introduction we discussed examples where we want to add noise to
  ordinary differential equations (ODEs). Intuitively, the most natural noise
  seems to be an i.i.d. family of standard normal variables $(\xi_t)_{t \in
  \mathbb{R}_+}$, i.e. $\xi$ is a centered Gaussian process with covariance
  $\Gamma (s, t) =\1_{s = t}$. This would mean that the noise is
  stationary (it has the same distribution at each time) and what happens at
  time $t$ is independent of what happens at any other time $s \neq t$. We
  call this process a {\emph{naive white noise}}. To understand where the name
  ``white noise'' comes from, note that if we plot i.i.d. random variables in
  the plane rather than on $\mathbb{R}_+$, then the image resembles the static
  ``white noise'' that you might remember from old analog televisions; see the
  next figure.
  
  \begin{figure}[h]
    \scalebox{0.7}{\includegraphics{StochAna-ongoing-7.pdf}}
    \caption{2d naive white noise}
  \end{figure}
  
  Of course, then the question is why static noise should be called white
  noise. We will discuss this on Sheet~1.
\end{example}

We introduced the naive white noise because we want to consider ODEs perturbed
by noise, say
\[ \dot{X}_t = b (X_t) + \xi_t, \qquad X_0 = x_0, \]
which in integral form reads as
\[ X_t = x_0 + \int_0^t b (X_s) \mathrm{d} s + \int_0^t \xi_s \mathrm{d} s. \]
Unfortunately, if $\xi$ is a naive white noise, the map $(\omega, s) \mapsto
\xi_s (\omega)$ cannot be jointly measurable and thus the formal expression
$\int_0^t \xi_s \mathrm{d} s$ might be problematic:

\begin{lemma}
  Let $(\xi_t)_{t \geqslant 0}$ be a naive white noise and let $t > 0$. Then
  the map
  \[ \Omega \times [0, t] \ni (\omega, s) \mapsto \xi_s (\omega) \in
     \mathbb{R} \]
  is {\underline{not}} measurable with respect to the product $\sigma$-algebra
  $\mathcal{F} \otimes \mathcal{B} ([0, t])$, and in particular $\omega
  \mapsto \int_0^t \xi_s (\omega) \mathrm{d} s$ might not be defined or even if it
  is defined it might not be a random variable.
\end{lemma}

\begin{proof}
  Assume to the contrary that $\xi |_{\Omega \times [0, t]}$ is measurable
  with respect to $\mathcal{F} \otimes \mathcal{B} ([0, t])$. Then also
  \[ \Omega \times [0, t] \times [0, t] \ni (\omega, s_1, s_2) \mapsto
     \xi_{s_1} (\omega) \xi_{s_2} (\omega) \in \mathbb{R} \]
  is measurable with respect to $\mathcal{F} \otimes \mathcal{B} ([0, t])
  \otimes \mathcal{B} ([0, t])$, and for each $r \in [0, t]$:
  \[ \int_0^r \int_0^r \mathbb{E} [| \xi_{s_1} \xi_{s_2} |] \mathrm{d} s_1 \mathrm{d}
     s_2 < \infty, \]
  as $\mathbb{E} [| \xi_{s_1} \xi_{s_2} |] \leqslant 1$ by the Cauchy-Schwarz
  inequality. Thus, the Fubini-Tonelli theorem shows that for all $r \in [0,
  t]$
  
  \begin{align*}
    \mathbb{E} \left[ \left( \int_0^r \xi_s \mathrm{d} s \right)^2 \right] &
    =\mathbb{E} \left[ \int_0^r \xi_{s_1} \mathrm{d} s_1 \int_0^r \xi_{s_2} \mathrm{d}
    s_2 \right]\\
    & =\mathbb{E} \left[ \int_0^r \int_0^r \xi_{s_1} \xi_{s_2} \mathrm{d} s_1
    \mathrm{d} s_2 \right]\\
    & = \int_0^r \int_0^r \mathbb{E} [\xi_{s_1} \xi_{s_2}] \mathrm{d} s_1 \mathrm{d}
    s_2\\
    & = \int_0^r \int_0^r \1_{s_1 = s_2} \mathrm{d} s_1 \mathrm{d} s_2 = 0.
  \end{align*}
  
  Therefore, $\int_0^r \xi_s \mathrm{d} s = 0$ almost surely, and since the
  countable union of null sets is a null set we deduce that almost surely
  $\int_0^r \xi_s \mathrm{d} s = 0$ for all $r \in [0, t] \cap \mathbb{Q}$.
  
  On the other hand, again by Fubini-Tonelli
  
  \begin{align*}
    \mathbb{E} \left[ \int_0^t | \xi_s | \mathrm{d} s \right] & = \int_0^t
    \mathbb{E} [| \xi_s |] \mathrm{d} s = \sqrt{\frac{2}{\pi}} t < \infty,
  \end{align*}
  
  where we used the fact that $\mathbb{E} [| \xi_s |] = \sqrt{2 / \pi}$ since
  $\xi_s \sim \mathcal{N} (0, 1)$ (and we don't need to know this precise
  formula but only that $\mathbb{E} [| X |] \in (0, \infty)$ for a standard
  normal distribution $X$). Therefore a.s. $s \mapsto \xi_s (\omega)$ is
  Lebesgue integrable on $[0, t]$ and by the dominated convergence theorem the
  map $r \mapsto \int_0^r \xi_s (\omega) \mathrm{d} s$ is continuous on $[0, t]$.
  
  Combined with the above, this implies that almost surely $\int_0^r \xi_s
  \mathrm{d} s = 0$ for all $r \in [0, t]$. But then a.s. $\xi_s = 0$ for
  Lebesgue-almost all $s \in [0, t]$, thus $\mathbb{E} \left[ \int_0^t | \xi_s
  | \mathrm{d} s \right] = 0$; but this is absurd because we just saw that
  $\mathbb{E} \left[ \int_0^t | \xi_s | \mathrm{d} s \right] = t \sqrt{2 / \pi}$.
  Therefore, the assumption must have been incorrect.
\end{proof}

\tmcolor{blue}{\begin{exercise*}
  Justify the last step of the proof: Show that if $f \in L^1 ([0, t])$ is
  such that $\int_0^r f (s) \mathrm{d} s = 0$ for all $r \in [0, t]$, then $f (s)
  = 0$ for Lebesgue-almost all $s \in [0, t]$.
  
  \tmtextit{Hint: Recall Dynkin's $\pi - \lambda$ theorem, cf.
  Theorem~\ref{thm:dynkin} in Appendix~\ref{app:dynkin}.}
\end{exercise*}}

The way out of this dilemma is to formally assume that $(\xi_t)_{t \geqslant
0}$ is an i.i.d. family of $\mathcal{N} (0, \infty)$ variables rather than
$\mathcal{N} (0, 1)$ variables, i.e. that $\mathbb{E} [\xi_t^2] = \infty$. Of
course, this makes no sense. But let us abandon mathematical rigor for a
moment and argue as physicists. Then we can consider the physicist's Dirac
delta function $\delta : \mathbb{R} \rightarrow \{ 0, \infty \}$, which
satisfies
\[ \delta (x) = \left\{\begin{array}{ll}
     \infty, & x = 0,\\
     0, & x \neq 0,
   \end{array}\right. \qquad \text{and} \qquad \int_{\mathbb{R}} f (x) \delta
   (x) \mathrm{d} x = f (0), \]
and we assume that $(\xi_t)_{t \geqslant 0}$ is a centered Gaussian process
with covariance function
\[ \mathbb{E} [\xi_s \xi_t] = \delta (t - s) . \]
This still does not make any sense, but if we assume that we can integrate
$\int_0^{\infty} \xi_t f (t) \mathrm{d} t$ for $f \in L^2 (\mathbb{R}_+)$, then we
obtain formally

\begin{align*}
  \mathbb{E} \left[ \int_0^{\infty} \xi_t f (t) \mathrm{d} t \int_0^{\infty} \xi_s
  g (s) \mathrm{d} s \right] & = \int_0^{\infty} \int_0^{\infty} \mathbb{E} [\xi_t
  \xi_s] f (t) g (s) \mathrm{d} s \mathrm{d} t\\
  & = \int_0^{\infty} \int_0^{\infty} \delta (t - s) f (t) g (s) \mathrm{d} s
  \mathrm{d} t\\
  & = \int_0^{\infty} \left( \int_{- \infty}^t \delta (s) f (t - s) \mathrm{d} s
  \right) g (t) \mathrm{d} t\\
  & = \int_0^{\infty} f (t) g (t) \mathrm{d} t.
\end{align*}

These were only formal manipulations. But now we can take this formal identity
and take it as the definition of a (non-naive) white noise. We interpret
\[ \xi (f) = \int_0^{\infty} \xi_t f (t) \mathrm{d} t, \]
where the right hand side is formal notation assuming that $\xi$ has a
density, and the left hand side is the ``action of $\xi$ on $f$''. This is
conceptually similar to formally writing
\[ \int_0^{\infty} f (t) \mu (t) \mathrm{d} t \coloneq \mu (f) \coloneq
   \int_0^{\infty} f (t) \mu (\mathrm{d} t) \]
for a measure $\mu$ on $\mathcal{B} (\mathbb{R}_+)$, even if $\mu$ does not
have a density with respect to Lebesgue measure. Note however that the white
noise is not a measure, so even this interpretation is dubious. Instead we
abandon the connection with densities and measures, and we define the white
noise rigorously as follows:

\begin{definition}[White noise]
  Let $\mathbb{T}= L^2 (\mathbb{R}_+)$ and
  \[ \Gamma (f, g) = \int_0^{\infty} f (t) g (t) \mathrm{d} t = \langle f, g
     \rangle_{L^2 (\mathbb{R}_+)} . \]
  Then $\Gamma$ is symmetric and positive semi-definite, and the centered
  Gaussian process $(\xi (f))_{f \in L^2 (\mathbb{R}_+)}$ with covariance
  $\Gamma$ is called {\emph{white noise}}.
\end{definition}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Show that $\Gamma$ is indeed positive semi-definite.
\end{exercise*}}}{\ }

\begin{definition}
  Let $(X, d_X)$ and $(Y, d_Y)$ be metric spaces. A map $T : X \rightarrow Y$
  is called an {\emph{isometry}} if $d_Y (T (x), T (x')) = d_X (x, x')$ for
  all $x, x' \in X$.
\end{definition}

\begin{lemma}
  If $(\xi (f))_{f \in L^2 (\mathbb{R}_+)}$ is a white noise, then
  \[ L^2 (\mathbb{R}_+) \ni f \mapsto \xi (f) \in L^2 (\Omega) \]
  is a linear isometry.
\end{lemma}

\begin{proof}
  Let us write $\langle \cdot, \cdot \rangle = \langle \cdot, \cdot
  \rangle_{L^2 (\mathbb{R}_+)}$. We have for $f, g, h \in L^2 (\mathbb{R}_+)$
  and $\alpha, \beta \in \mathbb{R}$
  \[ \mathbb{E} [(\alpha \xi (f) + \beta \xi (g) - \xi (\alpha f + \beta g))
     \xi (h)] = \alpha \langle f, h \rangle + \beta \langle g, h \rangle -
     \langle \alpha f + \beta g, h \rangle = 0, \]
  so in particular
  \[ \mathbb{E} [(\alpha \xi (f) + \beta \xi (g) - \xi (\alpha f + \beta
     g))^2] = 0, \]
  i.e. $\alpha \xi (f) + \beta \xi (g) = \xi (\alpha f + \beta g)$ and $\xi$
  is linear. Since $\| \xi (f) \|_{L^2 (\Omega)}^2 =\mathbb{E} [\xi (f)^2] =
  \|f\|^2_{L^2 (\mathbb{R}_+)}$, $\xi$ is an isometry.
\end{proof}

To recap: Our motivation for introducing the naive white noise was that it
seems to be natural noise to add to an ODE. But we saw that for a naive white
noise $\xi$ we cannot make sense of the ODE
\[ X_t = x_0 + \int_0^t b (X_s) \mathrm{d} s + \int_0^t \xi_s \mathrm{d} s, \]
because the integral on the right hand side is not defined or not a random
variable. But now we can take a white noise and use formal notation to write
\[ \int_0^t \xi_s \mathrm{d} s = \int_0^{\infty} \1_{[0, t]} (s) \xi_s \mathrm{d} s =
   \xi \left( \1_{[0, t]} \right), \]
and since $\1_{[0, t]} \in L^2 (\mathbb{R}_+)$ the right hand side is
perfectly well defined.

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Let $\xi$ be a white noise and define $B_t = \xi (\1_{[0, t]})$,
  for $t \geqslant 0$. Show that $B$ is a pre-Brownian motion.
\end{exercise*}}}{\ }

\

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on October 17}
  \hrulefill\hrulefill
\end{center}

\

Above we performed the construction of white noise for $(\xi (f))_{f \in H}$
where $H = L^2 (\mathbb{R}_+)$ us a Hilbert space. More generally, given
any Hilbert space $H$, one can construct a centered Gaussian
process $(X (h))_{h \in H}$ with $\mathbb{E} [X (f) X (g)] = \langle f, g
\rangle_H$, and also in that case $h \mapsto X (h)$ is a linear isometry; see
Exercise Sheet~1 for such a construction. In this case, $\xi$ is called a
{\emph{white noise on $H$}}.

\

Recap: having now interpreted $\int_0^t \xi_s \mathrm{d} s$ as $\xi
(\1_{[0, t]}) \eqqcolon B_t$ and having established that the latter
is a pre-Brownian motion, we finally end up with the stochastic differential
equation (SDE)
\[ X_t = x_0 + \int_0^t b (X_s) \mathrm{d} s + B_t . \]
This is still problematic because of bad path properties of the pre-Brownian
motion (the map $t \mapsto B_t (\omega)$ might not be measurable), but now we
just have to turn the pre-Brownian motion into an actual Brownian motion with
continuous trajectories and then we can solve the SDE. We will do this later
in the course, for now we discuss the relation between white noise and
Brownian motion further.

The previous exercise shows that formally the (pre-)Brownian motion is the
integral of the white noise. Conversely, we formally have $\xi_t = \partial_t
B_t$, i.e. white noise is the derivative of the (pre-)Brownian motion:

\begin{lemma}[Wiener integral]
  \label{lem:wiener-int}Let $(B_t)_{t \geqslant 0}$ be a pre-Brownian motion
  and let
  \[ \mathcal{E}= \left\{ f \in L^2 (\mathbb{R}_+) : f (t) = \sum_{k = 0}^{n -
     1} x_k \1_{(t_k, t_{k + 1}]} (t), n \in \mathbb{N}, x_0, \ldots, x_{n -
     1} \in \mathbb{R}, 0 \leqslant t_0 < t_1 < \cdots < t_n \right\} . \]
  For such $f$ we define
  \[ \xi (f) \coloneq \int_0^{\infty} f (s) \mathrm{d} B_s \coloneq \sum_{k = 0}^{n
     - 1} x_k (B_{t_{k + 1}} - B_{t_k}) . \]
  This definition does not depend on the specific representation of $f$, and
  we have
  \[ \| \xi (f) \|_{L^2 (\Omega)}^2 =\mathbb{E} [\xi (f)^2] = \| f \|_{L^2
     (\mathbb{R}_+)}^2 . \]
  Therefore, $\xi$ has a unique continuous extension to $L^2 (\mathbb{R}_+)$,
  also denoted by $\xi$, and we also write
  \[ \int_0^{\infty} f (s) \mathrm{d} B_s \coloneq \xi (f) . \]
  The process $(\xi (f))_{f \in L^2 (\mathbb{R}_+)}$ is a white noise.
\end{lemma}

The integral $\int_0^{\infty} f (s) \mathrm{d} B_s$ is called {\emph{Wiener
integral}} and it is a precursor of the {\emph{It{\^o} integral}}, which we
will construct later in the course and allows random integrands, not just
deterministic $f$ like the Wiener integral.

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Why is $\int_0^{\infty} f (s) \mathrm{d} B_s \coloneq \sum_{k = 0}^{n - 1} x_k
  (B_{t_{k + 1}} - B_{t_k})$ a sensible definition?
\end{exercise*}}}{\ }

\begin{proof}
  We leave it as an exercise to check that the definition of $\xi (f)$ does
  not depend on the representation of $f$, i.e. that if $\sum_{k = 0}^{n - 1}
  x_k \1_{(t_k, t_{k + 1}]} = \sum_{\ell = 0}^{m - 1} y_{\ell} \1_{(s_k, s_{k
  + 1}]}$, then
  \[ \sum_{k = 0}^{n - 1} x_k (B_{t_{k + 1}} - B_{t_k}) = \sum_{\ell = 0}^{m -
     1} y_{\ell} (B_{t_{\ell + 1}} - B_{t_{\ell}}) . \]
  It is clear from the definition that the map $\mathcal{E} \ni f \mapsto \xi
  (f)$ is linear; let us show the isometry property. We have
  \begin{eqnarray*}
    \| \xi (f) \|_{L^2 (\Omega)}^2 & = & \mathbb{E} \left[ \left( \sum_{k =
    0}^{n - 1} x_k (B_{t_{k + 1}} - B_{t_k}) \right)^2 \right]\\
    & = & \sum_{k, \ell = 0}^{n - 1} x_k x_{\ell} \mathbb{E} [(B_{t_{k + 1}}
    - B_{t_k}) (B_{t_{\ell + 1}} - B_{t_{\ell}})] .
  \end{eqnarray*}
  If (say) $k < \ell$, then $B_{t_{\ell + 1}} - B_{t_{\ell}}$ is independent
  of $B_{t_{k + 1}} - B_{t_k}$ and the expectation vanishes. Therefore, we
  remain with the diagonal terms and obtain
  \[ \| \xi (f) \|_{L^2 (\Omega)}^2 = \sum_{k = 0}^{n - 1} x_k^2 \mathbb{E}
     [(B_{t_{k + 1}} - B_{t_k})^2] = \sum_{k = 0}^{n - 1} x_k^2 (t_{k + 1} -
     t_k) = \int_0^{\infty} | f (t) |^2 \mathrm{d} t = \| f \|_{L^2
     (\mathbb{R}_+)}^2 . \]
  Therefore,
  \[ \xi : (\mathcal{E}, \| \cdot \|_{L^2 (\mathbb{R}_+)}) \rightarrow (L^2
     (\Omega), \| \cdot \|_{L^2 (\Omega)}) \]
  is a linear isometry, and in particular it is uniformly continuous. As
  $\mathcal{E}$ is dense in $L^2 (\mathbb{R}_+)$, the map $\xi$ has a unique
  continuous extension to all of $L^2 (\mathbb{R}_+)$, which is still a linear
  isometry and which we still denote by $\xi$. It remains to show that $\xi$
  is a white noise.
  
  By centered Gaussianity of $B$, the process $(\xi (f))_{f \in \mathcal{E}}$
  is centered Gaussian, and by a limiting argument (cf.
  Lemma~\ref{lem:limit.gaussians} in Appendix~\ref{app:gaussian}) also $(\xi
  (f))_{f \in L^2 (\mathbb{R}_+)}$ is centered Gaussian. By polarization we
  have
  \[ \mathbb{E} [\xi (f) \xi (g)] = \langle f, g \rangle_{L^2 (\mathbb{R}_+)},
     \qquad f, g \in L^2 (\mathbb{R}_+), \]
  and thus $\xi$ is a white noise.
  
  \
  
  {\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
    \textbf{Polarization:} Let $X$ be an $\mathbb{R}$-vector space and let
    $[\cdot, \cdot]_1, [\cdot, \cdot]_2 : X \times X \rightarrow
    \mathbb{R}$ be two symmetric bilinear forms such that $[x, x]_1 = [x,
    x]_2$ for all $x \in X$. Then $[x, y]_1 = [x, y]_2$ for all $x, y \in X$:
    \begin{eqnarray*}
      {}[x, y]_1 & = & \frac{1}{4} ([x + y, x + y]_1 - [x - y, x - y]_1)\\
      & = & \frac{1}{4} ([x + y, x + y]_2 - [x - y, x - y]_2)\\
      & = & [x, y]_2 .
    \end{eqnarray*}
  \end{tabularx}
\end{proof}

With formal notation we have
\[ \int_0^{\infty} f (s) \mathrm{d} B_s = \int_0^{\infty} f (s) \partial_s B_s
   \mathrm{d} s, \qquad \xi (f) = \int_0^{\infty} f (s) \xi_s \mathrm{d} s, \]
and since $\xi (f) = \int_0^{\infty} f (s) \mathrm{d} B_s$ for all $f \in L^2
(\mathbb{R}_+)$ we formally get $\partial_t B = \xi$. One can make this link
rigorous with the help of Schwartz's theory of generalized functions, see
Exercise Sheet 2 for some details; but we will not need this in the main
lectures.

\section{Brownian motion and Poisson process}

\subsection{Continuity of stochastic processes}

The pre-Brownian motion is not very useful yet. To turn it into an interesting
and useful process, we need to add one more property to its definition:

\begin{definition}[Continuous stochastic process, (fractional) Brownian
motion]
  \begin{enumerate}
    \item We say that a stochastic process $X = (X_t)_{t \geqslant 0}$ with
    values in $\mathbb{R}^d$ is {\emph{continuous}} if all of its trajectories
    are continuous, i.e. $t \mapsto X_t (\omega)$ is continuous for all
    $\omega \in \Omega$.
    
    \item A continuous pre-Brownian motion such that $B_0 (\omega) = 0$ for
    all $\omega \in \Omega$ (rather than $B_0 = 0$ a.s.) is called a
    {\emph{Brownian motion}} or {\emph{Wiener process}}.
    
    \item A continuous fractional pre-Brownian motion such that $B_0 (\omega)
    = 0$ for all $\omega \in \Omega$ (rather than $B_0 = 0$ a.s.) is called a
    {\emph{fractional Brownian motion}}.
  \end{enumerate}
\end{definition}

It is natural to ask under which conditions a process $X$ is continuous and if
a Brownian motion exists. This turns out to be quite subtle, because it is not
possible to find conditions on the finite-dimensional distributions of $X$
which guarantee the continuity of its trajectories:

\begin{example}
  \label{ex:discontinuous modification}Let $(X_t)_{t \geqslant 0}$ be a
  continuous stochastic process with values in $\mathbb{R}$, and let $\tau$ be
  a random variable which is uniformly distributed on $[0, 1]$. Then
  \[ \tilde{X}_t (\omega) = X_t (\omega) +\1_{\{\tau (\omega) \}}
     (t), \qquad t \geqslant 0, \]
  is discontinuous for all $\omega$ and satisfies $\mathbb{P} (\tilde{X}_t =
  X_t) = 1$ for all $t \geqslant 0$. In particular, $\tilde{X}$ and $X$ have
  the same finite-dimensional distributions.
  
  \begin{figure}[h]
    \scalebox{0.35}{\includegraphics{StochAna-ongoing-8.pdf}}
    \caption{}
  \end{figure}
  
  Recall from Stochastics~II that the {\emph{law}} of $(X_t)_{t \geqslant 0}$
  is defined as the measure $\mathbb{P}_X =\mathbb{P} \circ X^{- 1}$ on
  $(\mathbb{R}^{\mathbb{R}_+}, \mathcal{B} (\mathbb{R})^{{\otimes
  \mathbb{R}_+} })$, and that $\mathbb{P}_X$ is uniquely determined by the
  finite-dimensional distributions of $X$, i.e. the family of measures
  $(\mathbb{P} \circ (X_t)_{t \in I}^{- 1})_{I \subset \mathbb{T}, | I | <
  \infty}$. Since $X$ and $\tilde{X}$ have the same finite-dimensional
  distributions, they also have the same law on $(\mathbb{R}^{\mathbb{R}_+},
  \mathcal{B} (\mathbb{R})^{{\otimes \mathbb{R}_+} })$: $\mathbb{P}_X
  =\mathbb{P}_{\tilde{X}}$. So we have two processes with the same law, but $X
  (\omega)$ is continuous for all $\omega \in \Omega$, while $\tilde{X}
  (\omega)$ is discontinuous for all $\omega \in \Omega$. Consequently, we
  cannot determine from the law of a process whether it is continuous.
  
  In particular, the set $C (\mathbb{R}_+, \mathbb{R})$ is not in $\mathcal{B}
  (\mathbb{R})^{\otimes \mathbb{R}_+}$: Otherwise $\mathbb{P}_X (C
  (\mathbb{R}_+, \mathbb{R})) =\mathbb{P}_{\tilde{X}} (C (\mathbb{R}_+,
  \mathbb{R}))$ would be defined and this would lead to the contradiction
  \begin{eqnarray*}
    1 & = & \mathbb{P} (\Omega)\\
    & = & \mathbb{P} (X \in C (\mathbb{R}_+, \mathbb{R}))\\
    & = & \mathbb{P}_X (C (\mathbb{R}_+, \mathbb{R}))\\
    & = & \mathbb{P}_{\tilde{X}} (C (\mathbb{R}_+, \mathbb{R}))\\
    & = & \mathbb{P} (\tilde{X} \in C (\mathbb{R}_+, \mathbb{R}))\\
    & = & \mathbb{P} (\varnothing) = 0.
  \end{eqnarray*}
  Therefore, our assumption $C (\mathbb{R}_+, \mathbb{R}) \in \mathcal{B}
  (\mathbb{R})^{\otimes \mathbb{R}_+}$ must have been wrong. Even worse, a
  variation of the same argument shows that not even the point set $\{ 0 \}$
  is in $\mathcal{B} (\mathbb{R})^{\otimes \mathbb{R}_+}$ (where we write $0$
  for the function which maps every $t$ to $0$).
\end{example}

The problem is that the law of $X$ is defined on $\mathcal{B}
(\mathbb{R})^{\otimes \mathbb{R}_+}$, and roughly speaking sets from this
$\sigma$-algebra only depend on countably many $(X_{t_1}, X_{t_2}, \ldots)$.
But to determine whether $X$ is continuous we need to evaluate it at
{\underline{all}} $t \in \mathbb{R}_+$.

{\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
  \textbf{Structure of $\mathcal{B} (\mathbb{R})^{\otimes \mathbb{R}_+}$:}
  The following discussion is irrelevant for our lecture. A subset $A \subset
  \mathbb{R}^{\mathbb{R}_+}$ is in $\mathcal{B} (\mathbb{R})^{\otimes
  \mathbb{R}_+}$ if and only if there exists $t_1, t_2, \ldots \in
  \mathbb{R}_+$ and $B \in \mathcal{B} (\mathbb{R})^{\otimes \mathbb{N}}$ such
  that
  \[ A = \{ \omega \in \mathbb{R}^{\mathbb{R}_+} : (\omega (t_1), \omega
     (t_2), \ldots) \in B \} . \]
  Proving this amounts to showing that the family of sets of the claimed form
  is a Dynkin system and also stable by intersection, and then to apply the
  $\pi - \lambda$ theorem.
\end{tabularx}

\begin{definition}[Modification, indistinguishable]
  Let $X = (X_t)_{t \in \mathbb{T}}$ and $\tilde{X} = (\tilde{X}_t)_{t \in
  \mathbb{T}}$ be two stochastic processes with values in a measurable state
  space $S$. We say that
  \begin{enumerate}
    \item $\tilde{X}$ is a {\emph{modification}} of $X$ if $\mathbb{P} (X_t =
    \tilde{X}_t) = 1$ for all $t \in \mathbb{T}$;
    
    \item $X$ and $\tilde{X}$ are {\emph{indistinguishable}} if there exists a
    measurable set $A \in \mathcal{F}$ with $\mathbb{P} (A) = 1$ and such that
    $X_t (\omega) = \tilde{X}_t (\omega)$ for all $\omega \in A$ and all $t
    \in \mathbb{T}$. Formally, we also write $\mathbb{P} (X_t = \tilde{X}_t
    \text{ for all } t \in \mathbb{T}) = 1$.
  \end{enumerate}
\end{definition}

Note that $\mathbb{P} (X_t = \tilde{X}_t \text{ for all } t \in \mathbb{T})$
might in general not be defined, because
\[ \left\{ X_t = \tilde{X}_t \text{ for all } t \in \mathbb{T} \right\} =
   \bigcap_{t \in \mathbb{T}} \{ X_t = \tilde{X}_t \} \]
is an intersection of uncountably many events. Therefore, we require the
existence of the measurable set $A \in \mathcal{F}$ in ii.

The second property is much stronger than the first one. For example, if $X$
is a continuous process and $X$ and $\tilde{X}$ are indistinguishable, then
$\tilde{X}$ is almost surely continuous. While Example~\ref{ex:discontinuous
modification} shows that a continuous process can have a discontinuous
modification.

\

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on October 23}
  \hrulefill\hrulefill
\end{center}

\

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Let $(\tilde{X}_t)_{t \geqslant 0}$ be a modification of $(X_t)_{t \geqslant
  0}$. Show that:
  \begin{enumerate}
    \item $X$ and $\tilde{X}$ have the same finite dimensional distributions
    and therefore the same law.
    
    \item If $X$ and $\tilde{X}$ take values in a metric space and are both
    continuous, then they are indistinguishable.
  \end{enumerate}
\end{exercise*}}}{\ }

There are essentially two ways to solve these problems and to construct
continuous processes:
\begin{itemizeminus}
  \item Either we construct the process of interest $X$ on a different
  probability space than $(\mathbb{R}^{\mathbb{R}_+},
  \mathcal{B}(\mathbb{R})^{\otimes \mathbb{R}_+})$, for example on $(C
  (\mathbb{R}_+, \mathbb{R}), \mathcal{B}(C (\mathbb{R}_+, \mathbb{R})))$ (say
  via Donsker's invariance principle for the Brownian motion).
  
  \item Or we use the Kolmogorov extension problem to construct a process
  $\tilde{X}$ on $(\mathbb{R}^{\mathbb{R}_+}, \mathcal{B}(\mathbb{R})^{\otimes
  \mathbb{R}_+})$ which has all the prescribed finite dimensional
  distributions that we want, and then try to construct a continuous
  modification $X$ of $\tilde{X}$ (so in particular $X$ has the required law).
\end{itemizeminus}
Of course, there are also probability laws on $(\mathbb{R}^{\mathbb{R}_+},
\mathcal{B}(\mathbb{R})^{\otimes \mathbb{R}_+})$ for which the associated
process can never be continuous, for example the (deterministic) process $X_t
=\1_{[1, \infty)} (t)$, or the Poisson process that we will encounter
later. But in many cases of interest, most notably for the pre-Brownian
motion, one or both of these approaches can be used to construct a continuous
process with the given law. Here we will follow the second approach.

\begin{definition}[H{\"o}lder continuity]
  For $\alpha \in (0, 1]$ and $T \in (0, + \infty)$, the space of
  $\alpha$-{\emph{H{\"o}lder continuous}} functions on $[0, T]$ is defined as
  \[ C^{\alpha} ([0, T], \mathbb{R}) = \{f : [0, T] \rightarrow \mathbb{R},
     \|f\|_{\alpha} < \infty\}, \qquad \text{where } \|f\|_{\alpha} \coloneq
     \sup_{0 \le s < t \le T}  \frac{|f (t) - f (s) |}{|t - s|^{\alpha}} . \]
  In case of ambiguity of the time interval, we also write more explicitly
  \[ \|f\|_{C^{\alpha} ([0, T])} \coloneq \sup_{0 \le s < t \le T}  \frac{|f
     (t) - f (s) |}{|t - s|^{\alpha}} \]
\end{definition}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  {\tmdummy}
  
  \begin{enumerate}
    \item Do you know another name for $1$-H{\"o}lder continuous functions?
    
    \item Show that for $\beta \leqslant \alpha$ we have $C^{\alpha} ([0, T],
    \mathbb{R}) \subset C^{\beta} ([0, T], \mathbb{R})$.
  \end{enumerate}
\end{exercise*}}}{\ }

\

One of the most important tools for constructing continuous stochastic
processes is Kolmogorov's continuity criterion.

\begin{theorem}[Kolmogorov's continuity criterion]
  \label{thm:kolmogorov-continuity}Let $T \in (0, + \infty)$ and let $(X_t)_{t
  \in [0, T]}$ be a real-valued stochastic process such that there exist $p
  \in [1, \infty)$, $\alpha > \frac{1}{p}$ and $K \geqslant 0$ with
  \begin{equation}
    \label{eq:kolmogorov continuity assumption} \mathbb{E} [|X_t - X_s |^p]^{1
    / p} \leqslant K |t - s|^{\alpha} .
  \end{equation}
  Then there exists a continuous modification $\tilde{X}$ of $X$. Moreover,
  for all $\beta \in (0, \alpha - \frac{1}{p})$ there exists a constant $C = C
  (\alpha, \beta, p, T) > 0$ such that
  \begin{equation}
    \label{eq:kolmogorov-continuity-conclusion} \mathbb{E} [\| \tilde{X}
    \|_{\beta}^p]^{1 / p} \leqslant C K.
  \end{equation}
  In particular, $\tilde{X}$ is a.s. $\beta$-H{\"o}lder continuous.
\end{theorem}

Let us postpone the proof of Theorem~\ref{thm:kolmogorov-continuity} and first
present some applications, to show its power. Armed with it, we can finally
construct the Brownian motion.

\begin{corollary}
  \label{cor:Bm exists}The Brownian motion $B = (B_t)_{t \ge 0}$ exists and
  $(B_t)_{t \in [0, T]}$ is almost surely in $C^{\alpha} ([0, T], \mathbb{R})$
  whenever $T \in (0, \infty)$ and $\alpha < 1 / 2$. We have
  \[ \mathbb{E} [\|B\|_{C^{\alpha} ([0, T])}^p] < \infty \qquad \forall \, p
     \in [1, \infty) . \label{eq:holder.continuity.Bm} \]
\end{corollary}

\begin{proof}
  Let $(\tilde{B}_t)_{t \geqslant 0}$ be a pre-Brownian motion. Since $B$ is a
  centered Gaussian, all its $p$-moments scale in the same way and so for $p >
  0$ we have
  \[ \mathbb{E} [| \tilde{B}_t - \tilde{B}_s |^p]^{1 / p} = \left( c_p
     \mathbb{E}[| \tilde{B}_t - \tilde{B}_s |^2]^{\frac{p}{2}} \right)^{1 / p}
     = \left( c_p |t - s|^{\frac{p}{2}} \right)^{1 / p} = c_p^{1 / p} |t -
     s|^{\frac{1}{2}} . \]
  It follows from Corollary~\ref{cor:kolmogorov.infinite.time} below that
  $(\tilde{B}_t)_{t \geqslant 0}$ has a continuous modification $(B_t)_{t
  \geqslant 0}$; so here let us focus on proving the
  statement~\eqref{eq:holder.continuity.Bm}. Applying Kolmogorov's continuity
  criterion to $(B_t)_{t \in [0, T]}$ for $\alpha < \frac{1}{2}$ and
  $\frac{1}{p} < \frac{1}{2} - \alpha$, we find
  \[ \mathbb{E} [\|B\|_{C^{\alpha} ([0, T])}^p] < \infty . \]
  The claim was that this is true for all $p \geqslant 1$, and the above shows
  it for $p$ large enough, i.e. $p > \left( \frac{1}{2} - \alpha \right)^{-
  1}$; instead for $p \in [1, \left( \frac{1}{2} - \alpha \right)^{- 1}]$ we
  can find $n \in \mathbb{N}$ such that $n > \left( \frac{1}{2} - \alpha
  \right)^{- 1} \geqslant p$ and then bound it using Jensen's inequality:
  \[ \mathbb{E} [\|B\|_{C^{\alpha} ([0, T])}^p]^{\frac{1}{p}} \leqslant
     \mathbb{E} [\|B\|_{C^{\alpha} ([0, T])}^n]^{\frac{1}{n}} < \infty . \]
\end{proof}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  How big do we need to choose $p$ in the previous argument to at least be
  able to apply Kolmogorov's continuity criterion? Does $p = 2$ work? Which
  H{\"o}lder continuity would we get with $p = 2 + \varepsilon$?
\end{exercise*}}}{}

\begin{corollary}
  \label{cor:kolmogorov.infinite.time}Let $(X_t)_{t \geqslant 0}$ be a
  real-valued stochastic process; suppose that there exist $p \in [1,
  \infty)$, $\alpha > \frac{1}{p}$ and $K \geqslant 0$ such that
  \[ \mathbb{E} [|X_t - X_s |^p]^{1 / p} \leqslant K |t - s|^{\alpha}  \quad
     \forall \, s \leqslant t. \]
  Then there exists a continuous modification $\tilde{X}$ of $X$.
\end{corollary}

\begin{proof}
  The difference to the formulation of Theorem~\ref{thm:kolmogorov-continuity}
  is that now $X$ is indexed by $\mathbb{R}_+$, and not by a compact interval
  $[0, T]$. But we can apply for each $n \in \mathbb{N}$ Kolmogorov's
  continuity criterion to obtain a continuous modification
  $(\tilde{X}^{(n)}_t)_{t \in [0, n]}$ of $(X_t)_{t \in [0, n]}$. We would
  like to define $\tilde{X}_t = \tilde{X}^{(n)}_t$ for $n \geqslant t$. The
  problem is that there are infinitely many possible choices for $n \geqslant
  t$, so we have to justify that this definition does not depend on $n$ and
  that it leads to a continuous process.
  
  If $m \geqslant n$, then $(\tilde{X}^{(n)}_t)_{t \in [0, n]}$ and
  $(\tilde{X}^{(m)}_t)_{t \in [0, n]}$ are both modifications of $(X_t)_{t \in
  [0, n]}$ and they are both continuous, so they are indistinguishable. Since
  the countable union of null sets is a null set, we obtain $\mathbb{P} (N) =
  0$ for
  \[ N = \left\{ \omega \in \Omega : \, \exists m, n \in \mathbb{N} \text{ \
     s.t. } n \leqslant m \text{ and } \tilde{X}^{(n)}_t (\omega) \neq
     \tilde{X}^{(m)}_t \text{ for some } t \leqslant n \right\} . \]
  We then define for $t \leqslant n$:
  \[ \tilde{X}_t (\omega) = \left\{\begin{array}{ll}
       \tilde{X}^{(n)}_t (\omega), & \omega \in N^c,\\
       0, & \omega \in N.
     \end{array}\right. \]
  Since $N$ is a null set, $\tilde{X}$ is a modification of $X$, and it is
  trivially continuous for $\omega \in N$. And since for $\omega \in N^c$ we
  have
  \[ \tilde{X}_t (\omega) = \tilde{X}_t^{(n)} (\omega) = \tilde{X}_t^{(m)}
     (\omega) \]
  for all $n, m \geqslant t$ and all the $(\tilde{X}^{(k)}_t)_t$ are
  continuous, we get that $\tilde{X} (\omega)$ is continuous.
\end{proof}

We can finally present the

\begin{proof*}{Proof of Theorem~\ref{thm:kolmogorov-continuity}}
  We use the notation
  \[ X_{s, t} \coloneq X_t - X_s . \]
  \begin{enumeratenumeric}
    \item By rescaling time $t \rightarrow T \cdot t$, we may assume without
    loss of generality that $T = 1$ (convince yourself of this! See the blue
    exercise later).
    
    \item Assume that we already showed for a dense subset $D \subset [0, 1]$
    that:
    \begin{equation}
      \label{eq:kolmog-pr1} \mathbb{E} \left[ \left( \sup_{s \neq t \in D}
      \frac{| X_{s, t} |}{| t - s |^{\beta}} \right)^p \right]^{1 / p}
      \leqslant C K.
    \end{equation}
    Then in particular $\sup_{s \neq t \in D} \frac{| X_{s, t} (\omega) |}{| t
    - s |^{\beta}} < \infty$ for almost all $\omega$, and for such $\omega$
    the function $X (\omega)$ is uniformly continuous on the dense subset $D
    \subset [0, 1]$. Therefore, it has a unique continuous extension to a
    function $\tilde{X} (\omega)$ on $[0, 1]$, which satisfies
    \[ \sup_{s \neq t \in [0, 1]} \frac{| \tilde{X}_{s, t} (\omega) |}{| t - s
       |^{\beta}} = \sup_{s \neq t \in D} \frac{| X_{s, t} (\omega) |}{| t - s
       |^{\beta}} . \]
    If $\omega$ is in the null set for which $\sup_{s \neq t \in D} \frac{|
    X_{s, t} (\omega) |}{| t - s |^{\beta}} = \infty$, we simply define
    $\tilde{X}_t (\omega) = 0$ for all $t \in [0, 1]$. Then $\tilde{X}$ is
    continuous and it satisfies \eqref{eq:kolmogorov-continuity-conclusion},
    but we still have to show that it is a modification of $X$.
    
    For $t \in D$ we have a.s. $X_t = \tilde{X}_t$ by construction. For $t
    \nin D$ consider a sequence $(t_n) \subset D$ with $t_n \rightarrow t$.
    Then $\tilde{X}_{t_n} (\omega) \rightarrow \tilde{X}_t (\omega)$ for all
    $\omega$ by continuity of $\tilde{X}$, and $X_{t_n} \rightarrow X_t$ in
    $L^p$ because $\mathbb{E} [| X_{t_n} - X_t |^p]^{1 / p} \leqslant K | t -
    t_n |^{\alpha}$. Therefore, the sequence $(\tilde{X}_{t_n} = X_{t_n})_n$
    converges a.s. to $\tilde{X}_t$ and it converges in $L^p$ to $X_t$, thus
    $\tilde{X}_t = X_t$ a.s. and $\tilde{X}$ is indeed a modification of $X$.
    
    \item It remains to show \eqref{eq:kolmog-pr1}. For $n \in \mathbb{N}_0$,
    consider the dyadic times
    \[ D_n \coloneq \{ t^n_k \coloneq k 2^{- n}, 0 \leqslant k \leqslant 2^n \},
       \qquad D \coloneq \bigcup_{n = 0}^{\infty} D_n, \]
    and let
    \[ \Delta_n = \{ (t^n_k, t^n_{k + 1}) : 0 \leqslant k \leqslant 2^n - 1 \}
    \]
    be the nearest neighbors in $D_n$. Then $D$ is dense and it suffices to
    show \eqref{eq:kolmog-pr1} for this $D$. Let for $n \in \mathbb{N}_0$:
    \[ M_n \coloneq \max_{k = 0, \ldots, 2^n - 1} | X_{t^n_k, t^n_{k + 1}} | =
       \max_{(s, t) \in \Delta_n} | X_{s, t} | . \]
    Then
    \begin{equation}
      \begin{array}{ll}
        \mathbb{E} [M_n^p]^{1 / p} & =\mathbb{E} [\max_{k = 0, \ldots, 2^n -
        1} | X_{t^n_k, t^n_{k + 1}} |^p]^{1 / p}\\
        & \leqslant \mathbb{E} \left[ \sum_{k = 0}^{2^n - 1} | X_{t^n_k,
        t^n_{k + 1}} |^p \right]^{1 / p} = \left( \sum_{k = 0}^{2^n - 1}
        \mathbb{E} [| X_{t^n_k, t^n_{k + 1}} |^p] \right)^{1 / p}\\
        & \leqslant 2^{n / p} K 2^{- n \alpha} = K 2^{- n \left( \alpha -
        \frac{1}{p} \right)} .
      \end{array} \label{eq:kolmog-pr2}
    \end{equation}
    This bound would suffice if we only wanted to compare $s, t \in \bigcup_n
    \Delta_n$. But we also have to treat the case $s = t^n_k$ and $t =
    t^m_{\ell}$ for arbitrary $m, n$ and $k, \ell$. We claim that
    \begin{equation}
      \sup_{s \neq t \in D} \frac{| X_{s, t} |}{| t - s |^{\beta}} \leqslant
      2^{\beta + 1} M, \label{eq:kolmog-pr3}
    \end{equation}
    where $M \coloneq \sum_{n = 0}^{\infty} 2^{n \beta} M_n \in [0, \infty]$.
    If this is the case, then by the triangle inequality for the $L^p$-norm
    (``Minkowski's inequality''), we have:
    
    \begin{align*}
      \mathbb{E} [M^p]^{1 / p} & = \| M \|_{L^p} \leqslant \sum_{n =
      0}^{\infty} \| 2^{n \beta} M_n \|_{L^p}\\
      & \overset{\eqref{eq:kolmog-pr2}}{\leqslant} \sum_{n = 0}^{\infty} 2^{n
      \beta} K 2^{- n \left( \alpha - \frac{1}{p} \right)} = K \sum_{n =
      0}^{\infty} 2^{n \left( \beta - \left( \alpha - \frac{1}{p} \right)
      \right)} = K \tilde{C},
    \end{align*}
    
    where $\tilde{C} = \sum_{n = 0}^{\infty} 2^{n \left( \beta - \left( \alpha
    - \frac{1}{p} \right) \right)} < \infty$ because $\beta < \alpha -
    \frac{1}{p}$, so that the geometric series converges. Combining the above
    bound on $\| M \|_{L^p (\Omega)}$ with claim~\eqref{eq:kolmog-pr3} thus
    yields the conclusion~\eqref{eq:kolmogorov-continuity-conclusion}.
    
    \
    
    \begin{center}
      \hrulefill\hrulefill\textbf{ End of the lecture on October 24}
      \hrulefill\hrulefill
    \end{center}
    
    \
    
    \item To prove the claim~\eqref{eq:kolmog-pr3}, we use a {\emph{chaining
    argument}}: Define for $s < t \in D$:
    \[ s_n \coloneq \min \{ r \in D_n : r \geqslant s \}, \qquad t_n \coloneq
       \max \{ r \in D_n : r \leqslant t \} . \]
    Since $s, t \in D = \bigcup_m D_m$ we have $s_n = s$ and $t_n = t$ from
    some $n$ on.
    
    \begin{figure}[h]
      \scalebox{0.5}{\includegraphics{StochAna-ongoing-9.pdf}}
      \caption{Illustration of the $s_n$ and $t_n$.}
    \end{figure}
    
    \
    
    Consider now $m \in \mathbb{N}_0$ such that $2^{- m - 1} < t - s
    \leqslant 2^{- m}$. Then
    \begin{eqnarray*}
      | X_t - X_s | & \leqslant & | X_t - X_{t_m} | + | X_{t_m} - X_{s_m} | +
      | X_{s_m} - X_s |\\
      & \leqslant & \sum_{n = m}^{\infty} | X_{t_{n + 1}} - X_{t_n} | + |
      X_{t_m} - X_{s_m} | + \sum_{n = m}^{\infty} | X_{s_n} - X_{s_{n + 1}} |,
    \end{eqnarray*}
    where the two series on the right hand side are actually finite sums.
    Since $2^{- m} \geqslant t - s$ we know that either $s_m = t_m$ or $(s_m,
    t_m) \in \Delta_m$. Moreover,
    \[ s_n - s_{n + 1} \leqslant s_n - s < 2^{- n} \]
    and $s_n, s_{n + 1} \in D_{n + 1}$, so either $s_n = s_{n + 1}$ or $(s_{n
    + 1}, s_n) \in \Delta_{n + 1}$. Similarly for $(t_n, t_{n + 1})$.
    Therefore, we can estimate
    
    \begin{align*}
      \frac{| X_{s, t} |}{| t - s |^{\beta}} & \leqslant | t - s |^{- \beta}
      \left( 2 \sum_{n = m}^{\infty} \max_{(u, v) \in \Delta_{n + 1}} | X_{u,
      v} | + \max_{(u, v) \in \Delta_m} | X_{u, v} | \right)\\
      & \leqslant (2^{- m - 1})^{- \beta} 2 \sum_{n = m}^{\infty} M_n
      \leqslant 2^{\beta + 1} \sum_{n = m}^{\infty} 2^{n \beta} M_n \leqslant
      2^{\beta + 1} M,
    \end{align*}
    
    where $M = \sum_{n = 0}^{\infty} 2^{n \beta} M_n$. This concludes the
    proof.
  \end{enumeratenumeric}
\end{proof*}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  {\tmdummy}
  
  \begin{enumerate}
    \item Deduce that: If $(X_t)_{t \in [0, T]}$ is such that $\mathbb{E} [|
    X_t - X_s |^p] \leqslant K | t - s |^{\gamma}$ for some $p \geqslant 1$
    and $\gamma > 1$, then $X$ has a continuous modification. On Sheet~2 we
    will see that this is false for $\gamma = 1$.
    
    \item Convince yourself that the same proof works if $X$ takes values in a
    complete metric space (important special case: Banach space). But
    completeness is important: where did we use the fact that $\mathbb{R}$ is
    complete?
    
    \item Justify Step~1 of the proof. In fact, apply scaling to get a more
    precise statement: if $X$ satisfies~\eqref{eq:kolmogorov continuity
    assumption} on $[0, T]$, then for all $\beta \in (0, \alpha -
    \frac{1}{p})$ there exists a constant $\tilde{C} = \tilde{C} (\alpha,
    \beta, p) > 0$ such that
    \[ \mathbb{E} [\| \tilde{X} \|_{\beta}^p]^{1 / p} \leqslant \tilde{C} K
       T^{\alpha - \beta} \]
    where now the dependence on $T$ is explicit. Note that the r.h.s. explodes
    as $T \rightarrow \infty$. Can you reconstruct the exact expression of
    $\tilde{C} (\alpha, \beta, p)$ from the proof?
  \end{enumerate}
\end{exercise*}}}{\ }

Lemma~\ref{lem:pre-Brownian} is analogously true for Brownian motion: a
continuous stochastic process is a Brownian motion if and only if
the conditions i.-iii. in the lemma are satisfied.

\begin{remark}
  \label{rmk:Bm not globally hoelder}The Brownian motion is only
  H{\"o}lder-continuous on compact intervals, but not on $\mathbb{R}_+$, i.e.
  we a.s. have $\sup_{0 \leqslant s < t < \infty} \frac{| B_t - B_s |}{| t - s
  |^{\alpha}} = \infty$ for all $\alpha \in \mathbb{R}$. You will show this on
  Sheet~2.
\end{remark}

\begin{remark}
  {\tmdummy}
  
  \begin{enumerate}
    \item Recall from Probability Theory~II that the Borel $\sigma$-algebra on
    $C (\mathbb{R}_+, \mathbb{R}) = C (\mathbb{R}_+)$, equipped with the
    topology of locally uniform convergence, is given by
    \[ \mathcal{B} (C (\mathbb{R}_+)) =\mathcal{B} (\mathbb{R})^{\otimes
       \mathbb{R}_+} \cap C (\mathbb{R}_+) = \{ A \cap C (\mathbb{R}_+) : A
       \in \mathcal{B} (\mathbb{R})^{\otimes \mathbb{R}_+} \} . \]
    Therefore, a map $X : \Omega \rightarrow C (\mathbb{R}_+)$ is
    $\mathcal{F}-\mathcal{B} (C (\mathbb{R}_+, \mathbb{R}))$-measurable if and
    only if $X_t : \Omega \rightarrow \mathbb{R}$ is $\mathcal{F}-\mathcal{B}
    (\mathbb{R})$-measurable for all $t \geqslant 0$. In other words, $X$ is a
    random variable taking values in $C (\mathbb{R}_+)$ if and only if
    $(X_t)_{t \geqslant 0}$ is a continuous stochastic process. Therefore, any
    continuous stochastic process induces a probability measure $\mathbb{P}_X$
    on $(C (\mathbb{R}_+), \mathcal{B} (C (\mathbb{R}_+)))$ via $\mathbb{P}_X
    (A) =\mathbb{P} (X \in A)$ (i.e. $\mathbb{P}_X$ is the distribution of
    $X$).
    
    \item The distribution $\mathbb{P}_B$ of the Brownian motion is often
    called the {\emph{Wiener measure}} on $(C (\mathbb{R}_+), \mathcal{B} (C
    (\mathbb{R}_+)))$; the probability space $(C (\mathbb{R}_+), \mathcal{B}
    (C (\mathbb{R}_+)), \mathbb{P}_B)$ is called the {\emph{Wiener space}}.
  \end{enumerate}
\end{remark}

In fact, we can extend the discussion in the previous remark to show that any
continuous stochastic process can be realized on the space $(C (\mathbb{R}_+),
\mathcal{B} (C (\mathbb{R}_+)))$ in a canonical way. To this end,
we need to introduce some notation. Given $\omega \in C (\mathbb{R}_+)$ and $t
\geqslant 0$, we define the evaluation map} $e_t : C (\mathbb{R_+)
\rightarrow \mathbb{R}$ as $e_t (f) = f (t)$.

{\tmstrong{(In the lecture, the next statement was presented in a slightly
more informal way as part of the discussion in the previous remark)}}

\begin{lemma}
  Let $X$ be a continuous real valued stochastic process, $\mathbb{P}_X$ be
  its law. On the probability space $(C (\mathbb{R}_+), \mathcal{B} (C
  (\mathbb{R}_+)), \mathbb{P}_X)$, consider the collection $(e_t)_{t \geqslant
  0}$. Then $(e_t)_{t \geqslant 0}$ is a continuous stochastic process, with
  law $\mathbb{P}_X$.
\end{lemma}

\begin{proof}
  It's easy to see that, for each $t$, $e_t$ is a linear, continuous map; thus
  in particular is is measurable from $(C (\mathbb{R}_+), \mathcal{B} (C
  (\mathbb{R}_+)))$ to $(\mathbb{R}, \mathcal{B} (\mathbb{R}))$, namely it is
  a random variable, so that $(e_t)_{t \geqslant 0}$ is a stochastic process.
  For any $f \in C (\mathbb{R}_+)$, the map $t \mapsto e_t (f) = f (t)$ is
  none other than $f$ itself, which is continuous by definition, so $(e_t)_{t
  \geqslant 0}$ is a continuous stochastic process. Now consider $n \in
  \mathbb{N}$, $(t_1, \ldots, t_n) \in \mathbb{R}_+^n$, $A_i \in \mathcal{B}
  (\mathbb{R})$ for $i = 1, \ldots n$, and the subset of
  $\mathbb{R}^{\mathbb{R}_+}$ given by $\Gamma = \{ f \in
  \mathbb{R}^{\mathbb{R}_+} : f (t_i) \in A_i \}$. Then by construction
  
  \begin{align*}
    \mathbb{P}_X (f \in C (\mathbb{R}_+) : e_{t_i} (f) \in A_i \operatorname{for} i =
    1, \ldots, n) & =\mathbb{P}_X ((e_t)_{t \geqslant 0} \in \Gamma \cap C
    (\mathbb{R}_+))\\
    & =\mathbb{P} (X \in \Gamma \cap C (\mathbb{R}_+))\\
    & =\mathbb{P} (X_{t_i} \in A_i \operatorname{for} i = 1, \ldots n)
  \end{align*}
  
  which shows that the finite dimensional distributions of $(e_t)_{t \geqslant
  0}$ under $\mathbb{P}_X$ coincide with the finite dimensional distributions
  of $X$ under $\mathbb{P}$. In particular, $(e_t)_{t \geqslant 0}$ and $X$
  (which are possibly defined on different probability spaces!) have the same
  law.
\end{proof}

In probability, quite often we do not really care about the underlying
probability space $(\Omega, \mathcal{F}, \mathbb{P})$, which is treated as an
abstract object. The above result however tells us that, in the case of
continuous stochastic processes, if needed we can make it very explicit: we
can take $\Omega = C (\mathbb{R}_+)$, with the associated Borel
$\sigma$-algebra, and $\mathbb{P}$ to be the law of the process itself. This
is sometimes referred to as the canonical representation of the
process $X$. Notice that in this case $\Omega$ becomes a complete separable
metric space and a vector space, so it has a very nice structure.

\

For a Brownian motion $B$ and $n \in \mathbb{N}$, we can consider the
piecewise linear dyadic approximation $B^{(n)}$, which interpolates $B$
linearly between the points $t^n_k \coloneq k 2^{- n}$, for $k \in
\mathbb{N}_0$; namely
\[ B^{(n)}_t : = \sum_{k = 0}^{\infty} \1_{[t^n_k, t^n_{k + 1})} (t) 
   (B_{t^n_k} + 2^n (t - t^n_k) B_{t^n_k, t^n_{k + 1}}) . \]
By continuity of $B^{(n)}$ it is clear that $\sup_{t \leqslant T} |B^{(n)}_t
(\omega) - B_t (\omega) |$ converges to $0$ for all $\omega \in \Omega$ and
all $T \in (0, + \infty)$. It is also not difficult to show that for $f \in
L^2 (\mathbb{R}_+)$ we have
\[ \int_0^{\infty} f (t) \mathrm{d} B_t = \lim_{n \rightarrow \infty}
   \int_0^{\infty} f (t) \mathrm{d} B_t^{(n)} = \lim_{n \rightarrow \infty}
   \int_0^{\infty} f (t) \partial_t B^{(n)}_t \mathrm{d} t \eqqcolon \lim_{n
   \rightarrow \infty} \int_0^{\infty} f (t) \xi^{(n)}_t \mathrm{d} t, \]
where the left hand side is the Wiener integral and $\xi^{(n)}_t \coloneq
\partial_t B^{(n)}_t$ for all $t$ (this is well defined for all $t \nin \{
t^n_k : k \in \mathbb{N}_0 \}$, and in $t^n_k$ we could for example take the
right derivative), and the convergence is in $L^2 (\Omega)$. Since
$\int_0^{\infty} f (t) \mathrm{d} B_t = \xi (f)$ for a white noise $\xi$, we get
that $\xi (f) = \lim_{n \rightarrow \infty} \int_0^{\infty} f (t) \xi^{(n)}_t
\mathrm{d} t$, so in a sense we can intepret $\xi$ as limit of $\xi^{(n)}$.
Moreover, by construction
\[ \xi^{(n)}_t = \sum_{k = 0}^{\infty} \1_{[t^n_k, t^n_{k + 1})} (t) 2^n
   B_{t^n_k, t^n_{k + 1}} . \]
By independence of the Brownian increments we get that $\xi^{(n)} |_{[t^n_k,
t^n_{k + 1})}$ and $\xi^{(n)} |_{[t^n_{\ell}, t^n_{\ell + 1})}$ are
independent for $k \neq \ell$. Moreover, $\mathbb{E} [\xi^{(n)}_t] = 0$ and
$\operatorname{Var} (\xi^{(n)}_t) = 2^n$ for all $t \geqslant 0$. So by letting $n
\rightarrow \infty$ we formally obtain indeed that $(\xi_t)_{t \geqslant 0}$
are independent and identically distributed Gaussian random variables with
infinite variance. Of course, this is again purely formal and just intended to
guide your intuition.

\subsection{Some path properties of the Brownian motion}

So far we showed that the Brownian motion exists and it is almost surely
$\alpha$-H{\"o}lder continuous on compact subintervals of $\mathbb{R}_+$
whenever $\alpha < 1 / 2$. Our next aim is to understand its trajectories
better. For example a priori it is not clear whether the Brownian motion can
be more regular than $\alpha$-H{\"o}lder continuous. Although in simulations
it looks very rough, so we would not expect it to be a $C^1$ function, and
indeed we will show that it is not.

\begin{figure}[h]
  \resizebox{0.5\columnwidth}{!}{\includegraphics{StochAna-ongoing-10.pdf}}
  \caption{Sample path of a Brownian motion.}
\end{figure}

Throughout this section we fix a Brownian motion $B$. Let us start by showing
the invariance of the law of $B$ under certain path transformations:

\begin{proposition}
  \label{prop:brownian path transformation}{\tmdummy}
  
  \begin{enumerate}
    \item ($- B_t)_{t \geqslant 0}$ is a Brownian motion;
    
    \item more generally, for any $\lambda \in \mathbb{R} \setminus \{0\}$,
    $(\lambda^{- 1} B_{\lambda^2 t})_{t \geqslant 0}$ is a Brownian motion;
    
    \item $(B_{t + s} - B_s)_{t \geqslant 0}$ for $s \geqslant 0$ is a
    Brownian motion, and is independent of $(B_r)_{r \in [0, s]}$
    ({\emph{``Markov property''}});
    
    \item $(t \cdot B_{1 / t})_{t \geqslant 0}$, where we set $0 \cdot B_{1 /
    0} \coloneq 0$, is indistinguishable from a Brownian motion.
  \end{enumerate}
\end{proposition}

\begin{proof}
  i.}, \textit{ii.}, \tmtextit{iii. were shown on Sheet 1.
  
  iv.}: The process $(t \cdot B_{1 / t})_{t \geqslant 0$ is
  Gaussian, continuous everywhere except possibly at 0, and for $0 < s < t$ we
  have
  \[ \mathbb{E} [(s \cdot B_{1 / s}) (t \cdot B_{1 / t})] = s \cdot t (1 / t)
     = s = s \wedge t. \]
  It remains to show the (almost sure) continuity at 0. For that purpose, note
  that by continuity of $t \mapsto t B_{1 / t}$ on $(0, 1]$, it holds
  \[ \{ \omega : \lim_{t \rightarrow 0} t \cdot B_{1 / t} (\omega) = 0 \} =
     \bigcap_{m \in \mathbb{N}} \bigcup_{n \in \mathbb{N}} \{\omega : |t \cdot
     B_{1 / t} (\omega) | \leqslant 1 / m \text{for all } t \in \mathbb{Q}
     \cap (0, 1 / n]\} . \]
  The event on the right hand side depends only on $(t \cdot B_{1 / t})_{t \in
  \mathbb{Q} \cap (0, 1]}$, and this process has the same law as $(B_t)_{t \in
  \mathbb{Q} \cap (0, 1]}$ (both are centered Gaussian processes with the same
  covariance). Therefore
  
  \begin{align*}
    \mathbb{P} (\lim_{t \rightarrow 0} t \cdot B_{1 / t} = 0) & =\mathbb{P}
    \left( \bigcap_{m \in \mathbb{N}} \bigcup_{n \in \mathbb{N}} \left\{ |t
    \cdot B_{1 / t} | \leqslant 1 / m \text{for all } t \in \mathbb{Q} \cap
    (0, 1 / n] \right\} \right)\\
    & =\mathbb{P} \left( \bigcap_{m \in \mathbb{N}} \bigcup_{n \in
    \mathbb{N}} \left\{ |B_t | \leqslant 1 / m \text{for all } t \in
    \mathbb{Q} \cap (0, 1 / n] \right\} \right)\\
    & =\mathbb{P} (\lim_{t \rightarrow 0} B_t = 0) = 1,
  \end{align*}
  
  and the proof is complete.
\end{proof}

\begin{theorem}
  \label{thm:Bm nowhere differentiable}With probability $1$ there exists no $t
  \in [0, + \infty)$ at which $B$ is differentiable.
\end{theorem}

\begin{proof}
  The countable union of null sets is a null set and $(B_{n + t} - B_n)_{t \in
  [0, 1]}$ is a Brownian motion restricted to $[0, 1]$, so it suffices to show
  that almost surely $(B_t)_{t \in [0, 1]}$ is nowhere differentiable. If $B$
  is differentiable at $t \in [0, 1]$, then there exists a constant $\tilde{C}
  > 0$ such that
  \begin{equation}
    \label{eq:Bm not differentiable pr1} |B_{t + h} - B_t | \leqslant
    \tilde{C} h, \qquad \forall \, h \in [0, 1] .
  \end{equation}
  A priori, $\tilde{C}$ could be random; however, if we show that
  \begin{equation}
    \mathbb{P} \left( \omega \in \Omega : \exists t \in [0, 1] : |B_{t + h} -
    B_t | \leqslant C h \quad \forall \, h \in [0, 1] \right) = 0 \label{eq:Bm
    not differentiable pr2}
  \end{equation}
  for all deterministic, arbitrarily large constants $C > 0$, then the same
  must hold for random but finite $\tilde{C} > 0$ as well. In particular, to
  conclude it suffices to show~\eqref{eq:Bm not differentiable pr2} and from
  now on we can assume $C$ to be deterministic and fixed. Define the event
  \[ \Gamma = \left\{ \omega \in \Omega \, : \exists t \in [0, 1] : |B_{t + h}
     - B_t | \leqslant C h \quad \forall \, h \in [0, 1] \right\} . \]
  Notice that, by the order of quantifiers, $t$ here is allowed to be random,
  i.e. depend on the fixed realization $\omega$ we are looking at; so it's
  hard to manipulate $\Gamma$ directly, and we want to compare it to
  ``simpler'' events.
  
  Suppose $t \in [0, 1]$ is such that~(\ref{eq:Bm not differentiable pr1})
  hold; let $n \in \mathbb{N}$, and let $0 \leqslant k < 2^n$ be such that $t
  \in [k 2^{- n}, (k + 1) 2^{- n}]$. Then for all $1 \leqslant j < 2^n$ we
  have
  
  \begin{align*}
    |B_{(k + j + 1) 2^{- n}} - B_{(k + j) 2^{- n}} | & \leqslant |B_{(k + j +
    1) 2^{- n}} - B_t | + |B_t - B_{(k + j) 2^{- n}} |\\
    & \leqslant C ( (k + j + 1) 2^{- n} - k 2^{- n}) + C ((k + j) 2^{- n} - k
    2^{- n})\\
    & \leqslant C (2 j + 1) 2^{- n} .
  \end{align*}
  
  Let us define the events
  \[ \Omega_{n, k} = \bigcap_{j = 1, 2, 3} \{ |B_{(k + j + 1) 2^{- n}} - B_{(k
     + j) 2^{- n}} | \leqslant C (2 j + 1) 2^{- n} \} ; \]
  then the previous argument in fact shows that, for any $n \in \mathbb{N}$,
  \[ \Gamma \subset \bigcup_{k = 0}^{2^n - 1} \Omega_{n, k} . \]
  Therefore to show that $\mathbb{P} (\Gamma) = 0$, it suffices to estimate
  the probability of the set on the r.h.s., and show that it becomes
  infinitesimal as $n \rightarrow \infty$.
  
  \begin{center}
    \hrulefill\hrulefill\textbf{ End of the lecture on October 30}
    \hrulefill\hrulefill
  \end{center}
  
  By the independence and scaling properties of $B$
  
  \begin{align*}
    \mathbb{P} (\Omega_{n, k}) & = \prod_{j = 1}^3 \mathbb{P} (|B_{(k + j + 1)
    2^{- n}} - B_{(k + j) 2^{- n}} | \leqslant C (2 j + 1) 2^{- n})\\
    & = \prod_{j = 1}^3 \mathbb{P} (|B_1 | \leqslant C (2 j + 1) 2^{- n /
    2})\\
    & \leqslant \mathbb{P} (|B_1 | \leqslant C \cdot 7 \cdot 2^{- n / 2})^3\\
    & \leqslant (C \cdot 7 \cdot 2^{- n / 2})^3,
  \end{align*}
  
  where in the last step we used that the density of the standard normal
  distribution is bounded by $1 / \sqrt{2 \pi} \leqslant 1 / 2$. Thus,
  
  \begin{align*}
    \mathbb{P} (\Gamma) & \leqslant \mathbb{P} \left( \bigcup_{k = 0}^{2^n -
    1} \Omega_{n, k} \right)\\
    & \leqslant \sum_{k = 0}^{2^n - 1} \mathbb{P} (\Omega_{n, k}) \lesssim
    2^n 2^{- 3 n / 2} = 2^{- n / 2}
  \end{align*}
  
  and our claim follows by sending $n \rightarrow \infty$.
\end{proof}

In fact, one can slightly improve the previous proof to obtain a stronger
statement:

\begin{proposition}
  Let $\alpha > \frac{1}{2}$. With probability $1$ there exists no $t \in [0,
  + \infty)$ at which $B$ is $\alpha$-H{\"o}lder continuous (i.e. such that $|
  B_s - B_t | \leqslant C | t - s |^{\alpha}$ for all $s \geqslant 0$).
\end{proposition}

The proof is left as part of Exercise Sheet~3.

\tmfoldedplain{\begin{remark}
  \label{rmk:Bm not 1/2 hoelder}It is not true that the Brownian motion is
  nowhere $1 / 2$-H{\"o}lder continuous: there are so-called ``slow points''
  where it shows an exceptional behavior. This is beyond the scope of our
  lecture. But it is not very difficult to see that if $t \geqslant 0$ is
  fixed, then almost surely
  \begin{equation}
    \limsup_{s \rightarrow t}  \frac{|B_s - B_t |}{|s - t|^{1 / 2}} = \infty .
    \label{eq:rem.bm.slow.points}
  \end{equation}
\end{remark}}{Without loss of generality we may take $t = 0$. If $B$ is $1 /
2$-H{\"o}lder continuous in 0, then there exists $C > 0$ such that $|B_s |
\leqslant C \sqrt{s}$ for all $s \in [0, 1]$. Consider the disjoint intervals
$[1 / 2, 1]$, $[1 / 4, 1 / 2]$, $[1 / 8, 1 / 4]$, and in the $k$-th step
$[2^{- k}, 2^{- k + 1}]$, on which then
\[ |B_{2^{- k + 1}} - B_{2^{- k}} | \leqslant |B_{2^{- k + 1}} | + |B_{2^{-
   k}} | \leqslant C (2^{(- k + 1) / 2} + 2^{- k / 2}) \lesssim C 2^{- k / 2}
   . \]
But $(2^{k / 2} (B_{2^{- k + 1}} - B_{2^{- k}}))_{k \in \mathbb{N}}$ is an
i.i.d. family of standard normal variables, and therefore almost surely
unbounded. Therefore, we get
\[ \mathbb{P} \left( | B_s | \leqslant C \sqrt{s} \text{ for all } s \in [0,
   1] \right) = 0, \]
and since $C > 0$ was arbitrary the claim follows.}

\

One can combine our results on regularity of $B$ at $0$, with the fact that
$(t B_{1 / t})_{t \geqslant 0}$ is a Brownian motion (time invertion), to
learn something about the long time behavior of $B$:

\begin{corollary}
  \label{cor:bm-growth}For any $\alpha > 1 / 2$, with probability $1$ we have
  \[ 0 = \lim_{t \rightarrow \infty}  \frac{|B_t |}{t^{\alpha}} < \limsup_{t
     \rightarrow \infty}  \frac{|B_t |}{t^{1 / 2}} = \infty . \]
\end{corollary}

\begin{proof}
  We have
  \[ \limsup_{t \rightarrow \infty}  \frac{|B_t |}{t^{\alpha}} \overset{s =
     \frac{1}{t}}{=} \limsup_{s \rightarrow 0}  \frac{|s B_{1 / s} |}{s \cdot
     s^{- \alpha}} = \limsup_{s \rightarrow 0}  \frac{| \tilde{B}_s |}{s^{1 -
     \alpha}}, \]
  where $\tilde{B}_s = s B_{1 / s}$ is another Brownian motion by
  Proposition~\ref{prop:brownian path transformation}-iv.; since $1
  - \alpha < 1 / 2$, we can find $\varepsilon > 0$ small enough such that a.s.
  $\tilde{B} \in C^{1 - \alpha + \varepsilon} ([0, 1])$, so that
  \[ \limsup_{s \rightarrow 0}  \frac{| \tilde{B}_s |}{s^{1 - \alpha}}
     \leqslant \limsup_{s \rightarrow 0} \| \tilde{B} \|_{C^{1 - \alpha +
     \varepsilon}} \frac{s^{1 - \alpha + \varepsilon}}{s^{1 - \alpha}} = 0 \]
  which implies that the limsup is a limit and equals $0$. For $\alpha = 1 /
  2$, we similarly get
  \[ \limsup_{t \rightarrow \infty}  \frac{|B_t |}{t^{1 / 2}} = \limsup_{s
     \rightarrow 0}  \frac{| \tilde{B}_s |}{s^{1 / 2}} = \infty \]
  where the last equality comes from~\eqref{eq:rem.bm.slow.points}.
\end{proof}

So far we showed: Brownian motion is almost surely $(1 / 2 -
\varepsilon)$-H{\"o}lder continuous on every compact interval, and it is
almost surely nowhere $(1 / 2 + \varepsilon)$-H{\"o}lder continuous. With some
more work, it can be shown that at $\alpha = \frac{1}{2}$ there are some
logarithmic corrections.

The next statement is not examinable, but it is included here for completeness
so that you have seen it at least once, as it's a fairly celebrated result.

\begin{theorem}[L{\'e}vy's modulus of continuity \& law of the iterated
logarithm]
  \label{thm:law.iterated.log}
  \begin{enumerate}
    \item {\emph{L{\'e}vy's modulus of continuity}}: Almost surely, for any $T
    \in (0, + \infty)$:
    \[ \lim_{r \rightarrow 0} \sup_{\tmscript{\begin{array}{c}
         s, t \in [0, T] :\\
         | t - s | \leqslant r
       \end{array}}} \frac{| B_t - B_s |}{\sqrt{2 r \log (1 / r)}} = 1. \]
    \item {\emph{Law of the iterated logarithm}}: For any $t > 0$ we have
    almost surely
    \[ \limsup_{r \rightarrow 0} \frac{B_{t + r} - B_t}{\sqrt{2 r \log \log (1
       / r)}} = 1, \qquad \liminf_{r \rightarrow 0} \frac{B_{t + r} -
       B_t}{\sqrt{2 r \log \log (1 / r)}} = - 1. \]
  \end{enumerate}
\end{theorem}

\begin{proof}
  See Revuz-Yor~{\cite{Revuz1999}}, Theorem~I.2.7 and Theorem~II.1.9.
\end{proof}

Of course, we would suspect to have
\[ - \infty = \liminf_{t \rightarrow \infty}  \frac{B_t}{t^{1 / 2}} <
   \limsup_{t \rightarrow \infty}  \frac{B_t}{t^{1 / 2}} = \infty, \]
and indeed one can use Theorem~\ref{thm:law.iterated.log} and time invertion
to prove this (and more). We will not do so, but instead obtain this later as
a simple consequence of Blumenthal's $0$-1-law.

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Use the law of the iterated logarithm to deduce a stronger statement about
  the long time behavior of $B$.
\end{exercise*}}}{\ }

\subsection{The Poisson process}

We can interpret the Brownian motion as a continuous time random walk, because
just like a random walk it has independent and stationary increments (i.e.
$B_t - B_s$ is independent of what happened until time $s$, and it has the
same distribution as $B_{r + t} - B_{r + s}$ for any~$r$). It is natural to
ask whether there are other processes of this type. This leads to the
following definition:

\begin{definition}[L{\'e}vy process]
  A real-valued stochastic process $(X_t)_{t \geqslant 0}$ is called a
  {\emph{L{\'e}vy process}} if
  \begin{enumerate}
    \item $X_0 = 0$;
    
    \item for all $0 \leqslant t_0 < t_1 < \cdots < t_n$ the random variables
    $(X_{t_1} - X_{t_0}, \ldots, X_{t_n} - X_{t_{n - 1}})$ are independent
    ({\emph{independent increments}});
    
    \item for all $0 \leqslant s < t$ the random variable $X_t - X_s$ has the
    same distribution as $X_{t - s}$ ({\emph{stationary increments}});
    
    \item for all $\varepsilon > 0$ and $t \geqslant 0$ we have $\lim_{h
    \rightarrow 0} \mathbb{P} (| X_{t + h} - X_t | > \varepsilon) = 0$
    ({\emph{continuity in probability}}).
  \end{enumerate}
\end{definition}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  {\tmdummy}
  
  \begin{enumerate}
    \item Convince yourself of the following:
    parts~i.}-\tmtextit{ii. imply that $X_t - X_s$ is independent
    of $(X_r)_{r \leqslant s}$; part~iv. is equivalent to $X_s$
    converging in probability to $X_t$ as $s \rightarrow t$.
    
    \item Show that the Brownian motion is a L{\'e}vy process.
    
    \item Show that for all $a \in \mathbb{R}$ the linear function $X_t = a
    \cdot t$ is a L{\'e}vy process.
  \end{enumerate}
\end{exercise*}}}{\ }

If $X$ is a L{\'e}vy process, then we can write
\[ X_1 = X_{1 / n} + (X_{2 / n} - X_{1 / n}) + \cdots + (X_1 - X_{(n - 1) /
   n}) . \]
Let us write $\mu_t$ for the law of $X_t$. Then the left hand side has law
$\mu_1$, and the right hand side has law given by the {\emph{$n$-fold
convolution}}
\[ \mu_{1 / n}^{* n} \coloneq \begin{array}{l}
     \underbrace{\mu_{1 / n} * \ldots * \mu_{1 / n}}\\
     \hspace{1.8em} n \operatorname{times}
   \end{array} ; \]
this is because, if $U$ and $V$ are independent random variables with
$\operatorname{law} (U) = \pi$ and $\tmop{law} (V) = \nu$, then $\tmop{law} (U + V) =
\pi * \nu$, where the convolution $\pi * \nu$ is the measure defined by
\[ \pi * \nu (A) \coloneq \int \1_A (x + y) \pi (\mathrm{d} x) \nu (\mathrm{d} y) .
\]
Thus, for all $n \in \mathbb{N}$ there exists a measure $\mu_{1 / n}$ such
that $\mu_1 = \mu_{1 / n}^{* n}$. Any $\mu$ which has this property is
called {\emph{infinitely divisible}}. So, if $X$ is a L{\'e}vy process, then
$X_1$ is infinitely divisible. Conversely, one can show that for any
infinitely divisible distribution $\mu$ there exists a unique (in law)
L{\'e}vy process $X$ with $\operatorname{law} (X_1) = \mu$. Therefore, L{\'e}vy
processes are in one-to-one correspondence with infinitely divisible
distributions.

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}[Difficult]
  Show that if $X$ is a centered L{\'e}vy process such that $X_1$ is bounded
  (i.e. there exists $C > 0$ such that a.s. $| X_1 | \leqslant C$), then $X_1
  = 0$ a.s.
  
  Hint: Consider $\operatorname{var} (X_1)$.
\end{exercise*}}}{\ }

The infinite divisibility imposes strong structural constraints on L{\'e}vy
processes, and every L{\'e}vy process can be characterized in terms of its
{\emph{L{\'e}vy-Khintchine representation}}:

\begin{theorem}[L{\'e}vy-Khintchine representation]
  If $X$ is a L{\'e}vy process, then the characteristic function of $X$
  satisfies
  \[ \mathbb{E} [e^{i u X_t}] = e^{t \psi (u)}, \qquad t \geqslant 0, u \in
     \mathbb{R}, \]
  where $\psi$ is of the form
  \[ \psi (u) = i a u - \frac{1}{2} \sigma^2 u^2 + \int_{\mathbb{R} \setminus
     \{ 0 \}} \left( e^{i u x} - 1 - i u x \1_{\{ | x | < 1 \}} \right) \nu
     (\mathrm{d} x), \]
  for $a \in \mathbb{R}$, $\sigma^2 \geqslant 0$, and for a measure $\nu$ on
  $\mathbb{R} \setminus \{ 0 \}$ such that $\int_{\mathbb{R} \setminus \{ 0
  \}} (1 \wedge | x |^2) \nu (\mathrm{d} x) < \infty$ (a so called {\emph{L{\'e}vy
  measure}}). We call $(a, \sigma^2, \nu)$ the {\emph{L{\'e}vy triple}} of
  $X$.
\end{theorem}

\begin{proof}
  See Klenke {\cite{Klenke2008}}, Theorem~16.17.
\end{proof}

\begin{remark}
  Without further explanation, this result is not very interesting. But it has
  a neat probabilistic interpretation: Let $X$ be a L{\'e}vy process with
  characteristic function $\mathbb{E} [e^{i u X_t}] = e^{t \psi (u)}$ for
  \[ \psi (u) = i a u - \frac{1}{2} \sigma^2 u^2 + \int_{\mathbb{R} \setminus
     \{ 0 \}} \left( e^{i u x} - 1 - i u x \1_{\{ | x | < 1 \}} \right) \nu
     (\mathrm{d} x) . \]
  Then we can decompose $X$ into a sum of three independent processes, $X =
  X^{(1)} + X^{(2)} + X^{(3)}$, where
  \begin{itemize}
    \item $X^{(1)}_t = a t$;
    
    \item $X^{(2)}_t = \sigma B_t$, for a Brownian motion $B$;
    
    \item $X^{(3)}_t$ is a ``jump process'', with jumps determined by the
    L{\'e}vy measure $\nu$.
  \end{itemize}
\end{remark}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Show that if $\nu = 0$ and thus $X^{(3)} \equiv 0$, then for $X^{(1)}_t = a
  t$ and $X^{(2)}_t = \sigma B_t$ we get the claimed form of the
  characteristic function.
\end{exercise*}}}{}

Since $\nu$ describes jumps (namely, points where jump discontinuities arise
in the map $t \mapsto X_t$), this implies that the Brownian motion is the only
centered and continuous L{\'e}vy process (up to constant multiples).

\begin{example}[Pre-Poisson process]
  Let $X$ be a L{\'e}vy process such that for $\lambda > 0$:
  \[ \psi (u) = \lambda (e^{i u} - 1), \]
  i.e. $a = \sigma^2 = 0$ and $\nu = \lambda \delta_1$ is a multiple of the
  Dirac measure in $x = 1$. Then
  \[ \mathbb{E} [e^{i u X_t}] = e^{\lambda t (e^{i u} - 1)}, \]
  which is the characteristic function of a Poisson distribution with
  parameter $\lambda t$. We call this process the {\emph{pre-Poisson process
  (with intensity $\lambda$)}}.
  
  \
  
  {\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
    \textbf{Poisson distribution:} Recall that a random variable $Y$ with
    values in $\mathbb{N}_0$ has a Poisson distribution with parameter
    $\lambda \geqslant 0$ if $\mathbb{P} (Y = k) = \frac{\lambda^k}{k!} e^{-
    \lambda}$, $k \in \mathbb{N}_0$. We write $Y \sim \operatorname{Poi} (\lambda)$.
  \end{tabularx}
  
  \ 
\end{example}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Show that the Poisson distribution with parameter $\lambda \geqslant 0$ has
  the characteristic function $\mathbb{E} [e^{i u X}] = \exp (\lambda (e^{i u}
  - 1))$.
\end{exercise*}}}{}

\begin{remark}
  \label{rmk:poisson-alternative}Alternatively, we can describe the
  pre-Poisson process as follows: A stochastic process $(N_t)_{t \geqslant 0}$
  is a pre-Poisson process with intensity $\lambda > 0$ if and only if the
  following conditions are satisfied:
  \begin{enumerate}
    \item $N_0 = 0$ almost surely;
    
    \item for all $0 \leqslant s < t$ the random variable $N_t - N_s$ is
    independent of $(N_r)_{0 \leqslant r \leqslant s}$;
    
    \item for all $0 \leqslant s < t$ we have $N_t - N_s \sim \operatorname{Poi}
    (\lambda (t - s))$.
  \end{enumerate}
  \tmcolor{blue}{\begin{exercise*}
    Convince yourself of this!
  \end{exercise*}}
\end{remark}

Hopefully it will not be a surprise to you at this point that the Poisson
process (without ``pre-'') will be a pre-Poisson process with nice
trajectories. But note that the Poisson distribution takes values in
$\mathbb{N}_0$, so the Poisson process cannot be continuous. To formulate its
path properties, we introduce the following notation for $f : \mathbb{R}_+
\rightarrow \mathbb{R}$:
\[ f (t +) \coloneq \lim_{s \downarrow t} f (s) \coloneq
   \lim_{\tmscript{\begin{array}{c}
     s \rightarrow t\\
     s > t
   \end{array}}} f (s), \qquad f (t -) \coloneq \lim_{s \uparrow t} f (s)
   \coloneq \lim_{\tmscript{\begin{array}{c}
     s \rightarrow t\\
     s < t
   \end{array}}} f (s), \]
and similarly $\limsup_{s \downarrow t} f (s)$, $\liminf_{s \uparrow t} f
(s)$, etc. Recall that a function $f$ is called {\emph{right-continuous}}
(resp. {\emph{left-continuous}}) if $f (t +) = f (t)$ for all $t \geqslant 0$
(resp. $f (t -) = f (t)$ for all $t > 0$).

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Which of these functions is left- and/or right-continuous?
  \begin{enumerate}
    \item $f = \1_{[1, \infty)}$;
    
    \item $f = \1_{(1, \infty)}$;
    
    \item $f = \1_{\{ 1 \}}$;
    
    \item $f (t) = \sin \left( \frac{1}{1 - t} \right)$, $t \in [0, 1)$, and
    $f (t) = 0$ for $t \geqslant 1$.
  \end{enumerate}
\end{exercise*}}}{\ }

\begin{definition}[C{\`a}dl{\`a}g]
  A function $f : \mathbb{R}_+ \rightarrow \mathbb{R}$ is called
  {\emph{c{\`a}dl{\`a}g}} if it is right-continuous and at every $t > 0$ the
  limit $f (t -)$ exists (but might not be equal to $f (t)$). A c{\`a}dl{\`a}g
  function $t \mapsto f (t)$ has a {\emph{jump}} at $t$ if
  \[ \Delta f (t) \coloneq f (t) - f (t -) \neq 0. \]
  The acronym c{\`a}dl{\`a}g comes from French and stands for ``continue {\`a}
  droite, limite {\`a} gauche'', that is ``continuous from the right, limits
  from the left''.
\end{definition}

\begin{lemma}
  Let $f : \mathbb{R}_+ \rightarrow \mathbb{R}$ be c{\`a}dl{\`a}g; then $f$
  has at most countably many jumps, i.e. there exist at most countably many
  $\{ t_n \}_{n \in \mathbb{N}}$ such that $\Delta f (t_n) > 0$.
\end{lemma}

\begin{proof}
  Exercise Sheet 3.
\end{proof}

\begin{definition}[C{\`a}dl{\`a}g process, Poisson process]
  \begin{enumerate}
    \item We say that a stochastic process $X = (X_t)_{t \geqslant 0}$ with
    values in $\mathbb{R}^d$ is {\emph{c{\`a}dl{\`a}g}} if all of its
    trajectories are {\emph{c{\`a}dl{\`a}g}}, i.e. $t \mapsto X_t (\omega)$ is
    {\emph{c{\`a}dl{\`a}g}} for all $\omega \in \Omega$.
    
    \item A c{\`a}dl{\`a}g pre-Poisson process is called a {\emph{Poisson
    process}}.
  \end{enumerate}
\end{definition}

To get a more intuitive understanding of the Poisson process, we use the
following explicit construction:

\begin{theorem}
  \label{thm:construction.poisson}Let $(T_n)_{n \in \mathbb{N}}$ be an i.i.d.
  sequence of exponentially distributed random variables with parameter
  $\lambda > 0$. We define $S_n \coloneq T_1 + \cdots + T_n$ and
  \[ N_t \coloneq \max \{ n : S_n \leqslant t \}, \qquad t \geqslant 0. \]
  Then $(N_t)_{t \geqslant 0}$ is (indistinguishable from) a Poisson process
  with intensity $\lambda$.
\end{theorem}

{\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
  Recall that the \textbf{exponential distribution} with parameter $\lambda
  > 0$ has density $\1_{\mathbb{R}_+} (x) \lambda e^{- \lambda x}$.
\end{tabularx}

\begin{figure}[h]
  \resizebox{0.5\columnwidth}{0.35\columnwidth}{\includegraphics{StochAna-ongoing-11.pdf}}
  \caption{Poisson process constructed from $(T_n)_{n \geqslant 0}$.}
\end{figure}

Let us momentarily postpone the proof of
Theorem~\ref{thm:construction.poisson} and discuss the insight it provides on
the nature of the trajectories of $(N_t)_{t \geqslant 0}$ first.

The Poisson process is a ``counting process'' which is piecewise constant and
which jumps up by $1$ at random times $(S_n)_{n \in \mathbb{N}}$. The times
between the jumps are independent, and they follow an exponential distribution
with parameter $\lambda$.

The Poisson process is used to model the (cumulative) number of customers
arriving at a store, or the damage claims at an insurance, the number of
clicks of a Geiger counter (which corresponds to the number of decaying
atoms), or the number of meteorites hitting earth.

The Poisson process is in some sense ``the most elementary jump process'' and
almost all other pure jump processes can be constructed from it. On Sheet~3
you will construct a L{\'e}vy process with a general L{\'e}vy measure $\nu$,
provided that $\nu$ has finite mass ($\nu (\mathbb{R} \setminus \{ 0 \}) <
\infty$). Such a process is also called {\emph{compound Poisson process}},
because we can represent it as
\[ X_t = \sum_{k = 1}^{N_t} Y_k, \]
where $N = (N_t)_{t \geqslant 0}$ is a Poisson process with intensity $\lambda
= \nu (\mathbb{R} \setminus \{ 0 \})$, and $(Y_k)_{k \in \mathbb{N}}$ is
independent of $N$ and an i.i.d. sequence of random variables with
distribution $Y_k \sim \frac{\nu}{\nu (\mathbb{R} \setminus \{ 0 \})}$. It
follows from a computation that the L{\'e}vy triple of $X$ is $a = \int_{| x |
< 1} x \nu (\mathrm{d} x)$, $\sigma^2 = 0$, $\nu$.

\

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on October 31st}
  \hrulefill\hrulefill
\end{center}

\

One could give an alternative derivation of the Poisson process, where we
divide $\mathbb{R}_+$ in intervals of length $\frac{1}{n}$ and consider a
discrete time process which on each of these intervals jumps up by $1$ with a
small probability of order $\frac{\lambda}{n}$, independently of what happened
before. For $n \rightarrow \infty$, the finite-dimensional distributions of
this process converge to the finite-dimensional distributions of a Poisson
process with intensity $\lambda$ (this is sometimes referred to as the
{\emph{law of small numbers}}); more details on this construction might appear
later in the Exercise Sheets.

Hopefully, this makes it plausible why we can model the phenomena mentioned
above with a Poisson process: For example, each second there is a small
probability that a customer enters our store, and at first approximation we
can consider the different second-long intervals as independent.

We can now finally conclude this section with the

\begin{proof*}{Proof of Theorem~\ref{thm:construction.poisson}}
  We show that $N$ satisfies the properties of
  Remark~\ref{rmk:poisson-alternative}, and that it is almost surely
  c{\`a}dl{\`a}g.
  \begin{itemize}
    \item $N$ is almost surely c{\`a}dl{\`a}g: By definition, $N$ is
    c{\`a}dl{\`a}g on the set $ \{ \sup_n S_n = \infty \}$. But by
    $\sigma$-continuity we have
    \begin{eqnarray*}
      \mathbb{P} (\sup_n S_n < \infty) & = & \lim_{m \rightarrow \infty}
      \mathbb{P} (\sup_n S_n < m) \leqslant \lim_{m \rightarrow \infty}
      \lim_{n \rightarrow \infty} \mathbb{P} (S_n < m)\\
      & \leqslant & \lim_{m \rightarrow \infty} \lim_{n \rightarrow \infty}
      \mathbb{P} (\max_{k = 1, \ldots, n} T_n < m)\\
      & = & \lim_{m \rightarrow \infty} \lim_{n \rightarrow \infty}
      \mathbb{P} (T_1 < m)^n = 0,
    \end{eqnarray*}
    because $\mathbb{P} (T_1 < m) < 1$.
    
    \item We have $N_0 = 0$ by definition. So to verify the conditions of
    Remark~\ref{rmk:poisson-alternative} it suffices to show that for all $n
    \in \mathbb{N}$ and $0 = t_0 < t_1 < \cdots < t_n$ the random variables
    $(N_{t_1} - N_{t_0}, \ldots, N_{t_n} - N_{t_{n - 1}})$ are independent,
    and that $N_{t_{k + 1}} - N_{t_k} \sim \operatorname{Poi} (\lambda (t_{k + 1} -
    t_k))$. For simplicity we restrict our attention to the case $n = 2$. The
    general case can be handled by similar arguments, but the notation becomes
    much more tedious. We will show that for all $0 \leqslant s < t$ and all
    $k, \ell \in \mathbb{N}_0$
    \begin{equation}
      \mathbb{P} (N_s = k, N_t - N_s = \ell) = \frac{(\lambda s)^k}{k!} e^{-
      \lambda s} \frac{(\lambda (t - s))^{\ell}}{\ell !} e^{- \lambda (t - s)}
      . \label{eq:construct.poisson.proof1}
    \end{equation}
    By summing over $\ell \in \mathbb{N}_0$ respectively ${k \in \mathbb{N}_0}
    $ we see that $N_s \sim \operatorname{Poi} (\lambda s)$ and $N_t - N_s \sim
    \operatorname{Poi} (\lambda (t - s))$, and then that $N_s$ and $N_t - N_s$ are
    independent.
    
    To handle the computation, we need a bit of notation. Note that $(T_1,
    \ldots, T_{k + \ell + 1})$ has the density $\1_{\mathbb{R}_+^{k + \ell +
    1}} (x) \lambda^{k + \ell + 1} e^{- \lambda \Sigma_{k + \ell + 1} (x)}$
    with respect to Lebesgue measure on $\mathbb{R}^{k + \ell + 1}$, where for
    $n \leqslant m$ we define $\Sigma_n : \mathbb{R}^m \rightarrow \mathbb{R}$
    by
    \[ \Sigma_n (x) : = x_1 + \cdots + x_n . \]
    It will be also useful to exploit the following fact: it holds
    \begin{equation}
      \int_{\mathbb{R}_+^n} \1_{\{ \Sigma_n (x) \leqslant r \}} \mathrm{d} x =
      \int_{\mathbb{R}_+^n} \1_{\{ x_1 + \cdots + x_n \leqslant r \}} \mathrm{d} x
      = \frac{r^n}{n!} \quad \forall \, n \geqslant 1, \, r \in (0, + \infty)
      . \label{eq:construct.poisson.proof2}
    \end{equation}
    We postpone the verification of~\eqref{eq:construct.poisson.proof2} to the
    end of the proof.
    
    \item We start by considering the case $\ell = 0$. In this case
    
    \begin{align*}
      \mathbb{P} (N_s = k, N_t - N_s = 0) & = \, \mathbb{P} (N_s = k, N_t =
      N_s)\\
      & = \, \mathbb{P} (S_k \leqslant s < S_{k + 1}, S_k \leqslant t < S_{k
      + 1})\\
      & = \, \mathbb{P} (S_k \leqslant s, S_{k + 1} > t)\\
      & = \, \mathbb{P} (S_k \leqslant s, T_{k + 1} > t - S_k) .
    \end{align*}
    
    Since $T_{k + 1}$ is independent of $(T_1, \ldots, T_k)$, thus $S_k$, we
    can compute the above probability by first conditioning on $T_{k + 1}$ as
    \[ \mathbb{P} (S_k \leqslant s, T_{k + 1} > t) = \int_{\mathbb{R}^k_+}
       \1_{\{ \Sigma_k (x) \leqslant s \}} \lambda^k e^{- \lambda \Sigma_k
       (x)} \mathbb{P} (T_{k + 1} > t - \Sigma_k (x)) \mathrm{d} x ; \]
    here and below, we can always change the order of integration at will by
    virtue of Fubini's theorem, because all terms appearing are non-negative.
    Since $T_{k + 1}$ is exponentially distributed, $\mathbb{P} (T_{k + 1} >
    r) = e^{- \lambda r}$ for all $r \geqslant 0$ and so
    
    \begin{align*}
      \mathbb{P} (N_s = k, N_t - N_s = 0) & = \int_{\mathbb{R}^k_+} \1_{\{
      \Sigma_k (x) \leqslant s \}} \lambda^k e^{- \lambda \Sigma_k (x)} e^{-
      \lambda (t - \Sigma_k (x))} \mathrm{d} x\\
      & = \, \lambda^k e^{- \lambda t} \int_{\mathbb{R}^k_+} \1_{\{ \Sigma_k
      (x) \leqslant s \}} \mathrm{d} x\\
      & = \, \lambda^k e^{\lambda t}  \frac{s^k}{k!} = \frac{(\lambda
      s)^k}{k!} e^{- \lambda s}  \frac{(\lambda t)^0}{0!} e^{- \lambda (t -
      s)}
    \end{align*}
    
    proving~\eqref{eq:construct.poisson.proof1} in this case; in the
    intermediate passages, we applied~\eqref{eq:construct.poisson.proof2}.
    
    \item Next we deal with the case $\ell \geqslant 1$. We start by writing
    \begin{eqnarray*}
      \mathbb{P} (N_s = k, N_t - N_s = \ell) & = & \mathbb{P} (N_s = k, N_t =
      k + \ell)\\
      & = & \mathbb{P} (S_k \leqslant s < S_{k + 1}, S_{k + \ell} \leqslant t
      < S_{k + \ell + 1}) .
    \end{eqnarray*}
    Using the same notation for $\Sigma_k$ as before, and the density of
    $(T_1, \ldots, T_{k + \ell + 1})$, this leads to
    \begin{eqnarray*}
      &  & \mathbb{P} (S_k \leqslant s < S_{k + 1}, S_{k + \ell} \leqslant t
      < S_{k + \ell + 1})\\
      &  & \quad = \int_{\mathbb{R}^{k + \ell + 1}_+} \1_{\{ \Sigma_k (x)
      \leqslant s < \Sigma_{k + 1} (x) \}} \1_{\{ \Sigma_{k + \ell} (x)
      \leqslant t < \Sigma_{k + \ell + 1} (x) \}} \lambda^{k + \ell + 1} e^{-
      \lambda \Sigma_{k + \ell + 1} (x)} \mathrm{d} x.
    \end{eqnarray*}
    The expression is a bit more complicated than before, but we can proceed
    similarly. We start by integrating out $x_{k + \ell + 1}$. We apply the
    change of variables $z = \Sigma_{k + \ell + 1} (x)$ and obtain
    \begin{eqnarray*}
      \int_0^{\infty} \1_{\{ \Sigma_{k + \ell} (x) \leqslant t < \Sigma_{k +
      \ell + 1} (x) \}} \lambda e^{- \lambda \Sigma_{k + \ell + 1} (x)} \mathrm{d}
      x_{k + \ell + 1} & = & \int_{\Sigma_{k + \ell} (x)}^{\infty} \1_{\{
      \Sigma_{k + \ell} (x) \leqslant t < z \}} \lambda e^{- \lambda z} \mathrm{d}
      z\\
      & = & \1_{\{ \Sigma_{k + \ell} (x) \leqslant t \}} e^{- \lambda t},
    \end{eqnarray*}
    which leads to
    \begin{eqnarray*}
      &  & \int_{\mathbb{R}^{k + \ell + 1}_+} \1_{\{ \Sigma_k (x) \leqslant s
      < \Sigma_{k + 1} (x) \}} \1_{\{ \Sigma_{k + \ell} (x) \leqslant t <
      \Sigma_{k + \ell + 1} (x) \}} \lambda^{k + \ell + 1} e^{- \lambda
      \Sigma_{k + \ell + 1} (x)} \mathrm{d} x\\
      &  & \quad = \lambda^{k + \ell} e^{- \lambda t} \int_{\mathbb{R}^{k +
      \ell}_+} \1_{\{ \Sigma_k (x) \leqslant s < \Sigma_{k + 1} (x) \}} \1_{\{
      \Sigma_{k + \ell} (x) \leqslant t \}} \mathrm{d} x.
    \end{eqnarray*}
    Now we perform the change of variables $y_1 = \Sigma_{k + 1} (x) - s$,
    $y_2 = x_{k + 2}$, {\textdots}, $y_{\ell} = x_{k + \ell}$ and obtain
    \begin{eqnarray*}
      &  & \int_{\mathbb{R}^{k + \ell}_+} \1_{\{ \Sigma_k (x) \leqslant s <
      \Sigma_{k + 1} (x) \}} \1_{\{ \Sigma_{k + \ell} (x) \leqslant t \}}
      \mathrm{d} x\\
      &  & \qquad = \int_{\mathbb{R}^k_+} \1_{\{ \Sigma_k (x) \leqslant s \}}
      \left( \int_{\mathbb{R}^{\ell}_+} \1_{\{ y_1 + \cdots + y_{\ell}
      \leqslant t - s \}} \mathrm{d} y \right) \mathrm{d} x\\
      &  & \qquad = \, \frac{s^k}{k!} \cdot \frac{(t - s)^{\ell}}{\ell !},
    \end{eqnarray*}
    where in the last passage we
    used~\eqref{eq:construct.poisson.proof2}.\quad Altogether, we have shown
    that for $k \in \mathbb{N}_0$ and $\ell \in \mathbb{N}$,
    \[ \mathbb{P} (N_s = k, N_t - N_s = \ell) = \frac{s^k}{k!} \cdot \frac{(t
       - s)^{\ell}}{\ell !} \lambda^{k + \ell} e^{- \lambda t} =
       \frac{(\lambda s)^k}{k!} e^{- \lambda s} \cdot \frac{(\lambda (t -
       s))^{\ell}}{\ell !} e^{- \lambda (t - s)} ; \]
    namely,~\eqref{eq:construct.poisson.proof1} holds. Together with the
    previous case, this complete the verification
    of~\eqref{eq:construct.poisson.proof1} for any $k, \ell \in \mathbb{N}_0$.
    
    \item We finally prove~\eqref{eq:construct.poisson.proof2}. For $n = 1$ we
    have $\int_{\mathbb{R}_+^1} \1_{\{ x_1 \leqslant r \}} \mathrm{d} x = \int_0^r
    1 \mathrm{d} x_1 = r^1 / 1!$ and then by induction
    \begin{eqnarray*}
      \int_{\mathbb{R}_+^n} \1_{\{ x_1 + \cdots + x_n \leqslant r \}} \mathrm{d} x
      & = & \int_0^r \left( \int_{\mathbb{R}_+^{n - 1}} \1_{\{ x_1 + \cdots +
      x_{n - 1} \leqslant r - x_n \}} \mathrm{d} x_1 \cdots \mathrm{d} x_{n - 1}
      \right) \mathrm{d} x_n\\
      & = & \int_0^r \frac{(r - x_n)^{n - 1}}{(n - 1) !} \mathrm{d} x_n =
      \frac{r^n}{n!}
    \end{eqnarray*}
    which shows~\eqref{eq:construct.poisson.proof2}.
  \end{itemize}
\end{proof*}

[Comment: in Theorem~\ref{thm:construction.poisson we verified that
$N_t$ is a Poisson process ``by hand'', using elementary but lengthy
manipulations. There is an alternative more elegant approach, based on the
notion of {\emph{infinitesimal generator}} of the Markov process, but it is
outside the scope of these lectures; see Theorem~2.4.3
from~{\cite{Norris1998}} for more details.]}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Let $(N^1_t)_{t \geqslant 0}$ and $(N^2_t)_{t \geqslant 0}$ be independent
  Poisson processes with intensity $\lambda_1 > 0$ respectively $\lambda_2 >
  0$. Show that $N_t \coloneq N^1_t + N^2_t$, $t \geqslant 0$, is a Poisson
  process with intensity $\lambda_1 + \lambda_2$.
\end{exercise*}}}{\ }

\section{Filtrations and stopping times}

So far we have analysed Brownian motion as one of the most canonical examples
of: a) (continuous) Gaussian processes; b) L{\'e}vy processes. There are two
other fundamental categories of which Brownian motion is a prominent example,
which are respectively Markov processes and (continuous) martingales. In order
to introduce them, we first need to make a detour on the concept of
filtrations, stopping times and progressive processes.

\subsection{Filtrations and stopping times}

\begin{definition}[Filtration, right-continuous]
  \begin{enumerate}
    \item A {\emph{filtration}} is an increasing family $\mathbb{F}=
    (\mathcal{F}_t)_{t \geqslant 0}$ of sub sigma-algebras of $\mathcal{F}$,
    i.e. such that $\mathcal{F}_s \subset \mathcal{F}_t \subset \mathcal{F}$
    for all $0 \leqslant s \leqslant t$. We write
    \[ \mathcal{F}_{\infty} \coloneq \bigvee_{t \geqslant 0} \mathcal{F}_t =
       \sigma \left( \bigcup_{t \geqslant 0} \mathcal{F}_t \right), \qquad
       \mathcal{F}_{t +} \coloneq \bigcap_{s > t} \mathcal{F}_s, \qquad
       \operatorname{for} \tmop{any} t \geqslant 0. \]
    We call $(\Omega, \mathcal{F}, \mathbb{F}, \mathbb{P})$ a {\emph{filtered
    probability space}}.
    
    \item A filtration $\mathbb{F}$ is called {\emph{right-continuous}} if
    $\mathcal{F}_{t +} =\mathcal{F}_t$ for all $t \geqslant 0$. We write
    $\mathbb{F}^+ = (\mathcal{F}^+_t)_{t \geqslant 0}$ for the smallest
    right-continuous filtration containing $\mathbb{F}$, given by
    \[ \mathcal{F}^+_t \coloneq \bigcap_{s > t} \mathcal{F}_s =\mathcal{F}_{t
       +}, \qquad t \geqslant 0. \]
    Note that $(\mathbb{F}^+)^+ =\mathbb{F}^+$ for every filtration.
  \end{enumerate}
\end{definition}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Show the last statement.
\end{exercise*}}}{}

\

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on November 6}
  \hrulefill\hrulefill
\end{center}

\

\begin{definition}[Canonical/natural filtration]
  Let $(X_t)_{t \geqslant 0}$ be a stochastic process and set $\mathcal{F}_t
  \coloneq \sigma (X_s : s \leqslant t)$. In this case we write $\mathbb{F}^X
  \coloneq (\mathcal{F}_t^X)_{t \geqslant 0} \coloneq (\mathcal{F}_t)_{t
  \geqslant 0}$ and we call $\mathbb{F}^X$ the \tmtextit{{\emph{canonical
  filtration}}} (or {\emph{natural filtration}}) of $X$. We also
  write $\mathbb{F}^{X +} \coloneq (\mathbb{F}^X)^+$.
\end{definition}

Note that in general we can have $\mathbb{F}^{X +} \neq \mathbb{F}^X$, even if
$X$ is continuous and real-valued: for example
\[ A \coloneq \left\{ \omega : \lim_{h \downarrow 0} \frac{X_{t + h} (\omega) -
   X_t (\omega)}{h} \text{ exists} \right\} \in \mathcal{F}_t^{X +}, \]
but in general $A \nin \mathcal{F}^X_t$.

\begin{definition}[Adapted process]
  A stochastic process $(X_t)_{t \geqslant 0}$ is called {\emph{adapted}} to a
  given filtration $\mathbb{F}$ if $X_t$ is $\mathcal{F}_t$--measurable for
  all $t \geqslant 0$.
\end{definition}

Clearly, any process $X$ is adapted to its canonical filtration
$\mathbb{F}^X$.

\begin{definition}[Negligible sets, complete $\sigma$-algebra, completion]
  Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and let
  $\mathcal{G} \subset \mathcal{F}$ be a $\sigma$-algebra.
  \begin{enumerate}
    \item A set $B \subset \Omega$ is called {\emph{$\mathbb{P}$-negligible}}
    (with respect to $\mathcal{F}$), or simply {\emph{negligible}},
    if there exists $N \in \mathcal{F}$ with $\mathbb{P} (N) = 0$ such that $B
    \subset N$. We write $\mathcal{N}^{\mathbb{P}}$ for the
    $\mathbb{P}$-negligible sets.
    
    \item $\mathcal{G}$ is called {\emph{complete}} (with respect to
    $\mathcal{F}$) if $\mathcal{N}^{\mathbb{P}} \subset \mathcal{G}$.
    
    \item The {\emph{completion of $\mathcal{G}$}} (with respect to
    $\mathcal{F}$) is $\mathcal{G}^{\mathbb{P}} \coloneq \sigma (\mathcal{G}
    \cup \mathcal{N}^{\mathbb{P}}) .$
  \end{enumerate}
\end{definition}

\begin{remark}[Exercise, see also Durrett {\cite{Durrett2010}}, Theorem A.2.3]
  \label{rmk:completion}The completion $\mathcal{F}^{\mathbb{P}}$ of
  $\mathcal{F}$ is given by
  \[ \mathcal{F}^{\mathbb{P}} = \{ A \cup B : A \in \mathcal{F}, B \in
     \mathcal{N}^{\mathbb{P}} \} . \]
  Therefore, we can uniquely extend $\mathbb{P}$ from $\mathcal{F}$ to
  $\mathcal{F}^{\mathbb{P}}$ by setting
  \[ \mathbb{P} (A \cup B) =\mathbb{P} (A) . \]
\end{remark}

\begin{definition}[Complete filtration, usual conditions]
  Let $\mathbb{F}$ be a filtration.
  \begin{enumerate}
    \item $\mathbb{F}$ is called {\emph{complete}} if $\mathcal{F}_t$ is
    complete for all $t \geqslant 0$; equivalently, if $\mathcal{F}_0$ is
    complete.
    
    \item $\mathbb{F}$ satisfies the {\emph{usual conditions}} if it is
    right-continuous and complete.
  \end{enumerate}
\end{definition}

If $\mathbb{F}$ is a filtration, then
\[ \mathbb{F}^{+, \mathbb{P}} \coloneq (\mathbb{F}^{\mathbb{P}})^+ \]
is right-continuous and complete by construction. One can show that it is the
smallest filtration containing $\mathbb{F}$ that satisfies the usual
conditions. This is called the usual augmentation (or extension) of
a filtration. Here it is important that we first take the completion, and
after that we make the filtration right-continuous: if we took the opposite
order, then the resulting filtration $(\mathbb{F}^+)^{\mathbb{P}}$ might not
be right-continuous.

\begin{definition}[Stopping time, events determined until $\tau$]
  Let $\mathbb{F}$ be a filtration. An {\emph{$\mathbb{F}$-stopping time}} (or
  simply {\emph{stopping time}}, if there is no ambiguity about the
  filtration) is a map $\tau : \Omega \rightarrow [0, \infty]$ such that
  $\{\tau \leqslant t\} \in \mathcal{F}_t$ for all $t \geqslant 0$. If $\tau$
  is a $\mathbb{F}$-stopping time, then we write
  \begin{equation}
    \label{eq:FT definition} \mathcal{F}_{\tau} \coloneq \left\{ A \in
    \mathcal{F}: A \cap \{\tau \leqslant t\} \in \mathcal{F}_t \text{ for all
    } t \geqslant 0 \right\}
  \end{equation}
  for the $\sigma$-algebra of {\emph{events determined until $\tau$}}.
\end{definition}

Stopping times have many useful properties:

\begin{lemma}
  \label{lem:stopping-times}Let $\mathbb{F}$ be a filtration and let $\tau :
  \Omega \rightarrow [0, \infty]$.
  \begin{enumerate}
    \item If $\tau$ is a stopping time, then $\mathcal{F}_{\tau}$ is indeed a
    $\sigma$-algebra.
    
    \item If $\tau (\omega) = t$ for all $\omega$, where $t \in [0, \infty]$
    is fixed, then $\tau$ is a stopping time and $\mathcal{F}_t
    =\mathcal{F}_{\tau}$ where $\mathcal{F}_{\tau}$ is defined in~(\ref{eq:FT
    definition}). So our definitions are consistent.
    
    \item If $\tau$ is a stopping time, then so is $\tau + t$ for any $t \in
    [0, \infty]$; the same is not necessarily true for $\tau - t$. In
    particular, $\mathcal{F}_{\tau + t}$ is a $\sigma$-algebra for any $t
    \geqslant 0$ and we can define $\mathcal{F}_{\tau +} \coloneq \bigcap_{t >
    0} \mathcal{F}_{\tau + t}$.
    
    \item $\tau$ is an $\mathbb{F}^+$-stopping time if and only if $\{\tau <
    t\} \in \mathcal{F}_t$ for all $t > 0$.
    
    \item If $\tau$ is a stopping time, then $\tau$ is
    $\mathcal{F}_{\tau}$--measurable.
    
    \item If $\tau_1$, $\tau_2$ are stopping times with $\tau_1 (\omega)
    \leqslant \tau_2 (\omega)$ for all $\omega \in \Omega$, then
    $\mathcal{F}_{\tau_1} \subset \mathcal{F}_{\tau_2}$.
    
    \item If $\tau_1$, $\tau_2$ are stopping times, then $\tau_1 \vee \tau_2$
    and $\tau_1 \wedge \tau_2$ are stopping times and
    \[ \mathcal{F}_{\tau_1 \wedge \tau_2} =\mathcal{F}_{\tau_1} \cap
       \mathcal{F}_{\tau_2} . \]
  \end{enumerate}
\end{lemma}

\begin{proof}
  Parts~i.}, \textit{ii.}, \textit{iii.} and \tmtextit{v. are
  part of Exercise Sheet~4. Let us prove the rest.
  
  iv.} If $\{ \tau < r \} \in \mathcal{F_r$ for all $r$, then
  \[ \{ \tau \leqslant t \} = \bigcap_{\tmscript{\begin{array}{c}
       n \in \mathbb{N}
     \end{array}}} \left\{ \tau < t + \frac{1}{n} \right\} \subset \bigcap_{s
     > t} \mathcal{F}_s =\mathcal{F}_{t +}, \]
  so $\tau$ is an $\mathbb{F}^+$-stopping time. If $\tau$ is an
  $\mathbb{F}^+$-stopping time, then
  \[ \{ \tau < t \} = \bigcup_{\tmscript{\begin{array}{l}
       n \in \mathbb{N}
     \end{array}}} \underbrace{\left\{ \tau \leqslant t - \frac{1}{n}
     \right\}}_{\in \mathcal{F}^+_{t - 1 / n} \subset \mathcal{F}_t} \in
     \mathcal{F}_t . \]
  
  
  vi.} Let $A \in \mathcal{F}_{\tau_1$ and $t \geqslant 0$. Then $A
  \in \mathcal{F}$ and since $\{ \tau_1 \leqslant t \} \supset \{ \tau_2
  \leqslant t \}$, we have
  \[ A \cap \{ \tau_2 \leqslant t \} = \underbrace{(A \cap \{ \tau_1 \leqslant
     t \})}_{\in \mathcal{F}_t} \cap \{ \tau_2 \leqslant t \} \in
     \mathcal{F}_t . \]
  therefore $A \in \mathcal{F}_{\tau_2}$ as well.
  
  vii. For all $t \geqslant 0$, we have:
  \[ \{ \tau_1 \vee \tau_2 \leqslant t \} = \{ \tau_1 \leqslant t \} \cap \{
     \tau_2 \leqslant t \} \in \mathcal{F}_t, \]
  so $\tau_1 \vee \tau_2$ is a stopping time. Similarly,
  \[ \{ \tau_1 \wedge \tau_2 \leqslant t \} = \{ \tau_1 \leqslant t \} \cup \{
     \tau_2 \leqslant t \} \in \mathcal{F}_t, \]
  so $\tau_1 \wedge \tau_2$ is a stopping time.
  
  Since $\tau_1 \wedge \tau_2 \leqslant \tau_i$ for $i = 1, 2$, by
  vi.} we know that $\mathcal{F}_{\tau_1 \wedge \tau_2 \subset
  \mathcal{F}_{\tau_1} \cap \mathcal{F}_{\tau_2}$. Conversely, let $A \in
  \mathcal{F}_{\tau_1} \cap \mathcal{F}_{\tau_2}$. Then $A \in \mathcal{F}$
  and
  \[ A \cap \{\tau_1 \wedge \tau_2 \leqslant t\} = (A \cap \{\tau_1 \leqslant
     t\}) \cup (A \cap \{\tau_2 \leqslant t\}) \in \mathcal{F}_t \]
  and thus $A \in \mathcal{F}_{\tau_1 \wedge \tau_2}$.
\end{proof}

\

The most important examples of stopping times are so called hitting times:

\begin{definition}[Entry/hitting time]
  Let $X = (X_t)_{t \geqslant 0}$ be a stochastic process taking values in a
  measurable space $(S, \mathcal{S})$. For $A \in \mathcal{S}$, we define the
  {\emph{entry time}}, or {\emph{hitting time}} of $X$ into $A$, as
  \[ \tau_A (\omega) \coloneq \inf \{t \geqslant 0 : X_t (\omega) \in A\}, \]
  where we adopt the standard convetion $\inf \varnothing = \infty$.
\end{definition}

If $X$ is adapted to $\mathbb{F}$, then we would expect that by knowing the
trajectory of $X$ until time $t \geqslant 0$, we can decide whether $X$
entered $A$ strictly before $t$:
\[ \{\tau_A < t\} = \bigcup_{s < t} \{X_s \in A\} . \]
on the other hand, note that e.g. for an open set $A$, it is intuitively clear
that in general we can only decide if $\tau_A \leqslant t$ if we can ``peak a
bit into the future''. So one might hope that
\[ \{\tau_A \leqslant t\} = \bigcap_{\varepsilon > 0} \{\tau_A < t +
   \varepsilon\} = \bigcap_{\varepsilon > 0} \bigcup_{s < t + \varepsilon}
   \{X_s \in A\} \in \mathbb{F}^+ \]
and so that $\tau_A$ is an $\mathbb{F}^+$-stopping time. But there is a
problem with these arguments: While $\{X_s \in A\} \in \mathcal{F}_s$, our
descriptions of $\{\tau_A < t\}$ and $\{\tau_A \leqslant t\}$ involve unions
of uncountably many events, so a priori these sets are not in $\mathcal{F}_t$
or $\mathcal{F}_{t +}$. We could only deduce that $\tau_A$ is a stopping time
or an $\mathbb{F}^+$-stopping time if we were somehow able to reduce to
countably many set operations. Under suitable conditions on $A$ and $X$, this
is possible:

\begin{proposition}
  \label{prop:simple stopping times}Let $(S, d)$ be a metric space and let $X$
  be a stochastic process with values in $S$ which is adapted to the
  filtration $\mathbb{F}$.
  \begin{enumerate}
    \item If $A \subset S$ is open and $X$ is right-continuous or
    left-continuous, then $\tau_A$ is an $\mathbb{F}^+$\mbox{-}stopping time.
    
    \item If $A \subset S$ is closed and $X$ is continuous, then $\tau_A$ is
    an $\mathbb{F}$-stopping time.
  \end{enumerate}
\end{proposition}

\begin{proof}
  
  \begin{enumerate}
    \item If $A$ is open and $X$ is left- or right-continuous, we have
    \[ \{\tau_A < t\} = \bigcup_{s \in \mathbb{Q} \cap [0, t)} \{X_s \in A\}
       \in \mathcal{F}_t, \]
    so by Lemma~\ref{lem:stopping-times} we get that $\tau_A$ is an
    $\mathbb{F}^+$-stopping time.
    
    \item We get from the continuity of $X$ and closedness of $A$ that infima
    are always realized as minima, so that
    \[ \{\tau_A \leqslant t\} = \{ \min_{s \in [0, t]} d (X_s, A) = 0 \} = \{
       \inf_{s \in \mathbb{Q} \cap [0, t]} d (X_s, A) = 0 \} \in
       \mathcal{F}_t, \]
    where we wrote $d (x, A) = \inf \{d (x, a) : a \in A\}$.
  \end{enumerate}
\end{proof}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Let $X$ be an adapted, real-valued, increasing process, i.e. such that $t
  \mapsto X_t (\omega)$ is (not necessarily strictly) increasing for all
  $\omega \in \Omega$. Show that $\tau_a \coloneq \inf \{ t \geqslant 0 : X_t
  \geqslant a \}$ is an $\mathbb{F}^+$-stopping time for all $a \in
  \mathbb{R}$. If $X$ is additionally right-continuous, then $\tau_a$ is even
  an $\mathbb{F}$-stopping time.
\end{exercise*}}}{\ }

\subsection{Progressively measurable processes}

We discussed that entry times for (one-sided) continuous and adapted
stochastic processes are stopping times. Sometimes the assumption of path
continuity is too much, but adaptedness gives us no control at all about the
trajectories. The notion of progressive measurability answer this issue: it is
stronger than adaptedness and for example (almost) sufficient for a process to
serve as a {\emph{stochastic integrand}} (up to additional technical
conditions, as we will see later), but at the same time much less restrictive
than continuity of trajectories.

\

In the following, we are given a filterered probability space $(\Omega,
\mathcal{F}, \mathbb{F}, \mathbb{P})$ and another measurable space $(S,
\mathcal{S})$.

\begin{definition}[(Progressively) measurable processes]
  \label{defn:progressively.measurable}A stochastic process $X = (X_t)_{t
  \geqslant 0}$ taking values in $(S, \mathcal{S})$ is called
  \begin{enumerate}
    \item {\emph{measurable}} if the map
    \[ \Omega \times \mathbb{R}_+ \ni (\omega, t) \mapsto X_t (\omega) \in S
    \]
    is $(\mathcal{F} \otimes \mathcal{B}(\mathbb{R}_+),
    \mathcal{S})$--measurable;
    
    \item {\emph{progressive}} (or {\emph{progressively measurable}}) if for
    any $t \geqslant 0$, the map
    \[ \Omega \times [0, t] \ni (\omega, s) \mapsto X_s (\omega) \in S \]
    is $(\mathcal{F}_t \otimes \mathcal{B}([0, t]), \mathcal{S})$--measurable.
  \end{enumerate}
\end{definition}

\begin{remark}
  \label{rem:progressive.sets}We can define the $\sigma$-algebra of
  {\emph{progressive sets}} by
  \[ \operatorname{Prog} = \left\{ A \in \mathcal{F} \otimes \mathcal{B}
     (\mathbb{R}_+) \, : \, A \cap (\Omega \times [0, t]) \in \mathcal{F}_t
     \otimes \mathcal{B} ([0, t]) \right\} ; \]
  notice that $A \in \operatorname{Prog}$ if and only if $\1_A$ is
  progressive. It can be shown that $X : \Omega \times \mathbb{R}_+
  \rightarrow S$ is progressively measurable if and only if it is
  $(\operatorname{Prog}, \mathcal{S})$-measurable; in other words, progressive
  measurability amounts to measurability w.r.t. the $\sigma$-algebra of
  progressive sets.
  
  In the case when $(S, \mathcal{S}) = (\mathbb{R}, \mathcal{B}
  (\mathbb{R}))$, this fact has many useful consequences:
  \begin{itemize}
    \item If $X$ and $Y$ are progressive, so are $X + Y$ and $X \cdot Y$;
    
    \item If $(X^n)_n$ is a sequence of progressive processes, then $\limsup_n
    X^n$ and $\liminf_n X^n$ are still progressive; in particular, whenever it
    exists, $X_t (\omega) \coloneq \lim_{n \rightarrow \infty} X^n (t, \omega)$
    is progressive.
  \end{itemize}
\end{remark}

\tmcolor{blue}{\begin{exercise*}
  Check that $\operatorname{Prog}$ is a $\sigma$-algebra.
\end{exercise*}}

\begin{example}
  If $0 \leqslant s < u$ and $Y \in \mathcal{F}_s$, then the process
  \begin{equation}
    X_t (\omega) = Y (\omega) \1_{[s, u)} (t)
    \label{eq:basic.predictable}
  \end{equation}
  is progressive; similarly for $\tilde{X}_t (\omega) = Y (\omega)
  \1_{\{ s \}} (t)$.
\end{example}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Show that the process defined in~\eqref{eq:basic.predictable} is
  progressive.
\end{exercise*}}}{\ }

\begin{lemma}
  \label{lem:progr mb trajectories}Let $(X_t)_{t \geqslant 0}$ be a stochastic
  process taking values in $(S, \mathcal{S})$.
  \begin{enumerate}
    \item If $X$ is measurable, then the map $t \mapsto X_t (\omega)$ is
    $(\mathcal{B}(\mathbb{R}_+), \mathcal{S})$--measurable for all $\omega \in
    \Omega$.
    
    \item If $X$ is progressive, then it is measurable and
    $\mathbb{F}$-adapted.
    
    \item If $S$ is a metric space, $\mathcal{S}=\mathcal{B} (S)$ and $X$ is
    right-continuous (or left-continuous) and adapted, then $X$ is
    progressive.
  \end{enumerate}
\end{lemma}

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on November 7}
  \hrulefill\hrulefill
\end{center}

\begin{proof}
  \textbf{(The proofs of i. and ii. were skipped in the lecture in the
  interest of time, but for those interested they are included here)}
  \begin{enumerate}
    \item The statement is in fact part of Fubini theorem, or if you prefer
    the fundamental property of product $\sigma$-algebras like $\mathcal{F}
    \otimes \mathcal{B} (\mathbb{R}_+)$ are well-behaved under sections; a
    self-contained proof can be given by means of the monotone class theorem
    (Theorem~\ref{thm:monotone.class1}) applied with the $\pi$-system
    $\mathcal{E} = \{ A \times B : A \in \mathcal{F}, B \in \mathcal{B}
    (\mathbb{R}_+) \}$.
    
    \item It is clear that $X$ is measurable. To see that $X$ is adapted, note
    that for $t \ge 0$, $\Gamma \in \mathcal{S}$ we have
    \[ \{\omega : X_t (\omega) \in \Gamma\} = \{\omega : (\omega, t) \in X^{-
       1} (\Gamma)\}, \]
    where we interpret $X$ as a map from $\Omega \times [0, t]$ to
    $\mathcal{S}$. By assumption we have $B = X^{- 1} (\Gamma) \in
    \mathcal{F}_t \otimes \mathcal{B} ([0, t])$, and therefore the $t$-section
    $\{\omega : (\omega, t) \in B\}$ is in $\mathcal{F}_t$.
    
    \item Let $X$ be right-continuous and fix $t \geqslant 0$. For $n \in
    \mathbb{N}$, define the processes
    \[ X^n : \Omega \times [0, t] \rightarrow S, \qquad X^n_s = \sum_{k =
       0}^{n - 1} \1_{\left[ \frac{k}{n} t, \frac{k + 1}{n} t
       \right)} (s) X_{\frac{k + 1}{n} t} +\1_{\{ t \}} (s) X_t . \]
    Since $X$ is right-continuous, we have $\lim_{n \rightarrow \infty} X^n_s
    (\omega) = X_s (\omega)$ for all $s \in [0, t]$ and all $\omega \in
    \Omega$; so it suffices to show that $X^n$ is $\mathcal{F}_t \otimes
    \mathcal{B} ([0, t])$--measurable for all $n$. Since $X$ is adapted,
    $X_{(k + 1) t / n}$ is $\mathcal{F}_t$--measurable and so $\1_{[k
    t / n, (k + 1) t / n)} (s) {X_{(k + 1) t / n}} $ is $\mathcal{F}_t \otimes
    \mathcal{B} ([0, t])$--measurable; since this property is preserved under
    summation, we conclude that $X^n$ is $\mathcal{F}_t \otimes \mathcal{B}
    ([0, t])$--measurable.
    
    If $X$ is left-continuous, we similarly define $X^n$ in a discrete way by
    approximating $X$ from the left.
  \end{enumerate}
\end{proof}

Lemma~\ref{lem:progr mb trajectories} indicates why progressive measurability
is a useful property. For instance, it follows by similar arguments that if
$X$ is a progressive and bounded process (in the sense that there exists a
constant $C > 0$ such that $| X_t (\omega) | \leqslant C$ for all $(t,
\omega)$), then by the measurability of $t \mapsto X_t (\omega)$ we can
construct the time integral $Y_t (\omega) = \int_0^t X_s (\omega) \mathrm{d} s$;
it's not too hard to see that the resulting process $(Y_t)_{t \geqslant 0}$ is
continuous and $\mathbb{F}$-adapted, therefore by Lemma~\ref{lem:progr mb
trajectories} it is progressive. In particular, under mild assumptions,
progressive processes are closed under the operation of integration in time.
With a bit of work it can be also shown that, if $X$ is progressive, so is the
running maximum $X^{*}_t \coloneq \sup_{s \leqslant t} X_t$.

\begin{remark}
  Due to continuity of its trajectories, it follows from Lemma~\ref{lem:progr
  mb trajectories} that Brownian motion $(B_t)_{t \geqslant 0}$ is progressive
  (w.r.t. its natural filtration), and so in particular it is $(\mathcal{F}
  \otimes \mathcal{B}(\mathbb{R}_+), \mathbb{R})$--measurable. A similar
  argument applies to the Poisson process $(N_t)_{t \geqslant 0}$.
\end{remark}

{\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
  \textbf{Existence of (progressively) measurable modifications:} In the
  lectures, Lemma~\ref{lem:progr mb trajectories} will always suffice for our
  purposes. The following discussion was not presented in details in the
  lectures and is not examinable; it is a bit more technical in nature, but
  useful to get a more complete picture.
  
  We have seen before that Kolmogorov's continuity criterion provides
  sufficient conditions for the existence of a continuous modification, and at
  the same time there are stochastic processes to which it does not apply
  (e.g. Poisson) for which we can still have c{\`a}dl{\`a}g trajectories. It
  makes sense to wonder whether there are other abstract results guaranteeing
  the existence of measurable modifications. This is indeed the case, and the
  standard requirement in the literature is that $(X_t)_{t \geqslant 0}$ is
  {\emph{stochastically continuous}}, namely that $X_{t + \varepsilon}$
  converges in probability to $X_t$ whenever $\varepsilon \rightarrow 0$, for
  all $t \geqslant 0$; moreover, if $(X_t)_{t \geqslant 0}$ is
  $\mathbb{F}$-adapted and stochastically continuous, then it admits a
  {\emph{progressively measurable modification}} $(\tilde{X}_t)_{t \geqslant
  0}$, see Propositions~3.2 and~3.6-3.7 from~{\cite{DaPrato2014}}.
  
  Stochastic continuity is sufficient but not necessary for the existence of a
  measurable modification; the latter instead is equivalent to ``stochastic
  quasi-continuity'', see the recent~{\cite{DiNunno2001}}. Moreover, if
  $(X_t)_{t \geqslant 0}$ is a measurable, $\mathbb{F}$-adapted process, a
  classical result ensures the existence of a progressively measurable
  modification $(\tilde{X}_t)_{t \geqslant 0}$, see Theorem~IV.30
  from~{\cite{Dellacherie1978}}; the standard proof however is very demanding,
  see the recent~{\cite{OndSei2013}} for a more elementary one. Notice that,
  if we start with an adapted continuous process $(X_t)_{t \geqslant 0}$,
  there is no guarantee that the abstract modification $(\tilde{X}_t)_{t
  \geqslant 0}$ obtained in this way will be still continuous; thus in this
  case we are better off applying Lemma~\ref{lem:progr mb trajectories}
  anyway.
\end{tabularx}

\

The interest in stopping times often comes from looking at ``stopped
processes'', and in particular at computing the statistics of the process
$(X_t)_{t \geqslant 0}$ exactly when it is evaluated at the random time
$\tau$. Namely, we are interested in the map $\omega \mapsto X_{\tau} (\omega)
\coloneq X_{\tau (\omega)} (\omega)$ for a stopping time $\tau$. Since $\tau
(\omega)$ may be infinite, this map may not be defined for all $\omega$. So as
a convention, we introduce a ``cemetery state'' $\Delta \nin S$ and set
\[ X_{\tau} (\omega) \coloneq \left\{ \begin{array}{ll}
     X_{\tau (\omega)} (\omega) \hspace{1.2em} & \operatorname{if} \quad \tau (\omega)
     < \infty,\\
     \Delta & \operatorname{if} \quad \tau (\omega) = \infty .
   \end{array} \right. \]
On $S \cup \{ \Delta \}$, we consider the sigma algebra $\mathcal{S} \cup \{ A
\cup \{ \Delta \} : A \in \mathcal{S} \}$.

\begin{lemma}
  \label{lem:progressively measurable in stopping time}Let $X$ be progressive
  and let $\tau$ be a stopping time. Then $X_{\tau}$ is
  $\mathcal{F}_{\tau}$--measurable.
\end{lemma}

\begin{proof}
  We first show that $\{\omega : \tau (\omega) \leqslant t, X_{\tau} (\omega)
  \in A\} \in \mathcal{F}_t$ for all $A \in \mathcal{S}$ and $t \geqslant 0$.
  We introduce
  \[ \Phi : \{\tau \leqslant t\} \rightarrow \Omega \times [0, t]  \qquad \Phi
     (\omega) = (\omega, \tau (\omega)), \]
  which is $(\mathcal{F}_t \cap \{\tau \leqslant t\}, \mathcal{F}_t \otimes
  \mathcal{B}([0, t]))$--measurable, where
  \[ \mathcal{F}_t \cap \{\tau \leqslant t\} = \{A \cap \{\tau \leqslant t\}:
     A \in \mathcal{F}_t \} \subset \mathcal{F}_t . \]
  We also introduce
  \[ \Psi : \Omega \times [0, t] \rightarrow S, \qquad \Psi (\omega, s) = X_s
     (\omega), \]
  which by assumption is $(\mathcal{F}_t \otimes \mathcal{B}([0, t]),
  \mathcal{S})$--measurable.
  
  So $X_{\tau} |_{\{\tau \leqslant t\}}$ is a composition of measurable maps,
  \[ X_{\tau} |_{\{\tau \leqslant t\}} = \Psi \circ \Phi, \]
  and thus it is $(\mathcal{F}_t \cap \{\tau \leqslant t\},
  \mathcal{S})$--measurable. Therefore,
  \[ \{\omega : \tau (\omega) \leqslant t, X_{\tau} (\omega) \in A\} =
     \{\omega \in \{\tau \leqslant t\}: X_{\tau} (\omega) \in A\} \in
     \mathcal{F}_t \cap \{\tau \leqslant t\} \subset \mathcal{F}_t . \]
  It remains to show that $\{ X_{\tau} \in A \}$ is $\mathcal{F}$-measurable
  for all $A \in \mathcal{S} \cup \{ B \cup \{ \Delta \} : B \in \mathcal{S}
  \}$. For $A \in \mathcal{S}$, by the preceding we have
  \[ \{ X_{\tau} \in A \} = \{ X_{\tau} \in A, \tau < \infty \} = \bigcup_{n
     \in \mathbb{N}} \underbrace{\{ X_{\tau} \in A, \tau \leqslant n \}}_{\in
     \mathcal{F}_n} \in \mathcal{F}. \]
  For $A = B \cup \{ \Delta \}$ we have
  \[ \{ X_{\tau} \in A \} = \{ X_{\tau} \in B, \tau < \infty \} \cup \{ \tau =
     \infty \} \in \mathcal{F}. \]
\end{proof}

As a consequence of Lemma~\ref{lem:progressively measurable in stopping time},
we can deduce that stopped progressive processes are still
progressive.

\begin{lemma}
  Let $X$ be progressive and $\tau$ be a stopping time. Then the
  {\emph{stopped process}}
  \[ X^{\tau}_t (\omega) \coloneq X_{t \wedge \tau (\omega)} (\omega), \]
  usually abbreviated as $X^{\tau}_t = X_{t \wedge \tau}$, is also a
  progressive process.
\end{lemma}

\begin{proof}
  See Exercise Sheet~4.
\end{proof}

Another nice property of progressive processes is that, under strong
assumptions on the filtration, all entry times are stopping times:

\begin{theorem}[Debut theorem]
  \label{thm:Debut theorem}Let $\mathbb{F}$ be a filtration satisfying the
  usual conditions, let $X$ be $\mathbb{F}$-progressive with values in $(S,
  \mathcal{S})$, and let $A \in \mathcal{S}$. Then the entry time $\tau_A$ is
  a stopping time.
\end{theorem}

\begin{proof}
  We do not prove this result here. It relies on a deep theorem from measure
  theory, the so called Section Theorem. For a proof see
  Dellacherie-Meyer {\cite{Dellacherie1978}}, Theorem IV.50, or Revuz-Yor
  {\cite{Revuz1999}}, Theorem I.4.15.
\end{proof}

An alternative way of stating the Debut theorem is as follows: Let $X$ be a
progressively measurable process in an arbitrary filtration (not necessarily
satisfying the usual conditions) and let $A \in \mathcal{S}$. Then $\tau_A$ is
a stopping time with respect to $\mathbb{F}^{+, \mathbb{P}}$, no matter which
probability measure $\mathbb{P}$ we choose for completion. This points to the
role played by so called ``universal completions'' of filtrations.

\subsection{Applications to Brownian motion}

\begin{definition}[$d$-dimensional Brownian motion, $\mathbb{F}$-Brownian
motion]
  Let $B = (B^1, \ldots, B^d)$ be a stochastic process.
  \begin{enumerate}
    \item $B$ is called a {\emph{$d$-dimensional Brownian motion}} if the
    $B^j$, $j = 1, \ldots, d$, are independent (1-dimensional) Brownian
    motions.
    
    \item Let $B$ be a $d$-dimensional Brownian motion and let $\mathbb{F}$ be
    a filtration. $B$ is called a ($d$-dimensional) $\mathbb{F}$-Brownian
    motion if it is adapted to $\mathbb{F}$ and if for all $t \geqslant 0$ the
    process $(B_{t + s} - B_t)_{s \geqslant 0}$ is independent of
    $\mathcal{F}_t$.
  \end{enumerate}
\end{definition}

If $B$ is a Brownian motion, then it is obviously an $\mathbb{F}^B$-Brownian
motion. The reason for introducing the notion of an $\mathbb{F}$-Brownian
motion is that it is often desirable and indeed possible to take $\mathbb{F}$
larger than $\mathbb{F}^B$. Think for example of a two-dimensional Brownian
motion $B = (B^1, B^2)$. Then $B^1$ is a one-dimensional
$\mathbb{F}^B$-Brownian motion, although $\mathbb{F}^B$ is larger than
$\mathbb{F}^{B^1}$.

\begin{theorem}[Strong Markov property of Brownian motion]
  \label{thm:strong Markov}Let $\mathbb{F}$ be a filtration and let $B$ be a
  $d$-dimensional $\mathbb{F}$-Brownian motion. Then for any finite stopping
  time $\tau$ the process $B^{(\tau)} = (B_{\tau + t} - B_{\tau})_{t \geqslant
  0}$ is a $d$-dimensional Brownian motion and independent of
  $\mathcal{F}_{\tau +}$.
\end{theorem}

In particular, an $\mathbb{F}$-Brownian motion is also an
$\mathbb{F}^+$-Brownian motion and a $\mathbb{F}^{+, \mathbb{P}}$-Brownian
motion.

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  You might remember the strong Markov property of Markov chains. Does the
  Brownian motion also satisfy an analogous version of the strong Markov
  property?
\end{exercise*}}}{\ }

\begin{proof}
  The process $B^{(\tau)}$ is continuous by definition, so it suffices to show
  that it is a pre-Brownian motion and independent of $\mathcal{F}_{\tau +}$.
  For that purpose it suffices to show that
  \begin{equation}
    \label{eq:strong-markov-pr1} \mathbb{E} [\1_A \1_C (B^{(\tau)})]
    =\mathbb{P} (A) \mathbb{E} [\1_C (B)]
  \end{equation}
  for all $A \in \mathcal{F}_{\tau +}$ and all $C \in \mathcal{B}
  (\mathbb{R}^d)^{\otimes \mathbb{R}_+}$. By Dynkin's $\pi - \lambda$ theorem
  it suffices to consider $C = \{ f : \mathbb{R}_+ \rightarrow \mathbb{R}^d |f
  (t_1) \in C_1, \ldots, f (t_k) \in C_k \}$ for $k \in \mathbb{N}$ and closed
  $C_1, \ldots, C_k \subset \mathbb{R}^d$. Moreover, with $C = C_1 \times
  \cdots \times C_k$ we have for all $x \in \mathbb{R}^k$
  \[ \1_C (x) = \lim_{n \rightarrow \infty} (1 - n \cdot d (x, C)) \vee 0, \]
  and since the right hand side is bounded and continuous in $x$ we can
  replace $\1_C$ by $\varphi (B_{t_1}, \ldots, B_{t_k})$ for a continuous
  bounded function $\varphi \in C_b ((\mathbb{R}^d)^k, \mathbb{R})$.
  
  Next, we approximate $\tau$ from above by
  \[ \tau_n \coloneq \sum_{k = 0}^{n 2^n - 1} (k + 2) 2^{- n}
     \1_{\{\tau \in [k 2^{- n}, (k + 1) 2^{- n})\}} + \infty
     \1_{\{ \tau \geqslant n \}}, \]
  so that $\tau_n$ takes only finitely many values (for simplicity we write
  $s_1 < \ldots < s_m$ for these values) and $\tau_n \geqslant \tau + 2^{- n}$
  while $\lim_{n \rightarrow \infty} \tau_n = \tau$. By
  Lemma~\ref{lem:stopping-times}, vi., we have $\mathcal{F}_{\tau +} \subset
  \mathcal{F}_{\tau + 2^{- n}} \subset \mathcal{F}_{\tau_n}$, and therefore $A
  \cap \{\tau_n = s_j \} \in \mathcal{F}_{s_j}$, which leads to
  
  \begin{align*}
    \mathbb{E} [\1_{\{\tau_n < \infty\}} \, \1_A \, \varphi
    (B^{(\tau_n)}_{t_1}, \ldots, B^{(\tau_n)}_{t_k})] & = \sum_{j = 1}^m
    \mathbb{E} [\1_{\{\tau_n = s_j \}} \, \1_A \, \varphi
    (B^{(\tau_n)}_{t_1}, \ldots, B^{(\tau_n)}_{t_k})]\\
    & = \sum_{j = 1}^m \mathbb{E} [\1_{A \cap \{\tau_n = s_j \}} \,
    \varphi (B_{s_j + t_1} - B_{s_j}, \ldots, B_{s_j + t_k} - B_{s_j})]\\
    & = \sum_{j = 1}^m \mathbb{E} [\1_{A \cap \{\tau_n = s_j \}}] \,
    \mathbb{E} [\varphi (B_{t_1}, \ldots, B_{t_k})]\\
    & =\mathbb{P} (A \cap \{\tau_n < \infty\}) \, \mathbb{E} [\varphi
    (B_{t_1}, \ldots, B_{t_k})]
  \end{align*}
  
  where in the penultimate step we used that $(B_{s_j + t} - B_{s_j})_{t
  \geqslant 0}$ is a Brownian motion and independent of $\mathcal{F}_{s_j}$
  (Proposition~\ref{prop:brownian path transformation}). Recall that $\tau$ is
  finite. So letting $n$ tend to infinity, the left hand side converges to
  $\mathbb{E} [\1_A \varphi (B^{(\tau)}_{t_1}, \ldots,
  B^{(\tau)}_{t_k})]$ (recall that $\varphi$ is continuous and bounded) and
  the right hand side to $\mathbb{P} (A) \mathbb{E} [\varphi (B_{t_1}, \ldots,
  B_{t_k})]$.
\end{proof}

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on November 13}
  \hrulefill\hrulefill
\end{center}

\begin{remark}
  Let $\tau$ be a not necessarily finite stopping time with $\mathbb{P} (\tau
  < \infty) > 0$. Then the proof of Theorem~\ref{thm:strong Markov} still
  shows that
  \[ \mathbb{P} (A \cap \{\tau < \infty\} \cap \{ B^{(\tau)} \in C \})
     =\mathbb{P} (A \cap \{\tau < \infty\}) \mathbb{P} (B \in C) \]
  for all $A \in \mathcal{F}_{\tau +}$ and all $C \in \mathcal{B}
  (\mathbb{R}^d)^{\otimes \mathbb{R}_+}$. Dividing both sides by $\mathbb{P}
  (\tau < \infty)$, we get
  \[ \mathbb{P} (A \cap \{ B^{(\tau)} \in C \} | \tau < \infty) =\mathbb{P}
     (A| \tau < \infty) \mathbb{P} (B \in C), \]
  which shows that under the conditional probability measure $\mathbb{P}
  (\cdot | \tau < \infty)$ the process $(B_{\tau + t} - B_{\tau})_{t
  \geqslant 0}$ (defined for example as $0$ on the set $\tau = \infty$) is a
  Brownian motion independent of $\mathcal{F}_{\tau +}$. In particular, the
  statement of Theorem~\ref{thm:strong Markov} still holds for stopping times
  that are almost surely finite.
\end{remark}

\begin{corollary}[Blumenthal's 0-1 law]
  \label{cor:blumenthal}Let $B$ be a ($d$-dimensional) Brownian motion and let
  $A \in \mathcal{F}_{0 +}^B$. Then $\mathbb{P} (A) \in \{ 0, 1 \}$.
\end{corollary}

Intuitively, Blumenthal's 0-1 law says that we cannot learn anything new by
peaking a little bit into the future of the Brownian motion.

\begin{proof}
  If $A \in \mathcal{F}^B_{0 +} \subset \mathcal{F}^B_{\infty}$, then there
  exists $C \in \mathcal{B} (\mathbb{R}^d)^{\otimes \mathbb{R}_+}$ such that
  $A = \{\omega : B (\omega) \in C\}$. The strong Markov property applied with
  $\tau = 0$ gives
  \[ \mathbb{P} (A) =\mathbb{P} (A \cap A) =\mathbb{P} (A \cap \{ B \in C \})
     =\mathbb{P} (A \cap \{ B^{(0)} \in C \}) =\mathbb{P} (A) \mathbb{P} (B
     \in C) =\mathbb{P} (A)^2, \]
  and the result follows because the only numbers $a$ with $a^2 = a$ are $\{0,
  1\}$
\end{proof}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Let $B$ be a Brownian motion and let $\mathcal{F}_{t, \infty}^B \coloneq
  \sigma (B_s : s \geqslant t)$. Let $\mathcal{T}^B = \bigcap_{t > 0}
  \mathcal{F}^B_{t, \infty}$ be the tail $\sigma$-algebra of $B$. Show that
  every $A \in \mathcal{T}^B$ satisfies $\mathbb{P} (A) \in \{ 0, 1 \}$.
  Compare this result to the Kolmogorov 0-1 law (cf. Exercise Sheet 4).
  
  {\emph{Hint: Consider the time-inversed Brownian motion $\tilde{B}_t = t
  B_{1 / t}$.}}
\end{exercise*}}}{\ }

\begin{corollary}
  \label{cor:Bm up and down}Let $B$ be a Brownian motion. Then with
  probability $1$ we have for all $\varepsilon > 0$
  \[ \sup_{s \in [0, \varepsilon]} B_s > 0, \qquad \inf_{s \in [0,
     \varepsilon]} B_s < 0. \]
  Moreover, if for $a \in \mathbb{R}$ we set $\tau_a = \inf \{t \geqslant 0 :
  B_t = a\}$, then $\tau_a < \infty$ for all $a \in \mathbb{R}$ with
  probability $1$, so that in particular
  \begin{equation}
    - \infty = \liminf_{t \rightarrow \infty} B_t < \limsup_{t \rightarrow
    \infty} B_t = \infty . \label{eq:Bm.up.and.down}
  \end{equation}
\end{corollary}

At first sight, it is not obvious whether $\sup_{s \in [0, \varepsilon]} B_s$
is measurable. But recall that $B$ is continuous, and therefore $\sup_{s \in
[0, \varepsilon]} B_s = \sup_{s \in [0, \varepsilon] \cap \mathbb{Q}} B_s$. In
the sequel we will often implicitly use this kind of argument when dealing
with continuous (or right- or left-continuous) processes. The last
conclusion~\eqref{eq:Bm.up.and.down} above might not come as a surprise, given
our previous discussions and results around Corollary~\ref{cor:bm-growth} and
Theorem~\ref{thm:law.iterated.log}; but it is nice to see how Blumenthal's
$0$-$1$ law provides a short, elegant proof of that fact. \

\begin{proof*}{Proof of Corollary~\ref{cor:Bm up and down}}
  Notice that
  
  \begin{align*}
    \Gamma \coloneq \left\{ \omega \in \Omega : \sup_{s \in [0, \varepsilon]}
    B_s (\omega) > 0 \text{for all } \varepsilon > 0 \right\} & = \bigcap_{n
    \geqslant 1} \{ \omega \in \Omega : \sup_{s \in [0, 1 / n]} B_s (\omega) >
    0 \}\\
    & = \bigcap_{n \geqslant N} \{ \omega \in \Omega : \sup_{s \in [0, 1 /
    n]} B_s (\omega) > 0 \}
  \end{align*}
  
  for any fixed $N \in \mathbb{N}$. In particular, $\Gamma \in \mathcal{F}_{1
  / N}$ for all $N \in \mathbb{N}$ and so $\Gamma \in \mathcal{F}_{0 +}$; by
  Blumenthal's 0-1 law, $\mathbb{P} (\Gamma)$ must be $0$ or $1$. On the other
  hand
  
  \begin{align*}
    \mathbb{P} (\Gamma) & =\mathbb{P} \left( \bigcap_{n \in \mathbb{N}} \{
    \sup_{s \in [0, 1 / n]} B_s > 0 \} \right)\\
    & = \lim_{n \rightarrow \infty} \mathbb{P} (\sup_{s \in [0, 1 / n]} B_s >
    0)\\
    & \geqslant \limsup_{n \rightarrow \infty} \mathbb{P} (B_{1 / n} > 0) =
    \frac{1}{2}
  \end{align*}
  
  since $B_{1 / n}$ is a centered Gaussian, thus its law is symmetric.
  Therefore $\mathbb{P} (\Gamma) = 1$.
  
  Replacing $B$ by the Brownian motion $- B$, we get the statement about the
  infimum.
  
  If there exists $a > 0$ with $\tau_a = \infty$, then $\sup_{s \geqslant 0}
  B_s < \infty$. But
  \begin{eqnarray*}
    \mathbb{P} (\sup_{s \geqslant 0} B_s = \infty) & = & \lim_{n \rightarrow
    \infty} \mathbb{P} (\sup_{s \geqslant 0} B_s > n)\\
    & = & \lim_{n \rightarrow \infty} \mathbb{P} \left( \sup_{s \geqslant 0}
    n^{- 2} B_s > \frac{1}{n} \right)\\
    & = & \lim_{n \rightarrow \infty} \mathbb{P} \left( \sup_{s \geqslant 0} 
    \tilde{B}_{n^{- 4} s} > \frac{1}{n} \right)\\
    & = & \mathbb{P} (\sup_{s \geqslant 0} \tilde{B}_s > 0) = 1,
  \end{eqnarray*}
  where $\tilde{B}_s \coloneq n^{- 2} B_{n^4 s}$ is a new Brownian motion (so
  that $n^{- 2} B_s = \tilde{B}_{n^{- 4} s}$) and we used the scaling
  properties of the Brownian motion, as well as the fact that the supremum is
  taken over the whole real line $[0, + \infty)$ (so that computing it over
  the variable $\tilde{s} = n^{- 4} s$ instead of the original $s$ doesn't
  change its value).
  
  As before, up to replacing $B$ with $- B$, we find that $\mathbb{P} (\inf_{s
  \geqslant 0} B_s = - \infty) = 1$ as well. Since $B$ is continuous, so that
  its sup and inf computed on compact time intervals $[0, T]$ are necessarily
  finite (for fixed $\omega$), we deduce also the claim about $\liminf$ and
  $\limsup$.
\end{proof*}

\begin{proposition}[Reflection principle]
  Let $B$ be a one-dimensional Brownian motion and let $\tau$ be a finite
  stopping time. Then the process
  \[ B^{*}_t \coloneq B_t \1_{\{ t \leqslant \tau \}} + (2 B_{\tau}
     - B_t) \1_{\{ t > \tau \}} \]
  is also a Brownian motion.
\end{proposition}

\scalebox{0.8}{\includegraphics{StochAna-ongoing-12.pdf}}

\begin{proof}
  By the strong Markov property, both
  \[ B^{(\tau)} = (B_{t + \tau} - B_{\tau})_{t \geqslant 0}, \qquad -
     B^{(\tau)} = (B_{\tau} - B_{\tau + t})_{t \geqslant 0} \]
  are Brownian motions that are independent of $\mathcal{F}_{\tau}$. Using
  that $(\tau, B_{t \wedge \tau})$ is $\mathcal{F}_{\tau}$--measurable (by
  Corollary~\ref{lem:progressively measurable in stopping time}) and thus is
  independent of these two processes, we get that the ``glued'' process
  \begin{eqnarray*}
    B_t & = & B_{t \wedge \tau} + B^{(\tau)}_{t - \tau} \1_{\{ t >
    \tau \}}
  \end{eqnarray*}
  has the same law as
  \begin{eqnarray*}
    B_{t \wedge \tau} - B^{(\tau)}_{t - \tau} \1_{\{ t > \tau \}} & =
    & B_{t \wedge \tau} + (B_{\tau} - B_{\tau + (t - \tau)}) \1_{\{ t
    > \tau \}}\\
    & = & B_t \1_{\{ t \leqslant \tau \}} + B_{\tau} \1_{\{
    t > \tau \}} + (B_{\tau} - B_{\tau + (t - \tau)}) \1_{\{ t > \tau
    \}}\\
    & = & B^{*}_t
  \end{eqnarray*}
  and this concludes the proof.
  
  {\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
    You might (and probably should) feel a bit uncomfortable about plugging $t
    - \tau$ into $B^{(\tau)}$ resp. $- B^{(\tau)}$ and claiming that we still
    have the same law. To rigorously see that everything works, we could first
    assume that $\tau$ only takes finitely many values, verify everything
    there ``by hand'' conditioning on the values $\tau$ can attain, and then
    use a limiting argument as in the proof of the strong Markov property. Due
    to the similarity of such passages with those in the proof of
    Theorem~\ref{thm:strong Markov}, we omit them here for simplicity.
  \end{tabularx}
  
  \tmfolded{}{Solution for $\tau$ taking finitely many values, $\{ s_1,
  \ldots, s_m \}$ (and consider only $f (B^{*}_t)$ instead of $f
  (B^{*}_{t_1}, \ldots, B^{*}_{t_n})$ to simplify notation)
  \begin{eqnarray*}
    \mathbb{E} [f (B^{*}_t)] & = & \sum_{k = 1}^m \mathbb{E} \left[ f (B_{t
    \wedge s_k} - B^{(s_k)}_{t - s_k} \1_{\{ t > s_k \}}) \1_{\{ \tau
    = s_k \}} \right]\\
    & = & \sum_{k = 1}^m \mathbb{E} \left[ \mathbb{E} [f (B_{t \wedge s_k} -
    B^{(s_k)}_{t - s_k} \1_{\{ t > s_k \}}) |\mathcal{F}_{s_k}]
    \1_{\{ \tau = s_k \}} \right]\\
    & = & \sum_{k = 1}^m \mathbb{E} \left[ \mathbb{E} [f (x - B^{(s_k)}_{t -
    s_k} \1_{\{ t > s_k \}})] |_{x = B_{t \wedge s_k}} \1_{\{ \tau =
    s_k \}} \right]\\
    & = & \sum_{k = 1}^m \mathbb{E} \left[ \mathbb{E} [f (x + B^{(s_k)}_{t -
    s_k} \1_{\{ t > s_k \}})] |_{x = B_{t \wedge s_k}} \1_{\{ \tau =
    s_k \}} \right]\\
    & = & \ldots =\mathbb{E} [f (B_t)] .
  \end{eqnarray*}
  
  
  \
  
  \
  
  \
  
  \hrulefill
  
  Old:
  
  Additional details: To save notation we show that $\mathbb{E} [f
  (B^{*}_t)] =\mathbb{E} [f (B_t)]$. With more notation the same argument
  shows $\mathbb{E} [f (B_{t_1}^{*}, \ldots, B^{*}_{t_n})] =\mathbb{E}
  [f (B_{t_1}, \ldots, B_{t_n})]$.
  \begin{eqnarray*}
    \mathbb{E} [f (B_t^{*})] & = & \mathbb{E} [\mathbb{E} [f (B^{*}_t) |
    (B_{t \wedge \tau}, \tau)]]\\
    & = & \mathbb{E} \left[ \mathbb{E} \left[ f \left( B_{t \wedge \tau} -
    {\1_{\{ t > \tau \}}}  B^{(\tau)}_{t - \tau} \right) | (B_{t \wedge \tau},
    \tau) \right] \right]\\
    & \overset{(*)}{=} & \mathbb{E} \left[ \mathbb{E} \left[ f \left( x -
    {\1_{\{ t > s \}}}  B^{(\tau)}_{t - s} \right) \right] {|_{(x, s) = (B_{t
    \wedge \tau}, \tau)}}  \right]\\
    & = & \mathbb{E} \left[ \mathbb{E} \left[ f \left( x + {\1_{\{ t > s \}}}
    B^{(\tau)}_{t - s} \right) \right] {|_{(x, s) = (B_{t \wedge \tau},
    \tau)}}  \right]\\
    & = & \ldots =\mathbb{E} [f (B_t)] .
  \end{eqnarray*}
  $(*)$: Indeed, for $A \in \mathcal{B} (\mathbb{R} \times \mathbb{R}_+)$:
  \begin{eqnarray*}
    &  & \mathbb{E} \left[ f \left( B_{t \wedge \tau} - {\1_{\{ t > \tau \}}}
    B^{(\tau)}_{t - \tau} \right) \1_A (B_{t \wedge \tau}, \tau) \right]\\
    &  & \overset{B^{(\tau)} \indep (\tau, B_{t \wedge \tau})}{=}
    \int_{\mathbb{R} \times \mathbb{R}_+} \int_{C (\mathbb{R}_+)} f \left( x -
    {\1_{\{ t > s \}}}  \varphi (t - s) \right) \1_A (x, s)
    \mathbb{P}_{B^{(\tau)}} (\mathrm{d} \varphi) \mathbb{P}_{(B_{t \wedge \tau},
    \tau)} (\mathrm{d} x, \mathrm{d} s)\\
    &  & = \int_{\mathbb{R} \times \mathbb{R}_+} \int_{C (\mathbb{R}_+)} f
    \left( x - {\1_{\{ t > s \}}}  \varphi (t - s) \right)
    \mathbb{P}_{B^{(\tau)}} (\mathrm{d} \varphi) \1_A (x, s) \mathbb{P}_{(B_{t
    \wedge \tau}, \tau)} (\mathrm{d} x, \mathrm{d} s)\\
    &  & = \int_{\mathbb{R} \times \mathbb{R}_+} \mathbb{E} \left[ f \left( x
    - {\1_{\{ t > s \}}}  B^{(\tau)}_{t - s} \right) \right] \1_A (x, s)
    \mathbb{P}_{(B_{t \wedge \tau}, \tau)} (\mathrm{d} x, \mathrm{d} s)\\
    &  & =\mathbb{E} \left[ \mathbb{E} \left[ f \left( x - {\1_{\{ t > s \}}}
    B^{(\tau)}_{t - s} \right) \right] |_{(x, s) = (B_{t \wedge \tau}, \tau)}
    \1_A (B_{t \wedge \tau}, \tau) \right] .
  \end{eqnarray*}
  If $f$ is continuous and bounded, then $(x, s) \mapsto \mathbb{E} \left[ f
  \left( x - {\1_{\{ t > s \}}}  B^{(\tau)}_{t - s} \right) \right]$ is
  continuous and in particular measurable, and therefore $(*)$ follows.}
  
  \ 
\end{proof}

\begin{corollary}
  Let $B$ be a Brownian motion and let $S_t = \max_{s \in [0, t]} B_s$. Then
  \[ \mathbb{P} (S_t \geqslant a) = 2\mathbb{P} (B_t \geqslant a) =\mathbb{P}
     (| B_t | \geqslant a) \]
  for all $a \geqslant 0$.
\end{corollary}

\begin{proof}
  Exercise Sheet~5.
\end{proof}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  {\tmdummy}
  
  \begin{enumerate}
    \item Do $(S_t)_{t \geqslant 0}$ and $(| B_t |)_{t \geqslant 0}$ have the
    same law?
    
    \item Show that $\mathbb{E} [e^{\lambda S_t}] < \infty$ for all $\lambda
    \in \mathbb{R}$ and $t > 0$; show that, for any fixed $t > 0$, there
    exists $\lambda^{*} = \lambda^{*} (t) > 0$ small enough such that
    $\mathbb{E} [e^{\lambda^{*}  | S_t |^2}] < \infty$. 
  \end{enumerate}
\end{exercise*}}}{\ }

Here are simulations of $B$, $| B |$ and $M$. We start with $| B |$, then we
draw $B$ so that we can better compare it with $M$ (note that $M$ is the
maximum value of $B$ and not the maximum value of $| B |$). Here is $| B |$:

\tmsession{python}{default}{
  \tmoutput{Python 3.7.4 [/opt/anaconda3/bin/python3]
  
  Python plugin for TeXmacs.
  
  Please see the documentation in Help -> Plugins -> Python}
  \tmunfoldedio{>>> }{import numpy as np
  
  import matplotlib.pyplot as plt
  
  \
  
  T, h = 1, 1e-3
  
  n = int(T/h)
  
  k = 3
  
  \
  
  time = np.arange(0,T+h,h)
  
  dB = np.sqrt(h)*(np.random.randn(k,n))
  
  BM = np.zeros((k,n+1))
  
  BM[:,1:] = np.cumsum(dB, axis=1)
  
  BM\_norm = np.abs(BM)
  
  BM\_max = np.maximum.accumulate(BM,axis=1)
  
  \
  
  plt.clf()
  
  \ \ \
  
  for i in range(k):
  
  \ \ \ plt.plot(time,BM\_norm[i,:])
  
  \
  
  pdf\_out(plt.gcf())}{\raisebox{-6.08522644886627e-4\height}{\includegraphics[width=9.20064279155188cm,height=6.89838318247409cm]{StochAna-ongoing-13.pdf}}}
  Now we plot the Brownian motion $B$:
  \tmunfoldedio{>>> }{plt.clf()
  
  \ \ \
  
  for i in range(k):
  
  \ \ \ plt.plot(time,BM[i,:])
  
  \
  
  pdf\_out(plt.gcf())}{\raisebox{-6.08522644886627e-4\height}{\includegraphics[width=9.20064279155188cm,height=6.89838318247409cm]{StochAna-ongoing-14.pdf}}}
  And here is $M$. Compare this with the plot of $| B |$ from above!
  \tmunfoldedio{>>> }{plt.clf()
  
  \ \ \
  
  for i in range(k):
  
  \ \ \ plt.plot(time,BM\_max[i,:])
  
  \
  
  pdf\_out(plt.gcf())}{\raisebox{-6.08522644886627e-4\height}{\includegraphics[width=9.20064279155188cm,height=6.89838318247409cm]{StochAna-ongoing-15.pdf}}}
  \tminput{>>> }{\ }
}

Here is another example of two processes that have the same one-dimensional
marginal

distributions but which have different distributions as processes: If $X \sim
\mathcal{N} (0 ; 1)$, then for

each fixed $t > 0$ the random variable $\sqrt{t} X$ has the same distribution
as $B_t$, but of course

the processes $\left( \sqrt{t} X \right)_{t \geqslant 0}$ and $(B_t)_{t
\geqslant 0}$ are nothing alike.

\section{Martingales in continuous time}

Throughout this section we fix a filtered probability space $(\Omega,
\mathcal{F}, \mathbb{F}, \mathbb{P})$.

\subsection{Path regularity}

\begin{definition}[Integrable]
  A stochastic process $X$ is called {\emph{integrable}} if $\mathbb{E} [|X_t
  |] < \infty$ for all $t \geqslant 0$. For $p > 0$ we call $X$
  {\emph{$p$-integrable}} if $\mathbb{E} [|X_t |^p] < \infty$ for all $t
  \geqslant 0$. For $p = 2$ we also say {\emph{square-integrable}}.
\end{definition}

\begin{definition}[Martingale]
  An adapted, real-valued and integrable process $X = (X_t)_{t \geqslant 0}$
  is called a
  \begin{enumerate}
    \item {\emph{martingale}} if $\mathbb{E} [X_t |\mathcal{F}_s] = X_s$ for
    all $0 \leqslant s \leqslant t$;
    
    \item {\emph{supermartingale}} if $\mathbb{E} [X_t |\mathcal{F}_s]
    \leqslant X_s$ for all $0 \leqslant s \leqslant t$;
    
    \item {\emph{submartingale}} if $\mathbb{E} [X_t |\mathcal{F}_s] \geqslant
    X_s$ for all $0 \leqslant s \leqslant t$.
  \end{enumerate}
\end{definition}

Clearly, $X$ is a martingale if and only if it is both a submartingale and a
supermartingale; moreover $X$ is a supermartingale if and only if $- X$ is a
submartingale. Finally, notice how the martingale property may be rephrased as
$\mathbb{E} [X_t - X_s | \mathcal{F}_s] = 0$ for all $0 \leqslant s \leqslant
t$ (similarly for super- and sub-martingales, up to replacing $=$ with
$\leqslant$ and $\geqslant$).

In the following we will state some of the next results only for
supermartingales, but by the above similar variants can be immediately
inferred for submartingales as well.

\begin{example}[Brownian martingales]
  \label{ex:martingales}Let $B$ be an $\mathbb{F}$-Brownian motions. Then:
  \begin{enumerate}
    \item $B$ is a martingale:
    \[ \mathbb{E} [B_t |\mathcal{F}_s] =\mathbb{E} [B_t - B_s |\mathcal{F}_s]
       + B_s =\mathbb{E} [B_t - B_s] + B_s = B_s . \]
    \item $X_t = B_t^2 - t$, $t \geqslant 0$, is a martingale:
    \[ \mathbb{E} [X_t |\mathcal{F}_s] =\mathbb{E} [(B_t - B_s)^2 + 2 (B_t -
       B_s) B_s + B_s^2 |\mathcal{F}_s] - t = (t - s) + B_s^2 - t = X_s . \]
    \item For $\lambda \in \mathbb{R}$ the process $Y_t = e^{\lambda B_t -
    \lambda^2 t / 2}$, $t \geqslant 0$, is a martingale:
    
    \begin{align*}
      \mathbb{E} [Y_t |\mathcal{F}_s] & =\mathbb{E} [e^{\lambda (B_t - B_s)}
      |\mathcal{F}_s] e^{\lambda B_s - \lambda^2 t / 2} =\mathbb{E}
      [e^{\lambda (B_t - B_s)}] e^{\lambda B_s - \lambda^2 t / 2}\\
      & = e^{\lambda^2  (t - s) / 2} e^{\lambda B_s - \lambda^2 t / 2} = Y_s
      ;
    \end{align*}
    
    we used the formula $\mathbb{E} [e^{\lambda U}] = e^{\lambda^2 \sigma^2 /
    2}$ for the Laplace transform of $U \sim \mathcal{N} (0, \sigma^2)$.
    
    Similarly (up to extending the definition of martingale to the
    complex-valued processes), for any $\lambda \in \mathbb{R}$, $Y_t = e^{i
    \lambda B_t + \lambda^2 t / 2}$ is a martingale.
    
    \item If $B$, $\tilde{B}$ are independent $\mathbb{F}$-Brownian motions,
    then $U_t = B_t \tilde{B}_t$, $t \geqslant 0$, is a martingale:
    \[ \mathbb{E} [U_t |\mathcal{F}_s] =\mathbb{E} [(B_t - B_s) (\tilde{B}_t -
       \tilde{B}_s) + (B_t - B_s) \tilde{B}_s + B_s (\tilde{B}_t -
       \tilde{B}_s) + B_s \tilde{B}_s |\mathcal{F}_s] = U_s . \]
    \begin{center}
      \hrulefill\hrulefill\textbf{ End of the lecture on November 14}
      \hrulefill\hrulefill
    \end{center}
    
    \item Let $f \in L^2 (\mathbb{R}_+)$ and set $Z_t = \int_0^t f (s) \mathrm{d}
    B_s = \int_0^{\infty} \1_{[0, t]} (s) f (s) \mathrm{d} B_s$, where the right
    hand side is the Wiener integral; then $Z$ is a martingale. Indeed, first
    assume that $f (t) = \sum_{k = 0}^{n - 1} x_k \1_{(t_k, t_{k + 1})} (t)$,
    i.e. $f \in \mathcal{E}$ in the notation of Lemma~\ref{lem:wiener-int}.
    Then
    \[ Z_t = \sum_{k = 0}^{n - 1} x_k \int_0^{\infty} \1_{[0, t]} (s)
       \1_{(t_k, t_{k + 1}]} (s) \mathrm{d} B_s = \sum_{k = 0}^{n - 1} x_k
       (B_{t_{k + 1} \wedge t} - B_{t_k \wedge t}), \]
    which follows by considering the cases $t < t_k$, $t \in [t_k, t_{k + 1}]$
    and $t > t_{k + 1}$ separately. Therefore,
    \begin{eqnarray*}
      \mathbb{E} [Z_t |\mathcal{F}_s] & = & \sum_{k = 0}^{n - 1} x_k
      \mathbb{E} [B_{t_{k + 1} \wedge t} - B_{t_k \wedge t} |\mathcal{F}_s]\\
      & = & \sum_{k = 0}^{n - 1} x_k (B_{t_{k + 1} \wedge s} - B_{t_k \wedge
      s}) = Z_s .
    \end{eqnarray*}
    For general $f \in L^2 (\mathbb{R}_+)$ there exists a sequence $(f_n)_n
    \subset \mathcal{E}$ such that $\left\| f_n \1_{[0, t]} - f \1_{[0, t]}
    \right\|_{L^2 (\mathbb{R}_+)} \rightarrow 0$, and since the Wiener
    integral is an isometry we get that $Z^n_t = \int_0^t f_n (s) \mathrm{d} B_s$
    converges in $L^2 (\mathbb{R}_+)$ to $Z_t$, and we just saw that $Z^n$ is
    a martingale for each $n$. Since we can pull the $L^2$ limit into the
    conditional expectation, we get that $Z$ is a martingale.
  \end{enumerate}
\end{example}

\begin{example}[Poisson martingales]
  \label{ex:poisson}Let $N$ be a Poisson process with intensity $\lambda > 0$.
  Then:
  \begin{enumerate}
    \item $(N_t - \lambda t)_{t \geqslant 0}$ is a martingale in the
    filtration $\mathbb{F}=\mathbb{F}^N$.
    
    \item Let $X_t = \sum_{k = 1}^{N_t} Y_k$ be a compound Poisson process,
    where $(Y_k)_{k \in \mathbb{N}}$ is an i.i.d. sequence of integrable
    random variables that is independent of $N$ and we set $m =\mathbb{E}
    [Y_1]$. Then the compensated compound Poisson process
    $\tilde{X}_t \coloneq X_t - \lambda m t$ is a martingale w.r.t. its
    canonical filtration (also, note that $\mathbb{F}^X
    =\mathbb{F}^{\tilde{X}}$). In particular, $X$ is a martingale if $m = 0$.
    
    \item If additionally $a =\mathbb{E} [Y_1^2] < \infty$, then in the
    setting of the Point~ii., $M_t \coloneq | \tilde{X}_t |^2 - \lambda a t$ is
    also a martingale w.r.t. $\mathbb{F}^X$.
  \end{enumerate}
  All of the above statements were part of Exercise Sheet 3 (for point~i. this
  follows from $N$ being a L{\'e}vy process with $\mathbb{E} [N_t] = \lambda
  t$).
\end{example}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  {\tmdummy}
  
  \begin{enumerate}
    \item Let $N$ be a Poisson process with intensity $\lambda > 0$ and let
    $\mu \in \mathbb{R}$. Show that
    \[ M_t = \exp (\mu N_t - \lambda t (e^{\mu} - 1)), \qquad t \geqslant 0,
    \]
    is a martingale.
    
    \item Let $N^1, N^2$ be independent Poisson processes of the same
    intensity. Show that $N^1 - N^2$ is a martingale in the filtration
    $\mathbb{F}^{(N^1, N^2)}$.
  \end{enumerate}
\end{exercise*}}}{\ }

\begin{remark}
  \label{rem:martingale_monotone_mean}If $(X_t)_{t \geqslant 0}$ is a
  martingale, then by the tower property of conditional expectiation we
  immediately have $\mathbb{E} [X_t] =\mathbb{E} [X_0]$ for all $t \geqslant
  0$. Similarly, if $X$ is a supermartingale (respectively submartingale) then
  $t \mapsto \mathbb{E} [X_t]$ is decreasing (resp. increasing).
\end{remark}

{\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
  Recall \textbf{conditional Jensen's inequality} (e.g. from
  Stochastics~II): given a real-valued random variable $Z$ and a
  \textbf{convex} function $\varphi : \mathbb{R} \rightarrow \mathbb{R}$
  such that $Z$, $\varphi (Z)$ are integrable, it holds
  \[ \varphi (\mathbb{E} [Z| \mathcal{G}]) \leqslant \mathbb{E} [\varphi (Z) |
     \mathcal{G}] \]
  for any $\sigma$-algebra $\mathcal{G} \subset \mathcal{F}$.
\end{tabularx}

\begin{remark}
  \label{rem:martingale.jensen}It follows from conditional Jensen's inequality
  that:
  \begin{enumerate}
    \item If $X$ is a martingale, $\varphi : \mathbb{R} \rightarrow
    \mathbb{R}$ is convex and $(\varphi (X_t))_{t \geqslant 0}$ is integrable,
    then $\varphi (X)$ is a submartingale.
    
    \item If $X$ is a submartingale, $\varphi$ is convex and increasing, and
    $\varphi (X)$ is integrable, then $\varphi (X)$ is a submartingale.
    
    \item In particular, $|X|^p$ is a submartingale if $X$ is a $p$-integrable
    martingale and $p \geqslant 1$, and $X^+ = X \vee 0$ is a submartingale if
    $X$ is a submartingale.
  \end{enumerate}
\end{remark}

\tmcolor{blue}{\begin{exercise*}
  Prove/convince yourself of the above statements.
\end{exercise*}}

A priori, martingales have no path regularity. Our first aim is to show that
they admit nice modifications. In general, in the upcoming results, our
strategy will be to leverage as much as possible on the results for
discrete-time martingales you have already seen in Stochastics-II, and
transfer them to the continuous-time case. To that end, let us recall some
discrete-time results first.

\begin{definition}[Upcrossings]
  \label{def:upcrossings}Let $I \subset \mathbb{R}_+$ and $f : I \rightarrow
  \mathbb{R}$. For $a < b$, the number of upcrossings of $f$ across the
  interval $[a, b]$ in $I$ is the supremum over all $n$ for which there exist
  times $s_k, t_k \in I$, $k = 1, \ldots, n$, such that $s_1 < t_1 < s_2 < t_2
  < \ldots < s_n < t_n$ with $f (s_k) \leqslant a$ and $f (t_k) \geqslant b$
  for all $k = 1, \ldots, n$. We denote it with
  \[ U ([a, b] ; I ; f) . \]
\end{definition}

\begin{lemma}[Doob's upcrossing inequality]
  \label{lem:upcrossing}Let $(X_n)_{n \in \mathbb{N}_0}$ be a discrete time
  supermartingale. Then we have for all $a < b \in \mathbb{R}$
  \[ \mathbb{E} [U ([a, b] ; \{ 0, \ldots, n \} ; X)] \leqslant
     \frac{\mathbb{E} [(X_n - a)^-]}{b - a}, \qquad \mathbb{E} [U ([a, b] ;
     \mathbb{N}_0 ; X)] \leqslant \sup_{n \in \mathbb{N}} \frac{\mathbb{E}
     [(X_n - a)^-]}{b - a} . \]
\end{lemma}

\begin{lemma}[Doob's inequalities, discrete time case]
  \label{lem:doob.discrete}Let $(X_n)_{n \in \mathbb{N}_0}$ is a discrete time
  martingale, then for all $\lambda > 0$ and $n \in \mathbb{N}$:
  \[ \mathbb{P} (\max_{k \in \{ 0, \ldots, n \}} | X_k | \geqslant \lambda)
     \leqslant \frac{1}{\lambda} \mathbb{E} [| X_n |] . \]
  Moreover for all $p \in (1, \infty)$ we have
  \[ \mathbb{E} [\max_{k \in \{ 0, \ldots, n \}} | X_k |^p] \leqslant \left(
     \frac{p}{p - 1} \right)^p \mathbb{E} [| X_n |^p] . \]
\end{lemma}

It is also useful to shortly recall the concept of \tmtextit{uniform
integrability} of a family of random variables and its properties.

\begin{definition}
  A family of real-valued random variables $(Y_j)_{j \in J}$ is
  \textbf{uniformly integrable} if
  \[ \lim_{M \rightarrow \infty} \sup_{j \in J} \mathbb{E} \left[ | Y_j |
     \1_{\{ | Y_j | \geqslant M \}} \right] = 0. \]
\end{definition}

\begin{remark}
  \label{rem:uniform.integrability}Recall the following facts about uniform
  integrability:
  \begin{enumerate}
    \item If $(Y_j)_{j \in J}$ is uniformly integrable, then it is bounded in
    $L^1$: $\sup_{j \in J} \mathbb{E} [| Y_j |] < \infty$; the converse is not
    true.
    
    \item If $(Y_j)_{j \in J}$ is bounded in $L^p$ for some $p > 1$, i.e.
    $\sup_{j \in J} \mathbb{E} [| Y_j |^p] < \infty$, then it is uniformly
    integrable.
    
    \item Given a sequence $(Y_n)_{n \in \mathbb{N}}$, $Y_n \rightarrow Y$ in
    $L^1$ if and only if $Y_n \rightarrow Y$ in probability and $(Y_n)_{n \in
    \mathbb{N}}$ is uniformly integrable.
    
    \item If $Y \in L^1$ and $(\mathcal{G}_j)_{j \in J}$ is a family of
    $\sigma$-algebras, then $(\mathbb{E} [Y| \mathcal{G}_j])_{j \in J}$ is
    uniformly integrable.
  \end{enumerate}
\end{remark}

With these preparations, we can now show that martingales have c{\`a}dl{\`a}g
modifications, the proof of which crucially relies on
Lemma~\ref{lem:upcrossing}.

\begin{theorem}
  \label{thm:submartingale cadlag}Let $X$ be a martingale and assume that
  $\mathbb{F}$ satisfies the usual conditions. Then $X$ has an adapted
  c{\`a}dl{\`a}g modification which still is a martingale.
\end{theorem}

\begin{proof}[The proof was only sketched in the lectures and is not
examinable]
  \begin{enumeratenumeric}
    \item We first show that $X$ restricted to $\mathbb{Q}_+$ almost surely
    admits limits from the left and right: Let $k \in \mathbb{N}$ and let
    $(I_n)_{n \in \mathbb{N}}$ be an increasing sequence of finite subsets of
    $\mathbb{Q}_+ \cap [0, k]$ such that $\bigcup_n I_n =\mathbb{Q}_+ \cap [0,
    k]$. We also assume that $k \in I_n$ for all $n$. Then by the monotone
    convergence theorem, together with Doob's upcrossing lemma, for all $a, b
    \in \mathbb{R}$, $a < b$ and all $n \in \mathbb{N}$ it holds that
    \[ \mathbb{E} [U ([a, b] ; \mathbb{Q}_+ \cap [0, k] ; X)] = \lim_{n
       \rightarrow \infty} \mathbb{E} [U ([a, b] ; I_n ; X)] \leqslant
       \frac{\mathbb{E} [(X_k - a)^-]}{b - a} < \infty . \]
    Similarly, by applying Lemma~\ref{lem:doob.discrete} and passing to the
    limit, we get with Doob's maximal inequality for any $\lambda > 0$:
    \[ \mathbb{P} (\sup_{t \in \mathbb{Q}_+ \cap [0, k]} |X_t | \geqslant
       \lambda) = \lim_{n \rightarrow \infty} \mathbb{P} (\sup_{t \in I_n}
       |X_t | \geqslant \lambda) \leqslant \frac{\mathbb{E} [| X_k
       |]}{\lambda} . \]
    Therefore, there exists a null set $N$ such that for all $\omega \in N^c$
    \[ U ([a, b] ; \mathbb{Q}_+ \cap [0, k] ; X (\omega)) < \infty \qquad
       \text{for all } a < b \in \mathbb{Q}, k \in \mathbb{N}, \]
    and
    \[ \sup_{t \in \mathbb{Q}_+ \cap [0, k]} |X_t (\omega) | < \infty \qquad
       \text{for all } k \in \mathbb{N}. \]
    From here it is not hard to see that for $\omega \in N^c$ the limits
    \[ X_{t +} (\omega) \coloneq \lim_{s \downarrow t, s \in \mathbb{Q}_+} X_s
       (\omega) \in \mathbb{R} \qquad \text{and} \qquad X_{t -} (\omega)
       \coloneq \lim_{s \uparrow t, s \in \mathbb{Q}_+} X_s (\omega) \in
       \mathbb{R} \]
    exist for all $t \geqslant 0$ respectively $t > 0$.
    
    \
    
    \item With the null set $N$ and $X_{t +}$ as in step i. we define
    \[ \tilde{X}_t (\omega) = \left\{ \begin{array}{ll}
         X_{t +} (\omega), & \omega \in N^c,\\
         0 \comma & \omega \in N.
       \end{array} \right. \]
    $\tilde{X}$ is right-continuous by construction, and it also has left
    limits: For $\omega \in N$ this is clear, so let $\omega \in N^c$, let
    $t_n \uparrow t$, and consider for all $n \in \mathbb{N}$ a point $s_n \in
    (t_n, t) \cap \mathbb{Q}$ such that $| X_{t_n +} (\omega) - X_{s_n}
    (\omega) | < 1 / n$. Then
    \[ \lim_{n \rightarrow \infty} \tilde{X}_{t_n} (\omega) = \lim_{n
       \rightarrow \infty} X_{t_n +} (\omega) = \lim_{n \rightarrow \infty}
       X_{s_n} (\omega) \overset{s_n \uparrow t, (s_n) \subset \mathbb{Q}}{=}
       X_{t -} (\omega) . \]
    Moreover, $\tilde{X}$ is adapted because our filtration satisfies the
    usual conditions. The family
    \[ (X_s)_{s \in [t, t + 1] \cap \mathbb{Q}_+} = (\mathbb{E} [X_{t + 1}
       |\mathcal{F}_s])_{s \in [t, t + 1] \cap \mathbb{Q}_+} \]
    is uniformly integrable, because it is given by conditional expectations
    of $X_{t + 1} \in L^1$ (cf. Remark~\ref{rem:uniform.integrability}-iv.).
    Therefore, we get almost surely
    
    \begin{align*}
      \tilde{X}_t & =\mathbb{E} [\tilde{X}_t |\mathcal{F}_t] =\mathbb{E}
      [\nobracket \lim_{s \downarrow t, s \in \mathbb{Q}_+} X_s |
      \mathcal{F}_t] = \lim_{s \downarrow t, s \in \mathbb{Q}_+} \mathbb{E}
      [X_s |\mathcal{F}_t] = \lim_{s \downarrow t, s \in \mathbb{Q}_+} X_t =
      X_t,
    \end{align*}
    
    i.e. $\tilde{X}$ is a modification of $X$.
  \end{enumeratenumeric}
\end{proof}

\begin{remark}
  More generally, one can show that any supermartingale $X$ in a filtration
  satisfying the usual conditions and for which $t \mapsto \mathbb{E} [X_t]$
  is right-continuous has a c{\`a}dl{\`a}g adapted modification; see
  Theorem~3.17 of Le Gall {\cite{LeGall2016}}.
\end{remark}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  The condition that \ $t \mapsto \mathbb{E} [X_t]$ is right-continuous is
  necessary: Find a supermartingale which does {\underline{not}} have a
  c{\`a}dl{\`a}g modification.
\end{exercise*}}}{}

\begin{center}
  \
  
  \hrulefill\hrulefill\textbf{ End of the lecture on November 20}
  \hrulefill\hrulefill
\end{center}

\

\begin{theorem}[Martingale convergence theorem]
  \label{prop:supermartingale convergence}Let $X$ be a c{\`a}dl{\`a}g
  supermartingale with $\sup_{t \geqslant 0} \mathbb{E} [X_t^-] < \infty$.
  
  Then there exists a random variable $X_{\infty} \in L^1$ with $\lim_{t
  \rightarrow \infty} X_t = X_{\infty}$ almost surely.
  
  If $(| X_t |^p)_{t \geqslant 0}$ is uniformly integrable, for $p \geqslant
  1$, then $X_t$ also converges in $L^p$ to $X_{\infty}$.
\end{theorem}

\begin{remark}
  Notice that since $X$ is a supermartingale,
  \[ \sup_{t \geqslant 0} \mathbb{E} [X_t^-] < \infty \quad \Leftrightarrow
     \quad \sup_{t \geqslant 0} \mathbb{E} [| X_t |] < \infty . \]
  One implication is obvious; for the other, we have $\mathbb{E} [X^+_t]
  -\mathbb{E} [X^-_t] =\mathbb{E} [X_t] \leqslant \mathbb{E} [X_0]$, so that
  \[ \sup_{t \geqslant 0} \mathbb{E} [X^+_t] \leqslant \sup_{t \geqslant 0}
     \mathbb{E} [X_t^-] +\mathbb{E} [X_0] \quad \Rightarrow \quad \sup_{t
     \geqslant 0} \mathbb{E} [| X_t |] \leqslant \sup_{t \geqslant 0}
     \mathbb{E} [X^+_t] + \sup_{t \geqslant 0} \mathbb{E} [X_t^-] < \infty .
  \]
  \[ \  \]
\end{remark}

\begin{proof}
  By an approximation argument of $\mathbb{Q}_+$ via finite sets we get
  (similarly as in Theorem~\ref{thm:submartingale cadlag}) for all $a < a' <
  b' < b \in \mathbb{R}$:
  \[ \mathbb{E} [U ([a, b] ; \mathbb{R}_+ ; X)] \leqslant \mathbb{E} [U ([a',
     b'] ; \mathbb{Q}_+ ; X)] \leqslant \frac{1}{b' - a'}  (\sup_{t \geqslant
     0} \mathbb{E}[X_t^-] + |a' |) < \infty, \]
  where the first inequality uses that $X$ is c{\`a}dl{\`a}g. So almost surely
  $U ([a, b] ; \mathbb{R}_+ ; X) < \infty$ for all $a, b \in \mathbb{Q}$ with
  $a < b$, which shows that $X_t$ converges almost surely to a limit
  $X_{\infty}$ with values in $[- \infty, \infty]$. Since $X_{\infty}$ is also
  the limit of $(X_n)_{n \in \mathbb{N}}$, we get $X_{\infty} \in L^1$ from
  the discrete time version of the martingale convergence theorem (Stochastics
  II).
  
  Suppose now that $(| X_t |^p)_{t \geqslant 0}$ is uniformly integrable; then
  $| X_t |^p \rightarrow | X_{\infty} |^p$ $\mathbb{P}$-a.s. (thus also in
  probability), which together with
  Remark~\ref{rem:uniform.integrability}-iii. implies $| X_t |^p \rightarrow |
  X_{\infty} |^p$ in $L^1$, which in turn implies that $X_t \rightarrow
  X_{\infty}$ in $L^p$.
\end{proof}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Show that any positive c{\`a}dl{\`a}g supermartingale almost surely
  converges.
\end{exercise*}}}{}

\begin{example}
  {\tmdummy}
  
  \begin{enumerate}
    \item Without a condition like $\sup_{t \geqslant 0} \mathbb{E} [X_t^-] <
    \infty$, convergence can fail: For example, the Brownian motion almost
    surely does not converge because it is unbounded from below and from
    above.
    
    \item If $X$ is a martingale, then $\mathbb{E} [X_t] =\mathbb{E} [X_0]$
    for all $t \geqslant 0$. But even if $X$ converges, we may have
    $\mathbb{E} [X_{\infty}] \neq \mathbb{E} [X_0]$. Consider for example $X_t
    = \exp (B_t - t / 2)$, $t \geqslant 0$, which is a positive martingale
    (cf. Example~\ref{ex:martingales}-iii.) and therefore it almost surely
    converges. We know from Corollary~\ref{cor:bm-growth} that for $\alpha \in
    (1 / 2, 1)$ and for almost every $\omega \in \Omega$ there exists $C
    (\omega) > 0$ with $|B_t (\omega) | \leqslant C (\omega) t^{\alpha}$ for
    all $t \geqslant 0$, so that
    \[ 0 \leqslant \limsup_{t \rightarrow \infty} X_t (\omega) \leqslant
       \limsup_{t \rightarrow \infty} \exp (C (\omega) t^{\alpha} - t / 2) =
       0, \]
    while $\mathbb{E} [X_t] = 1$ for all $t \geqslant 0$.
  \end{enumerate}
\end{example}

\begin{theorem}
  For a c{\`a}dl{\`a}g martingale $X$ the following conditions are equivalent:
  \begin{enumerate}
    \item $X$ is uniformly integrable (we say $X$ is a {\emph{uniformly
    integrable martingale}});
    
    \item $X_t$ converges almost surely and in $L^1$ to a limit $X_{\infty}$
    as $t \rightarrow \infty$;
    
    \item there exists $Y \in L^1$ with $X_t =\mathbb{E} [Y|\mathcal{F}_t]$
    for all $t \geqslant 0$ (we say that $X$ is a {\emph{closed martingale}}).
  \end{enumerate}
  In that case we can take $Y = X_{\infty}$, and for general $Y$ we always
  have $X_{\infty} =\mathbb{E} [Y|\mathcal{F}_{\infty}]$.
\end{theorem}

\begin{proof}
  \tmfoldedplain{This follows line-by-line by the same arguments as in the
  discrete time case, see Stochastics II.}{i.$\Rightarrow$ii.: If $X$ is
  uniformly integrable, then in particular $\sup_{t \geqslant 0} \mathbb{E}
  [|X_t |] < \infty$, so by Proposition~\ref{prop:supermartingale convergence}
  we obtain the almost sure convergence of $X_t$ to $X_{\infty}$. Using once
  more the uniform integrability, we deduce that the convergence also takes
  place in $L^1$.
  
  ii.$\Rightarrow$iii.: If $X_t$ converges in $L^1$ to $X_{\infty}$, then
  \[ \mathbb{E} [X_{\infty} |\mathcal{F}_t] = \lim_{s \rightarrow \infty}
     \mathbb{E} [X_s |\mathcal{F}_t] = \lim_{s \rightarrow \infty} X_t = X_t,
  \]
  so that we can take $Y = X_{\infty}$.
  
  iii.$\Rightarrow$i.: The family $\{\mathbb{E}[Y|\mathcal{G}] : \mathcal{G}
  \subset \mathcal{F} \text{ is a sigma algebra} \}$ is uniformly integrable
  and it contains $(X_t)_{t \geqslant 0}$, so $(X_t)_{t \geqslant 0}$ is
  uniformly integrable.
  
  It remains to show that
  \[ X_{\infty} =\mathbb{E} [Y|\mathcal{F}_{\infty}] . \]
  Both sides are $\mathcal{F}_{\infty}$--measurable, so it suffices to show
  that
  \[ \mathbb{E} \left[ \1_A X_{\infty} \right] =\mathbb{E} \left[ \1_A
     \mathbb{E} [Y|\mathcal{F}_{\infty}] \right] \]
  for all $A \in \mathcal{F}_{\infty}$. But it is easy to see that the family
  $\mathcal{D}$ of all sets $A \in \mathcal{F}$ for which the identity holds
  is a Dynkin system, and it contains $\mathcal{A} \coloneq \bigcup_n
  \mathcal{F}_n$. Indeed, for $A \in \mathcal{F}_n$:
  \[ \mathbb{E} [\1_A X_{\infty}] =\mathbb{E} [\1_A
     \mathbb{E} [X_{\infty} |\mathcal{F}_n]] =\mathbb{E} [\1_A X_n]
     =\mathbb{E} [\1_A \mathbb{E} [Y|\mathcal{F}_n]] =\mathbb{E}
     [\1_A \mathbb{E} [Y|\mathcal{F}_{\infty}]] . \]
  Since $\mathcal{A}$ is stable under finite intersections ($\mathcal{A}$ is
  even an algebra), it follows from Dynkin's $\pi - \lambda$-theorem that
  $\mathcal{D}$ contains $\sigma (\mathcal{A}) =\mathcal{F}_{\infty}$.}
\end{proof}

\begin{remark}
  \label{rem:basic.martingale}Given an integrable r.v. $Y$ and a filtration
  $\mathbb{F}$, $X_t =\mathbb{E} [Y| \mathcal{F}_t]$ always defines a
  martingale, by the tower property of conditional expectation; moreover $X$
  is uniformly integrable, by Remark~\ref{rem:uniform.integrability}-iv. If
  additionally $\mathbb{F}$ satisfies the usual assumptions, then we can
  invoke Theorem~\ref{thm:submartingale cadlag} to deduce that, up to a
  modification, $X$ has c{\`a}dl{\`a}g paths.
\end{remark}

\begin{example}
  \label{ex:deterministic.stopped.martingale}Let $(X_t)_{t \geqslant 0}$ be a
  martingale and fix a deterministic $T \in (0, + \infty)$; set
  \[ X^T_t = X_{t \wedge T} = X_t  \1_{t \leqslant T} + X_T
     \1_{t > T} . \]
  It's easy to check that $X^T$ is also a martingale, that it is uniformly
  integrable, since $X_t =\mathbb{E} [X_T | \mathcal{F}_t]$ for all $t
  \geqslant 0$.
\end{example}

\tmfolded{\ }{\tmunfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Find both an example of a uniformly integrable and of a non-uniformly
  integrable continuous-time martingale.
\end{exercise*}}}{The Brownian motion is a non-uniformly integrable
martingale.

It's not so easy to find a uniformly integrable one, all the examples we
discussed are not uniformly integrable. But we could take for example
\[ X_t = B_{t \wedge n}, \qquad t \geqslant 0. \]}}

\subsection{Martingale inequalities and stopping theorems}

Here we transfer some useful properties of discrete time martingales to
continuous time.

\begin{theorem}[Doob's martingale inequalities]
  \label{thm:doob}Let $T \in [0, + \infty)$ and $\lambda > 0$.
  \begin{enumerate}
    \item If $X$ is a c{\`a}dl{\`a}g submartingale, then
    \[ \mathbb{P} (\sup_{t \in [0, T]} X_t \geqslant \lambda) \leqslant
       \frac{1}{\lambda} \mathbb{E} [X_T^+], \qquad \mathbb{P} (\sup_{t
       \geqslant 0} X_t \geqslant \lambda) \leqslant \frac{1}{\lambda} \sup_{t
       \geqslant 0} \mathbb{E} [X_t^+] . \]
    \item If $X$ is a c{\`a}dl{\`a}g martingale, then
    \[ \mathbb{P} (\sup_{t \in [0, T]} |X_t | \geqslant \lambda) \leqslant
       \frac{1}{\lambda} \mathbb{E} [|X_T |], \qquad \mathbb{P} (\sup_{t
       \geqslant 0} |X_t | \geqslant \lambda) \leqslant \frac{1}{\lambda}
       \sup_{t \geqslant 0} \mathbb{E} [|X_t |], \]
    \item If $X$ is a c{\`a}dl{\`a}g martingale, then for all $p \in (1,
    \infty)$
    \[ \mathbb{E} [\sup_{t \in [0, T]} |X_t |^p] \leqslant \left( \frac{p}{p -
       1} \right)^p \mathbb{E} [|X_T |^p], \qquad \mathbb{E} [\sup_{t
       \geqslant 0} |X_t |^p] \leqslant \left( \frac{p}{p - 1} \right)^p
       \sup_{t \geqslant 0} \mathbb{E} [|X_t |^p] . \]
  \end{enumerate}
\end{theorem}

\

\begin{proof}
  Inequalities i.--ii. for $T = \infty$ are obtained by sending $T
  \rightarrow \infty$ in the corresponding finite time inequalities, and
  applying the monotone convergence theorem. There is a small subtlety though,
  because we may have $\sup_{t \geqslant 0} X_t = \lambda$ and yet $\sup_{t
  \in [0, T]} X_t < \lambda$ for all $T > 0$; we can circumvent this with a
  small trick. Assume we have proved the finite-time statement in
  i.; then for any $\varepsilon \in (0, 1)$, we have:
  \begin{eqnarray*}
    \mathbb{P} (\sup_{t \geqslant 0} X_t \geqslant \lambda) & \leqslant &
    \mathbb{P} (\sup_{t \geqslant 0} X_t > \lambda (1 - \varepsilon)) =
    \lim_{T \rightarrow \infty} \mathbb{P} (\sup_{t \in [0, T]} X_t > \lambda
    (1 - \varepsilon))\\
    & \leqslant & \frac{1}{\lambda (1 - \varepsilon)} \sup_{t \geqslant 0}
    \mathbb{E} [X_t^+] .
  \end{eqnarray*}
  Since the left hand side does not depend on $\varepsilon$, we can then send
  $\varepsilon \rightarrow 0$ to get the claim. The argument works similarly
  for ii.
  
  To derive the inequality i. in finite time, let $(I_n)_{n \in
  \mathbb{N}}$ be an increasing sequence of finite subsets of $\mathbb{Q}_+
  \cap [0, T]$ such that $\bigcup_{n \in \mathbb{N}} I_n =\mathbb{Q}_+ \cap
  [0, T]$ and such that $T \in I_n$ for all $n$. From the $\sigma$-continuity
  of $\mathbb{P}$ and the right-continuity of $X$, we get
  \[ \mathbb{P} (\sup_{t \in [0, T]} X_t > \lambda) = \lim_{n \rightarrow
     \infty} \mathbb{P} (\sup_{t \in I_n} X_t > \lambda) \leqslant \lim_{n
     \rightarrow \infty}  \frac{1}{\lambda} \mathbb{E} [X_T^+] =
     \frac{1}{\lambda} \mathbb{E} [X_T^+], \]
  where we applied Doob's inequality in discrete time,
  Lemma~\ref{lem:doob.discrete}. With the same argument as above, we can
  replace $\mathbb{P} (\sup_{t \in [0, T]} X_t > \lambda)$ by $\mathbb{P}
  (\sup_{t \in [0, T]} X_t \geqslant \lambda)$ on the left hand side.
  
  If $X$ is a c{\`a}dl{\`a}g martingale, then $\tilde{X}_t = | X_t |$ is a
  c{\`a}dl{\`a}g submartingale, so that ii. follows from
  i.} applied to $\tilde{X$.
  
  The inequalities in iii. are obtained using similar arguments,
  relying on Lemma~\ref{lem:doob.discrete} and the monotone convergence
  theorem (instead of $\sigma$-continuity).
\end{proof}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Show that in each of the infinite-time inequalities in
  Theorem~\ref{thm:doob} we have
  \[ \sup_{t \geqslant 0} \mathbb{E} [\varphi (X_t)] = \lim_{t \rightarrow
     \infty} \mathbb{E} [\varphi (X_t)] . \]
  Hint: recall Remark~\ref{rem:martingale.jensen}.
\end{exercise*}}}{\begin{enumerate}
  \
  
  \item If $X$ is a martingale, then $| X |^p$ is a submartingale for $p
  \geqslant 1$ and therefore $\mathbb{E} [| X_t |^p]$ is increasing in $t$.
\end{enumerate}}

\begin{remark}
  The constant $\left( \frac{p}{p - 1} \right)^p$ in Doob's maximal
  $L^p$-inequality (inequality iii.} in Theorem~\ref{thm:doob) is
  optimal. Notice that it diverges for $p \rightarrow 1$; indeed, the
  inequality is false for $p = 1$ and we cannot control $\mathbb{E} [\sup_{t
  \in [0, T]} | X_t |]$ in terms of $\mathbb{E} [| X_T |]$ (the corresponding
  inequality already fails in finite discrete time).
  
  To control the supremum, one needs $X_T$ to belong to $L \log L$: if $X$ is
  a c{\`a}dl{\`a}g martingale, then it holds
  \[ \mathbb{E} [\sup_{t \in [0, T]} | X_t |] \leqslant \frac{e}{e - 1} (1
     +\mathbb{E} [| X_T | \log | X_T |]) \]
  see for instance Exercise~II.1.16 in~{\cite{Revuz1999}}.
\end{remark}

If $\tau$ is a stopping time and $X_t$ almost surely converges to $X_{\infty}$
as $t \rightarrow \infty$, then we define
\[ X_{\tau} (\omega) \coloneq \1_{\{\tau (\omega) < \infty\}} X_{\tau
   (\omega)} (\omega) +\1_{\{\tau (\omega) = \infty\}} X_{\infty}
   (\omega) . \]

\begin{theorem}[Optional Sampling Theorem]
  \label{thm:optional-sampling}Let $X$ be a c{\`a}dl{\`a}g martingale and let
  $\sigma \leqslant \tau$ be stopping times. Assume that either
  \begin{enumerate}
    \item $\tau \leqslant C < \infty$ almost surely, where $C > 0$ is a
    deterministic constant;
    
    \item or $X$ is uniformly integrable.
  \end{enumerate}
  Then $X_{\sigma}$ and $X_{\tau}$ are in $L^1$ and
  \[ \mathbb{E} [X_{\tau} |\mathcal{F}_{\sigma}] = X_{\sigma} . \]
\end{theorem}

We momentarily postpone the proof of Theorem~\ref{thm:optional-sampling}
(similarly for Corollary~\ref{cor:stopping.theorem} below) in order to present
some applications of interest to Brownian motion (cf.
Corollary~\ref{cor:brownian.thresholds}).

\begin{theorem}
  \label{thm:optional.supermartingale}Let $X$ be a positive c{\`a}dl{\`a}g
  supermartingale (which almost surely converges to some $X_{\infty}$ by
  Proposition~\ref{prop:supermartingale convergence}) and let $\sigma
  \leqslant \tau$ be stopping times. Then $X_{\sigma}$ and $X_{\tau}$ are in
  $L^1$ and
  \[ \mathbb{E} [X_{\tau} |\mathcal{F}_{\sigma}] \leqslant X_{\sigma} . \]
\end{theorem}

\begin{proof}
  The proof is similar to the one of Theorem~\ref{thm:optional-sampling}, but
  in some places a bit more technical, so we skip it; for a reference, see
  Theorem~3.25 of~{\cite{LeGall2016}}.
\end{proof}

\begin{corollary}[Stopping theorem]
  \label{cor:stopping.theorem}Let $X$ be a c{\`a}dl{\`a}g martingale and let
  $\tau$ be a stopping time. Then the stopped process $X^{\tau}_t = X_{t
  \wedge \tau}$, $t \geqslant 0$, is a c{\`a}dl{\`a}g martingale. If $X$ is
  uniformly integrable, then $X^{\tau}$ is as well and we have
  \begin{equation}
    X^{\tau}_t =\mathbb{E} [X_{\tau} |\mathcal{F}_t] \quad \forall \, t
    \geqslant 0. \label{eq:stopping.theorem}
  \end{equation}
\end{corollary}

\tmfolded{}{\begin{proof}
  It suffices to show the claim for uniformly integrable $X$, because
  otherwise we can consider the stopped processes $(X_{t \wedge n})_{t
  \geqslant 0}$ for $n \in \mathbb{N}$. So let $X$ be uniformly integrable.
  Since $X$ is right-continuous and adapted, it is progressively measurable.
  By Lemma~\ref{lem:progressively measurable in stopping time} we know that
  $X^{\tau}_t = X_{\tau \wedge t}$ is $\mathcal{F}_{\tau \wedge
  t}$--measurable, and by Lemma~\ref{lem:stopping-times}, vi., we have
  $\mathcal{F}_{\tau \wedge t} \subset \mathcal{F}_t$, so $X^{\tau}$ is
  adapted. The stopping theorem shows that $X^{\tau}_t = X_{t \wedge \tau} \in
  L^1$, so it remains to prove the martingale property. The stopping theorem
  yields for $t \geqslant 0$
  \[ \mathbb{E} [X_{\tau} |\mathcal{F}_{t \wedge \tau}] = X^{\tau}_t, \]
  and if $A \in \mathcal{F}_t$, then $A \cap \{\tau > t\} \in \mathcal{F}_{t
  \wedge \tau}$: Indeed we have for $s \geqslant t$
  \[ A \cap \{\tau > t\} \cap \{t \wedge \tau \leqslant s\} = \underbrace{A
     \cap \{\tau > t\}}_{\in \mathcal{F}_t \subset \mathcal{F}_s} \in
     \mathcal{F}_s, \]
  while for $s < t$
  \[ A \cap \{\tau > t\} \cap \{t \wedge \tau \leqslant s\} = A \cap \{\tau >
     t\} \cap \{\tau \leqslant s\} = \varnothing \in \mathcal{F}_s, \]
  and therefore $A \cap \{\tau > t\} \in \mathcal{F}_{t \wedge \tau}$ as
  claimed. This yields
  
  \begin{align*}
    \mathbb{E} [X_{\tau} \1_A] & =\mathbb{E} [X_{\tau} \1_A
    \1_{\{\tau > t\}}] +\mathbb{E} [X_{\tau} \1_A
    \1_{\{\tau \leqslant t\}}]\\
    & =\mathbb{E} [\mathbb{E}[X_{\tau} |\mathcal{F}_{t \wedge
    \tau}]\1_A \1_{\{\tau > t\}}] +\mathbb{E} [X_{\tau}
    \1_A \1_{\{\tau \leqslant t\}}]\\
    & =\mathbb{E} [X_t^{\tau} \1_A \1_{\{\tau > t\}}]
    +\mathbb{E} [X^{\tau}_t \1_A \1_{\{\tau \leqslant t\}}]
    =\mathbb{E} [X^{\tau}_t \1_A],
  \end{align*}
  
  and since $A \in \mathcal{F}_t$ was arbitrary, we get $\mathbb{E} [X_{\tau}
  |\mathcal{F}_t] = X^{\tau}_t$ which proves that $X^{\tau}$ is a uniformly
  integrable martingale.
\end{proof}}

\begin{corollary}
  \label{cor:brownian.thresholds}Let $B$ be a Brownian motion and write
  $\tau_x = \inf \{t \geqslant 0 : B_t = x\}$ for $x \in \mathbb{R}$. Let $a,
  b > 0$. Then
  \[ \mathbb{P} (\tau_{- a} < \tau_b) = \frac{b}{a + b}, \qquad \mathbb{P}
     (\tau_{- a} > \tau_b) = \frac{a}{a + b} . \]
\end{corollary}

\begin{proof}
  By the stopping theorem $B^{\tau_{- a} \wedge \tau_b}$ is a martingale,
  which has uniformly bounded trajectories due to the very definition of
  $\tau_{- a} \wedge \tau_b$: it holds $\sup_{t \geqslant 0} | B^{\tau_{- a}
  \wedge \tau_b}_t | \leqslant | a | \vee | b |$; therefore $B^{\tau_{- a}
  \wedge \tau_b}$ is uniformly integrable. By Corollary~\ref{cor:Bm up and
  down}, the stopping time $\tau_{- a} \wedge \tau_b$ is almost surely finite
  and we get
  
  \begin{align*}
    0 & =\mathbb{E} [B^{\tau_{- a} \wedge \tau_b}_0] =\mathbb{E} [B_{\tau_{-
    a} \wedge \tau_b}]\\
    & =\mathbb{E} [B_{\tau_{- a}} \1_{\tau_{- a} \leqslant \tau_b} +
    B_{\tau_b} \1_{\tau_a > \tau_b}]\\
    & = - a\mathbb{P} (\tau_{- a} \leqslant \tau_b) + b\mathbb{P} (\tau_{- a}
    > \tau_b)
  \end{align*}
  
  Now observe that $\mathbb{P} (\tau_{- a} \leqslant \tau_b) = 1 -\mathbb{P}
  (\tau_{- a} > \tau_b)$, and therefore
  \[ 0 = - a (1 -\mathbb{P}(\tau_{- a} > \tau_b)) + b\mathbb{P} (\tau_{- a} >
     \tau_b) = (a + b) \mathbb{P} (\tau_{- a} > \tau_b) - a, \]
  from where the claim follows (notice that by definition $\tau_{- a} \neq
  \tau_b$).
\end{proof}

\

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on November 21}
  \hrulefill\hrulefill
\end{center}

\

\begin{proof*}{Proof of Theorem~\ref{thm:optional-sampling}}
  It suffices to show ii.}, because then we obtain \tmtextit{i. by
  considering the uniformly integrable martingale $(X_{t \wedge C})_{t
  \geqslant 0}$ (cf. Example~\ref{ex:deterministic.stopped.martingale}).
  
  To show ii.}, define for $n \in \mathbb{N$
  \[ \sigma_n = \sum_{k = 0}^{\infty} (k + 1) 2^{- n} \1_{\{\sigma
     \in [k 2^{- n}, (k + 1) 2^{- n})\}} + \infty \1_{\{\sigma =
     \infty\}} \]
  and similarly for $\tau_n$. Then $\sigma_n$ and $\tau_n$ are stopping times
  and decrease to $\sigma$ and $\tau$, respectively, as $n \rightarrow
  \infty$. It is not hard to see that $\sigma_n$ and $\tau_n$ are also
  stopping times with respect to the discrete time filtration $(\mathcal{F}_{k
  2^{- n}})_{k \geqslant 0}$; moreover, the $\sigma$-algebra
  $\mathcal{F}_{\sigma_n}$ defined w.r.t. $(\mathcal{F}_{k 2^{- n}})_{k
  \geqslant 0}$ coincide with the one defined w.r.t. $(\mathcal{F}_t)_{t
  \geqslant 0}$, similarly for $\tau_n$. We can therefore apply the discrete
  time Optional Sampling Theorem for uniformly integrable martingales
  (Stochastics II) to obtain
  \[ \mathbb{E} [X_{\tau_n} |\mathcal{F}_{\sigma_n}] = X_{\sigma_n} . \]
  Conditioning both sides on $\mathcal{F}_{\sigma}$ and using that $\sigma
  \leqslant \sigma_n$, so that $\mathcal{F}_{\sigma} \subset
  \mathcal{F}_{\sigma_n}$, we obtain
  \[ \mathbb{E} [X_{\tau_n} |\mathcal{F}_{\sigma}] =\mathbb{E} [\mathbb{E}
     [X_{\tau_n} | \mathcal{F}_{\sigma_n}] |\mathcal{F}_{\sigma}] =\mathbb{E}
     [X_{\sigma_n} |\mathcal{F}_{\sigma}] . \]
  Since $X$ is right-continuous, $(X_{\tau_n})_n$ converges almost surely to
  $X_{\tau}$. By the discrete time stopping theorem we know that $X_{\tau_n}
  =\mathbb{E} [X_{\infty} |\mathcal{F}_{\tau_n}]$, and therefore
  $(X_{\tau_n})_n$ is uniformly integrable and the convergence also holds in
  $L^1$. Similarly, $(X_{\sigma_n})_n$ converges in $L^1$ to $X_{\sigma}$, and
  therefore
  \[ \mathbb{E} [X_{\tau} |\mathcal{F}_{\sigma}] = \lim_{n \rightarrow \infty}
     \mathbb{E} [X_{\tau_n} |\mathcal{F}_{\sigma}] = \lim_{n \rightarrow
     \infty} \mathbb{E} [X_{\sigma_n} |\mathcal{F}_{\sigma}] =\mathbb{E}
     [X_{\sigma} |\mathcal{F}_{\sigma}] = X_{\sigma} . \]
  Note that $X_{\tau} \in L^1$ as we just showed that it is the limit in $L^1$
  of the sequence $X_{\tau_n}$; similarly for $X_{\sigma}$.
\end{proof*}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Which parts of the proof of Theorem~\ref{thm:optional-sampling} also work
  for supermartingales, and where did we use the martingale property of $X$
  (as opposed to the supermartingale property)? Compare with the statement of
  Theorem~\ref{thm:optional.supermartingale}.
\end{exercise*}}}{}

\begin{proof*}{Proof of Corollary~\ref{thm:optional-sampling}}
  Since $X$ is c{\`a}dlag, $X^{\tau}$ is also c{\`a}dl{\`a}g due to its
  definition.
  
  First assume that $X$ is uniformly integrable; note that, once we
  prove~\eqref{eq:stopping.theorem}, both martingale and uniform integrability
  properties follow from Remark~\ref{rem:basic.martingale} (and the fact that
  $X_{\tau} \in L^1$, by Theorem~\ref{thm:optional-sampling}). We have
  
  \begin{align*}
    \mathbb{E} [X_{\tau} |\mathcal{F}_t] & =\mathbb{E} [X_{\tau} 
    \1_{\tau \leqslant t} |\mathcal{F}_t] +\mathbb{E} [X_{\tau} 
    \1_{\tau > t} |\mathcal{F}_t]\\
    & = X_{\tau}  \1_{\tau \leqslant t} +\mathbb{E} [X_{\tau \vee t} 
    \1_{\tau > t} |\mathcal{F}_t]\\
    & = X_{\tau}  \1_{\tau \leqslant t} +\mathbb{E} [X_{\tau \vee t}
    |\mathcal{F}_t]  \1_{\tau > t}
  \end{align*}
  
  where in the second step we used that $X_{\tau}  \1_{\tau \leqslant
  t}$ is $\mathcal{F}_t$-measurable (cf. Exercise Sheet 4) and similarly in
  the last step that $\1_{\tau > t}$ is $\mathcal{F}_t$-measurable.
  Since $\tau \vee t$ is a stopping time, $\tau \vee t \geqslant t$, and $X$
  is uniformly integrable, by Theorem~\ref{thm:optional-sampling} we get
  \[ \mathbb{E} [X_{\tau} |\mathcal{F}_t] = X_{\tau}  \1_{\tau
     \leqslant t} + X_t  \1_{\tau > t} = X_{t \wedge \tau} =
     X^{\tau}_t . \]
  Now let $X$ be any c{\`a}dl{\`a}g martingale and fix $t \geqslant 0$. Then
  $X^t$ is a uniformly integrable martingale (cf.
  Example~\ref{ex:deterministic.stopped.martingale}), $(X^t)^{\tau} = X^{t
  \wedge \tau}$; so for any $s \leqslant t$ we get
  \[ \mathbb{E} [X^{\tau}_t | \mathcal{F}_s] =\mathbb{E} [X^{t \wedge \tau}_t
     | \mathcal{F}_s] = X^{t \wedge \tau}_s = X^{\tau}_s . \]
\end{proof*}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}[A random walk embedded in
Brownian motion, this exercise is a bit technical]
  Let $B$ be a Brownian motion and consider the stopping times $\tau_0 \coloneq
  0$ and
  \[ \tau_{n + 1} \coloneq \inf \{ t \geqslant \tau_n : | B_t - B_{\tau_n} | =
     1 \} = \inf \left\{ t \geqslant 0 : \1_{\{ t \geqslant \tau_n \}} | B_t -
     B_{\tau_n} | = 1 \right\} . \]
  Show that $X_n \coloneq B_{\tau_n}$, $n \in \mathbb{N}_0$, is a simple
  symmetric random walk.
\end{exercise*}}}{\ }

{\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
  \textbf{We skipped this remark in the lectures:} With the help of the
  {\emph{Skorokhod embedding theorem}}, one can show that for {\emph{any}}
  centered and square-integrable random walk $(Y_n)_{n \in \mathbb{N}_0}$
  (i.e. $Y_n$ is the sum of i.i.d. centered and square-integrable random
  variables) there exist integrable stopping times $(\tau_n)_{n \in
  \mathbb{N}_0}$ such that $(B_{\tau_n})_{n \in \mathbb{N}_0}$ has the same
  distribution as $(Y_n)_{n \in \mathbb{N}_0}$. Once this result is shown, it
  leads to a relatively simple proof of Donsker's invariance principle. See
  for example Chapters~1.10 and~1.11 of Liggett~{\cite{Liggett2010}}.
\end{tabularx}

\section{Continuous semimartingales}

We saw that the Brownian motion is nowhere differentiable. But we would like
to make sense of stochastic differential equations such as
\[ \partial_t Y_t = b (Y_t) + \sigma (Y_t) \partial_t B_t, \qquad Y_0 = y_0 .
\]
One way of doing so is to integrate both sides from $0$ to $t$, formally
obtaining
\begin{equation}
  Y_t = y_0 + \int_0^t b (Y_s) \mathrm{d} s + \int_0^t \sigma (Y_s) \mathrm{d} B_s .
  \label{eq:sde.sec5}
\end{equation}
In order to make sense of the equation, we construct the stochastic integral
$\int H_s \mathrm{d} X_s$ for suitable processes $H$ and $X$; in particular, we
would like not only to be able to make sense of $\int H_s \mathrm{d} B_s$, but
also of objects of the form $\int H_s \mathrm{d} Y_s$ for processes $Y$ which are
themselves solutions to \eqref{eq:sde.sec5}.

A good class of integrators $X$ turn out to be semimartingales,
i.e. processes $X$ which can be decomposed as $X = M + A$, where $M$ is a
{\emph{local martingale}} and $A$ has paths of finite variation. In
this lecture we will restrict our attention to continuous semimartingales, and
we start by studying some basic properties of semimartingales.

\

{\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
  \textbf{Assumption:} from now on until the end of the lecture notes we
  will assume that our filtration $\mathbb{F}$ satisfies the usual conditions
  -- unless explicitly stated otherwise. It is possible (and sometimes
  crucial) to develop the theory that follows without this assumption, see
  e.g. Jacod-Shiryaev~{\cite{Jacod2003}}, Section~I.4, where the filtration is
  only assumed to be right-continuous (which does not change too much), or von
  Weizs{\"a}cker-Winkler~{\cite{Weizsacker1990}}, Chapters 5 and 6, where not
  even right-continuity is needed (for this we have to be very careful). As
  the material is already technical enough as it is, we prefer to simplify our
  life as much as possible and thus we work under the usual conditions.
  
  Let us also stress that, in the Brownian case, by Blumenthal's 0-1 law
  (Corollary~\ref{cor:blumenthal}), $\mathcal{F}^B_t$ and $\mathcal{F}^B_{t
  +}$ can only differ by trivial sets, i.e. having either probability $0$ or
  $1$. In particular, if we take the completion of $\mathbb{F}^B$ w.r.t. the
  Wiener measure $\mathbb{P}$, it is automatically right-continuous. 
\end{tabularx}

\

Recall the notation for the increment of $X$ from $s$ to $t$: $X_{s, t}
\coloneq X_t - X_s$.

\subsection{Processes of finite variation}

\begin{definition}[Finite variation, total variation]
  Let $T \in (0, + \infty)$. We say that a continuous function $a : [0, T]
  \rightarrow \mathbb{R}$ is of {\emph{finite variation}} on $[0, T]$, i.e. $a
  \in \operatorname{TV} ([0, T])$, if $a (0) = 0$ and its {\emph{total variation}} on
  $[0, T]$ is finite:
  \[ \| a \|_{\operatorname{TV} ([0, T])} \coloneq \sup \left\{ \sum_{k = 0}^{n - 1} |a
     (t_{k + 1}) - a (t_k) | : n \in \mathbb{N}, 0 = t_0 < \ldots < t_n = T
     \right\} < \infty . \]
  We say that a continuous function $a : \mathbb{R}_+ \rightarrow \mathbb{R}$
  is of {\emph{finite variation}}, notation $a \in \operatorname{TV} (\mathbb{R}_+)$,
  if $a|_{[0, T]}$ is of finite variation for all $T \in (0, \infty)$. In that
  case we write
  \[ V (a) (t) \coloneq \| a \|_{\operatorname{TV} ([0, t])}, \quad \forall \, t
     \geqslant 0. \]
\end{definition}

\begin{example}
  \label{ex:finite-variation}{\tmdummy}
  
  \begin{enumerate}
    \item Any $a \in C^1 (\mathbb{R}_+)$ with $a (0) = 0$ is of finite
    variation: If $0 = t_0 < \ldots < t_n = t$, then
    \[ \sum_{k = 0}^{n - 1} |a (t_{k + 1}) - a (t_k) | \leqslant \sum_{k =
       0}^{n - 1} \max_{s \in [t_k, t_{k + 1}]} | a' (s) | \times | t_{k + 1}
       - t_k | \leqslant \max_{s \in [0, t]} | a' (s) | \cdot t. \]
    \item More generally, any absolutely continuous $a : \mathbb{R}_+
    \rightarrow \mathbb{R}$ with $a (0) = 0$ is of finite variation, because
    \[ \sum_{k = 0}^{n - 1} |a (t_{k + 1}) - a (t_k) | = \sum_{k = 0}^{n - 1}
       \left| \int_{t_k}^{t_{k + 1}} a' (s) d s \right| \leqslant \sum_{k =
       0}^{n - 1} \int_{t_k}^{t_{k + 1}} | a' (s) | d s \leqslant \int_0^t |
       a' (s) | d s. \]
    \item Any increasing function $a : \mathbb{R}_+ \rightarrow \mathbb{R}$
    with $a (0) = 0$ is of finite variation, because
    \[ \sum_{k = 0}^{n - 1} |a (t_{k + 1}) - a (t_k) | = \sum_{k = 0}^{n - 1}
       (a (t_{k + 1}) - a (t_k)) = a (t) - a (0) = a (t) . \]
    \item By the previous example, there exist continuous functions $a$ of
    finite variation which are not absolutely continuous: one example is the
    devil's staircase, which is constant outside of the Cantor set
    (which has Lebesgue measure $0$).
    
    \item If $a, b$ are of finite variation, then also $a + b$ is of finite
    variation (follows from the triangle inequality); if $a$ is of finite
    variation, so is $\lambda a$ for any $\lambda \in \mathbb{R}$. In
    particular, $\operatorname{TV} ([0, T])$ is a vector space. 
  \end{enumerate}
\end{example}

The last two examples together show that if $a_+, a_-$ are increasing
functions starting from $0$ and $a = a_+ - a_-$, then $a$ is of finite
variation. Next, we will see that the existence of such a decomposition is
also necessary for $a$ to be of finite variation.

\begin{proposition}
  Let $a \in C (\mathbb{R}_+)$ be such that $a (0) = 0$. The following
  conditions are equivalent:
  \begin{enumerate}
    \item $a \in \operatorname{TV} (\mathbb{R}_+)$.
    
    \item There exist two measures $\mu_+$ and $\mu_-$ on $\mathcal{B}
    (\mathbb{R}_+)$ such that $\mu_{\pm} ([0, T]) < \infty$ for all $T > 0$,
    such that $\mu_+$ and $\mu_-$ are mutually singular (i.e. there exists
    $D_+ \in \mathcal{B} (\mathbb{R}_+)$ with $\mu_+ = \mu_+ (\cdot \cap
    D_+)$ and $\mu_- (D_+) = 0$), and such that
    \[ a (t) = \mu ([0, t]) \coloneq \mu_+ ([0, t]) - \mu_- ([0, t]) . \]
    \item $a$ can be written as the difference of two increasing functions
    $a_+$ and $a_-$, $a (t) = a_+ (t) - a_- (t)$.
  \end{enumerate}
  In this case $\mu_+$ and $\mu_-$ are unique, we write $| \mu | = \mu_+ +
  \mu_-$, and we have
  \[ | \mu | ([0, t]) = V (a) (t) . \]
  We call $\mu$ the (signed) {\emph{measure associated with}} $a$.
\end{proposition}

\begin{remark}
  Note that, since $a$ is continuous, and $\mu_+$ and $\mu_-$ are mutually
  singular, they must be non-atomic: $\mu_{\pm} (\{ t \}) = 0$ for all $t
  \geqslant 0$.
\end{remark}

\begin{proof}
  (Sketch of proof):
  \begin{itemize}
    \item {\emph{i. $\Rightarrow$ ii.}}: One can show that $V (a)$ is
    continuous, see e.g. Friz-Victoir~{\cite{Friz2010}}, Proposition~1.12.
    Define
    \[ a_+ (t) \coloneq \frac{1}{2} (V (a) (t) + a (t)), \qquad a_- (t) \coloneq
       \frac{1}{2} (V (a) (t) - a (t)) . \]
    Then
    \[ a (t) = a_+ (t) - a_- (t), \qquad t \geqslant 0, \]
    and \ $a_{\pm}$ are positive, increasing continuous functions and
    therefore they are the ``distribution functions'' of two measures on
    $\mathcal{B} (\mathbb{R}_+)$, determined via
    
    \begin{gather*}
      \mu_+ ([0, t]) = a_+ (t), \qquad \mu_- ([0, t]) = a_- (t) .
    \end{gather*}
    
    By construction we have $a (t) = \mu_+ ([0, t]) - \mu_- ([0, t])$ and one
    can show that $\mu_+$ and $\mu_-$ are mutually singular and the unique
    mutually singular measures with this property.
    
    {\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
      \textbf{(Sketch of the argument, you may skip this):} Use the
      \href{https://en.wikipedia.org/wiki/Hahn\_decomposition\_theorem\#Jordan\_measure\_decomposition}{Jordan
      decomposition} $\mu = \nu_+ - \nu_-$ of the signed measure $\mu \coloneq
      \mu_+ - \mu_-$, where $\nu_{\pm}$ are mutually singular by definition of
      the Jordan decomposition, and use that
      \[ (\mu_+ + \mu_-) ((s, t]) = V (a) (t) - V (a) (s) \leqslant (\nu_+ +
         \nu_-) ((s, t]) \leqslant (\mu_+ + \mu_-) ((s, t]), \]
      where the second inequality holds by definition of $V (a)$ as a
      supremum, and the last inequality holds because the Jordan decomposition
      is minimal. Since also $\mu_+ - \mu_- = \nu_+ - \nu_-$ we get $\mu_{\pm}
      = \nu_{\pm}$, and then that $\mu_+$ and $\mu_-$ are mutually singular
      because $\nu_+$ and $\nu_-$ are mutually singular.
      
      Uniqueness: Also follows from the Jordan decomposition.
    \end{tabularx}
    
    \item {\emph{ii. {\Rightarrow} iii.}}: Set $a_{\pm} (t) \coloneq \mu_{\pm}
    ([0, t])$.
    
    \item {\emph{iii. $\Rightarrow$ i.}}: This is exactly the discussion in
    Example~\ref{ex:finite-variation}-iii-iv.
  \end{itemize}
\end{proof}

\begin{definition}[Lebesgue-Stieltjes integration]
  Let $a \in C (\mathbb{R}_+) \cap \operatorname{TV} (\mathbb{R}_+)$ and let $h :
  \mathbb{R}_+ \rightarrow \mathbb{R}$ be measurable with $\int_0^T | h (t) |
  | \mu | (\mathrm{d} t) < \infty$ for all $T \geqslant 0$. Then we define
  \[ \int_0^t h (s) \mathrm{d} a (s) \coloneq \int_{[0, t]} h (s) \mu (\mathrm{d} s) =
     \int_{[0, t]} h (s) \mu_+ (\mathrm{d} s) - \int_{[0, t]} h (s) \mu_- (\mathrm{d}
     s), \qquad t \geqslant 0, \]
  and
  \[ \int_0^t h (s) \mathrm{d} V (a) (s) \coloneq \int_{[0, t]} h (s) | \mu |
     (\mathrm{d} s), \qquad t \geqslant 0. \]
  Both $\int_0^{\cdot} h (s) \mathrm{d} a (s)$ and $\int_0^{\cdot} h (s)
  \mathrm{d} V (a) (s)$ are continuous functions (by dominated convergence and the
  atomless property of $| \mu |$), have finite variation and the associated
  measures are $h \mu$ and $h | \mu |$.
\end{definition}

\

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on November 27}
  \hrulefill\hrulefill
\end{center}

\

\begin{example}
  \label{ex:lebesgue.stjeltes.C1}If $a \in C^1 (\mathbb{R}_+)$, then
  \[ \int_0^t h (s) \mathrm{d} a (s) = \int_0^t h (s) a' (s) \mathrm{d} s, \qquad
     \int_0^t h (s) \mathrm{d} V (a) (s) = \int_0^t h (s) |a' (s) | \mathrm{d} s. \]
  Indeed, for $h = \1_{(u, v]}$ this follows from the fundamental theorem of
  calculus, and for more general $h$ we apply the usual approximation
  arguments (``measure-theoretic induction'', e.g. the monotone class theorem,
  cf. Theorem~\ref{thm:monotone.class1}).
\end{example}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Let $a \in C (\mathbb{R}_+) \cap \operatorname{TV} (\mathbb{R}_+)$ and let $h \in C
  (\mathbb{R}_+)$. Show that the integral $\int_0^t h (s) \mathrm{d} a (s)$ can be
  computed as limit of Riemann sums:
  \[ \int_0^t h (s) \mathrm{d} a (s) = \lim_{n \rightarrow \infty} \sum_{k = 0}^{n
     - 1} h \left( \frac{k t}{n} \right) \left( a \left( \frac{(k + 1) t}{n}
     \right) - a \left( \frac{k t}{n} \right) \right) . \]
\end{exercise*}}}{\ }

Now we introduce randomness:

\begin{definition}[Process of finite variation]
  A stochastic process $A = (A_t)_{t \geqslant 0}$ is a {\emph{process of
  finite variation}} if it is adapted, continuous, and $A (\omega) \in
  \operatorname{TV} (\mathbb{R}_+)$ for all $\omega \in \Omega$. In that case we write
  $A \in \mathcal{A}$. If furthermore $A (\omega)$ is increasing for all
  $\omega \in \Omega$, we write $A \in \mathcal{A}^+$.
\end{definition}

If $A \in \mathcal{A}$, then $V (A)$ is a continuous increasing process and
also adapted, so $V (A) \in \mathcal{A}^+$: Indeed, it is possible
(\tmcolor{blue}{exercise!}) to show that
\[ V (A)_t = \lim_{n \rightarrow \infty} \sum_{k = 0}^{n - 1} \left|
   A_{\frac{k + 1}{n} t} - A_{\frac{k}{n} t} \right|  \quad \forall \, t
   \geqslant 0 \]
and for fixed $n$ the sum on the right hand side is obviously
$\mathcal{F}_t$--measurable.

\begin{proposition}
  Let $A \in \mathcal{A}$ and let $H$ be a progressively measurable process
  such that almost surely
  \[ \int_0^T |H_s | \mathrm{d} V (A)_s < \infty \quad \forall \, T \geqslant 0.
  \]
  Then
  \[ \left( \int_0^t H_s \mathrm{d} A_s \right) (\omega) \coloneq \left\{
     \begin{array}{ll}
       \int_0^t H_s (\omega) \mathrm{d} A_s (\omega) \quad & \operatorname{if} \int_0^T
       |H_s | (\omega) \mathrm{d} V (A)_s (\omega) < \infty \text{for all } T
       \geqslant 0,\\
       0 & \operatorname{otherwise},
     \end{array} \right. \]
  defines ($\omega$-wise) a (progressively measureable) process of finite
  variation.
\end{proposition}

\begin{proof}
  Note that by Lemma~\ref{lem:progr mb trajectories} the trajectories of $H$
  are measurable, so both the condition $\int_0^t |H_s | (\omega) \mathrm{d} V
  (A)_s (\omega) < \infty$ and the term $\int_0^t H_s (\omega) \mathrm{d} A_s
  (\omega)$ make sense. By definition, the trajectories
  \[ t \mapsto \left( \int_0^t H_s \mathrm{d} A_s \right) (\omega) \]
  are continuous finite variation functions for all $\omega$, so we only have
  to show that $\int_0^{\cdot} H_s \mathrm{d} A_s$ is adapted. Upon modifying
  $H$ on a null set (recall that our filtration satisfies the usual
  conditions!) we may assume that $\int_0^t |H_s | (\omega) \mathrm{d} V (A)_s
  (\omega) < \infty$ and $(H \cdot A)_t (\omega) = \int_0^t H_s (\omega)
  \mathrm{d} A_s (\omega)$ for all $\omega \in \Omega$ and all $t \geqslant 0$.
  
  Fix $t \geqslant 0$. We first show that $\omega \mapsto \int_0^t \1_B
  (\omega, s) \mathrm{d} A_s (\omega)$ is $\mathcal{F}_t$-measurable for all $B
  \in \mathcal{F}_t \otimes \mathcal{B} ([0, t])$. For $B = B_1 \times (a, b]$
  with $B_1 \in \mathcal{F}_t$ and $0 \leqslant a < b \leqslant t$ or $B = B_1
  \times \{ 0 \}$ this is clear. But these sets are stable by intersection and
  they generate $\mathcal{F}_t \otimes \mathcal{B} ([0, t])$. Moreover, the
  set of all $B \in \mathcal{F}_t \otimes \mathcal{B} ([0, t])$ for which
  $\omega \mapsto \int_0^t \1_B (\omega, s) \mathrm{d} A_s (\omega)$ is
  $\mathcal{F}_t$-measurable is a $\lambda$-system since measurability is
  preserved under pointwise convergence. Therefore, this holds for all $B \in
  \mathcal{F}_t \otimes \mathcal{B} ([0, t])$. By the usual approximation
  argument (``measure-theoretic induction'', first consider $H = \sum_{k =
  1}^n x_k \1_{B_k}$, then positive $H$, then differences of positive
  functions; equivalently the monotone class theorem) it follows that, for all
  progressive $H$ such that $\int_0^t |H_s | \mathrm{d} V (A)_s < \infty$, the
  random variable $\omega \mapsto \int_0^t H_s (\omega) \mathrm{d} A_s (\omega)$
  is $\mathcal{F}_t$-measurable.
\end{proof}

\begin{remark}[Associativity of the Lebesgue-Stieltjes integral]
  \label{rem:associativity.lebesgue-stieltjes}If, for progressive $H, G$,
  almost surely $\int_0^t |H_s | \mathrm{d} V (A)_s < \infty$ and $\int_0^t |G_s
  H_s | \mathrm{d} V (A)_s < \infty$ for all $t \geqslant 0$, then we have
  \[ \int_0^{\cdot} G_s \mathrm{d} \left( \int_0^s H_r \mathrm{d} A_r \right) =
     \int_0^{\cdot} G_s H_s \mathrm{d} A_s, \]
  because $\int_0^{\cdot} H_s \mathrm{d} A_s$ is a finite variation process
  associated to the measure $H \mathrm{d} \mu$, where $\mu$ is the measure
  associated to $A$.
\end{remark}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Let $A (\omega) \in C^1$ for all $\omega$, and let $G (\omega), H (\omega)$
  be continuous for all $\omega$. Verify the identity $\int_0^{\cdot} G_s
  \mathrm{d} \left( \int_0^{\cdot} H_s \mathrm{d} A_s \right) = \int_0^{\cdot} G_s H_s
  \mathrm{d} A_s$ using only elementary (Analysis I) arguments and
  Example~\ref{ex:lebesgue.stjeltes.C1}.
\end{exercise*}}}{\ }

\subsection{Brownian motion and prelude to stochastic integration}

{\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
  \textbf{Disclaimer:} from now on we will always (unless specified)
  consider processes $(X_t)_{t \geqslant 0}$ with continuous time. Whenever
  talking about continuous martingales, we therefore mean martingales with
  $\mathbb{P}$-a.s. continuous paths, not just martingales indexed over
  continuous time $t \in [0, \infty)$.
\end{tabularx}

Let now $B$ be a Brownian motion. If we would have $B \in \mathcal{A}$, then
we could use the results from the last section to construct $\int_0^t H_s
\mathrm{d} B_s$ for suitable integrands $H$. However, we have the following
negative result, informing us that there is no hope to accomplish this
strategy for any continuous martingale!

\begin{lemma}[Continuous finite variation martingales are constant]
  \label{lem:mart not fv}Let $M \in \mathcal{A}$ be a continuous martingale of
  finite variation. Then almost surely $M_t = 0$ for all $t \geqslant 0$.
\end{lemma}

To prove the lemma, we first need a couple of remarks.

\begin{remark}
  \label{rem:mart.orthogonal.increments}Let $M$ be a square integrable
  martingale, then it enjoys the property of \tmtextit{orthogonality of
  increments}: for any $t_1 < t_2 < t_3 < t_4$, it holds
  
  \begin{align*}
    \mathbb{E} [(M_{t_4} - M_{t_3}) (M_{t_2} - M_{t_1})] & =\mathbb{E}
    [\mathbb{E} [(M_{t_4} - M_{t_3}) (M_{t_2} - M_{t_1}) |
    \mathcal{F}_{t_2}]]\\
    & =\mathbb{E} [(M_{t_2} - M_{t_1}) \mathbb{E} [(M_{t_4} - M_{t_3}) |
    \mathcal{F}_{t_2}]]\\
    & = 0.
  \end{align*}
\end{remark}

\tmcolor{blue}{\tmfoldedplain{\begin{exercise*}
  Let $A$ be a process of finite variation, $\tau$ be a stopping time,
  $A^{\tau}_t = A_{t \wedge \tau}$ be the stopped process. Show that $V
  (A^{\tau})_t = V (A)_{t \wedge \tau} = V (A)^{\tau}_t$.
\end{exercise*}}{\ }}

\begin{proof*}{Proof of Lemma~\ref{lem:mart not fv}}
  Since $M \in \mathcal{A}$, the process $V (M)$ is continuous and $V (M)_0 =
  0$.
  
  Without loss of generality, we may assume $M$ and $V (M)$ to be uniformly
  bounded. Indeed, if they weren't, define the stopping time $\tau_m = \inf
  \{t \geqslant 0 : V (M)_t \geqslant m\}$ with $m \in \mathbb{N}$; note that
  \[ | M^{\tau_m}_t | \leqslant V (M^{\tau_m})_t = V (M)^{\tau_m}_t \leqslant
     m \quad \forall \, t \geqslant 0, \]
  where we used the above exercise. By the stopping theorem, $M^{\tau_m}$ is a
  continuous, bounded martingale of finite variation; one we show the
  statement for $M^{\tau_m}$, so that $M^{\tau_m} \equiv 0$, we can send $m
  \rightarrow \infty$ (note that $\mathbb{P}$-a.s. $\tau_m \uparrow + \infty$
  by definition, since we assume $M \in \mathcal{A}$) to conclude that
  $\mathbb{P}$-a.s. $M \equiv 0$ as well.
  
  So now assume  |$M$|, $V (M)$ uniformly bounded by $m$ and fix $t > 0$; for
  $n \in \mathbb{N}$, set $t_k = \frac{kt}{n}$. By Remark
  \ref{rem:mart.orthogonal.increments}, we have
  
  \begin{align*}
    \mathbb{E} [M_t^2] & =\mathbb{E} \left[ \left( \sum_{k = 0}^{n - 1}
    (M_{t_{k + 1}} - M_{t_k}) \right)^2 \right]\\
    & = \sum_{k = 0}^{n - 1} \mathbb{E} [(M_{t_{k + 1}} - M_{t_k})^2 ] + 2
    \sum_{k \neq l} \mathbb{E} [(M_{t_{k + 1}} - M_{t_k}) (M_{t_{\ell + 1}} -
    M_{t_{\ell}})]\\
    & = \sum_{k = 0}^{n - 1} \mathbb{E} [(M_{t_{k + 1}} - M_{t_k})^2 ] .
  \end{align*}
  
  By the definition of total variation we find
  
  \begin{align*}
    \mathbb{E} [M_t^2] & \leqslant \mathbb{E} [V (M)_t \cdot \sup_{k = 0,
    \ldots, n - 1} |M_{t_{k + 1}} - M_{t_k} |]\\
    & \leqslant m\mathbb{E} [\sup_{k = 0, \ldots, n - 1} |M_{t_{k + 1}} -
    M_{t_k} |] .
  \end{align*}
  \[ \  \]
  For $n \rightarrow \infty$, the term inside the expectation goes to zero
  because $M$ is continuous (thus uniformly continuous on $[0, t]$). Since
  moreover $\sup_{t \geqslant 0} | M_t | \leqslant m$, by dominated
  convergence we get $\mathbb{E} [M_t^2] = 0$. Since $t > 0$ was arbitrary,
  the proof is complete.
\end{proof*}

\begin{remark}
  Lemma~\ref{lem:mart not fv} shows that any nontrivial
  {\underline{continuous}} martingale is almost surely of infinite variation.
  For discontinuous martingales this is not true: recall for instance the
  compensated Poisson process of Example~\ref{ex:poisson}.
\end{remark}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Show that the compensated Poisson process is almost surely of finite
  variation (with the same definition of ``finite variation'' that we used for
  continuous functions).
\end{exercise*}}}{}

Since Brownian motion is a continuous martingale and not constant, we deduce
that it is not in $\mathcal{A}$. In fact, it follows from the previous proof
that for any square-integrable martingale $M$ and any partition $0 = t_0 < t_1
< \ldots < t_n = t$ of $[0, t]$, we have:
\begin{equation}
  \mathbb{E} [(M_t - M_0)^2] =\mathbb{E} \left[ \sum_{k = 0}^{n - 1} (M_{t_k,
  t_{k + 1}})^2 \right] ; \label{eq:sum.square.mart.increments}
\end{equation}
so it seems more reasonable to expect that $\sum_{k = 0}^{n - 1} (M_{t_k, t_{k
+ 1}})^2$ converges as $n \rightarrow \infty$, rather than hoping for
convergence of $\sum_{k = 0}^{n - 1} | M_{t_k, t_{k + 1}} |$. We start by
showing this explicitly in the Brownian case.

\begin{lemma}[Quadratic variation of Brownian motion]
  \label{lem:Brownian-qv}Let $t > 0$ and let $0 = t^n_0 < t^n_1 < \ldots <
  t^n_{k_n} = t$ be a sequence of deterministic partitions of $[0, t]$ with
  $\max_{0 \leqslant i < k_n} |t^n_{i + 1} - t^n_i |$ converging to zero as $n
  \rightarrow \infty$. Then
  \[ \lim_{n \rightarrow \infty}  \sum_{i = 0}^{k_n - 1} (B_{t^n_{i + 1}} -
     B_{t^n_i})^2 = t \]
  where the convergence takes place in $L^2 (\Omega, \mathbb{P})$.
  
  We call $\langle B \rangle_t \coloneq t$, $t \geqslant 0$, the
  {\emph{quadratic variation}} of $B$. It is the unique (up to
  indistinguishability) process in $\mathcal{A}^+$ such that $B^2_t - \langle
  B \rangle_t$, $t \geqslant 0$, is a martingale.
\end{lemma}

\begin{proof}
  The variables $(B_{t^n_{i + 1}} - B_{t^n_i})^2_{i = 0, \ldots, k_{n - 1}}$
  are independent and $\mathbb{E} [(B_{t^n_{i + 1}} - B_{t^n_i})^2] = (t^n_{i
  + 1} - t^n_i)$; therefore
  
  \begin{align*}
    \left[ \left( \sum_{i = 0}^{k_n - 1} (B_{t^n_{i + 1}} - B_{t^n_i})^2 - t
    \right)^2 \right] & = \, \operatorname{var} \left( \sum_{i = 0}^{k_n - 1}
    (B_{t^n_{i + 1}} - B_{t^n_i})^2 \right)\\
    & = \, \sum_{i = 0}^{k_n - 1} \operatorname{var} ((B_{t^n_{i + 1}} -
    B_{t^n_i})^2)\\
    & \leqslant \, \sum_{i = 0}^{k_n - 1} \mathbb{E} [(B_{t^n_{i + 1}} -
    B_{t^n_i})^{^4}]\\
    \left( B_{t^n_{i + 1} - t^n_i} \sim \sqrt{t^n_{i + 1} - t^n_i} N,
    \hspace{0.5em} \mathbb{E} [N^4] = 3 \text{for } N \sim \mathcal{N} (0, 1)
    \right) \, & = \, 3 \sum_{i = 0}^{k_n - 1} (t^n_{i + 1} - t^n_i)^2\\
    & \lesssim \, \max_{0 \leqslant k < k_n} |t^n_{k + 1} - t^n_k |  \sum_{i
    = 0}^{k_n - 1} (t^n_{i + 1} - t^n_i)\\
    & = t \cdot \max_{0 \leqslant k < k_n} |t^n_{k + 1} - t^n_k | \,
    \rightarrow 0
  \end{align*}
  
  as $n \rightarrow \infty$ by assumption.
  
  We already saw in Example~\ref{ex:martingales} that $B^2_t - t$ is a
  martingale. If $A \in \mathcal{A}^+$ is another process for which $B^2_t -
  A_t$ is a martingale, then by linearity $t - A_t \in \mathcal{A}$ is a
  continuous martingale of finite variation; therefore $t - A_t$ is
  indistinguishable from $0$ by Lemma~\ref{lem:mart not fv}.
\end{proof}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Let $f \in C^{\alpha} ([0, t])$ with $\alpha \in (\frac{1}{2}, 1]$. Show
  that for any sequence of partitions as in Lemma~\ref{lem:Brownian-qv}, it
  holds
  \[ \lim_{n \rightarrow \infty}  \sum_{i = 0}^{k_n - 1} (f (t^n_{i + 1}) - f
     (t^n_i))^2 = 0. \]
\end{exercise*}}}{\ }

\

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on November 28}
  \hrulefill\hrulefill
\end{center}

\

Refining the arguments from Lemmas~\ref{lem:mart not fv}
and~\ref{lem:Brownian-qv} (see also Exercise Sheet 6) it's easy to show that
\[ \mathbb{P} \left( \| B \|_{\operatorname{TV} ([s, t])} = + \infty \text{ for all }
   0 \leqslant s < t < \infty \right) = 1 \]
(technically we only defined $\operatorname{TV} ([0, t])$, but the definition
immediately generalizes to any interval $[s, t]$). As a consequence, we cannot
hope to integrate general continuous stochastic processes against $B$ naively.
Indeed, for any $n$ and any partition $\pi^n = \{ 0 = t_0 < t_1 < \ldots <
t^n_{k_n} = t \}$, we can find a continuous process $H^{(n)}$ such that
$|H^{(n)}_t (\omega) | \leqslant 1$ for all $t$ and $\omega$ and such that
\[ \sum_{k = 0}^{n - 1} H^{(n)}_{t^n_k} B_{t^n_k, t^n_{k + 1}} = \sum_{k =
   0}^{n - 1} | B_{t^n_k, t^n_{k + 1}} |, \]
\begin{flushleft}
  implying that this quantity can grow without control as $n \rightarrow
  \infty$ and not converge at all. $H^{(n)}$ can be constructed by enforcing
  $H^{(n)}_{t^n_k} = \operatorname{sgn} (B_{t^n_k, t^n_{k + 1}})$ and then extending
  to all other values of $t$ by piecewise linear interpolation (or splines,
  Legendre polynomials, or the numerical scheme you prefer).
\end{flushleft}

However, to construct $H^{(n)}$ one already needs to know $\operatorname{sgn}
(B_{t^n_k, t^n_{k + 1}})$ at time $t^n_k$, so we have to peak into the future.
The brilliant idea of It{\^o} in the 1940s was to restrict the space of
integrands to those that are adapted (more precisely,
{\underline{progressively measurable}}) with respect to the past of $B$ (or
more generally with respect to our filtration $\mathbb{F}$). Moreover, unlike
for the integral against processes of finite variation $A$, we will not freeze
the realization $B (\omega)$ and construct a pathwise integral using real
analysis, but rather we construct the integral as a limit in $L^2$, so using
functional analysis instead. The point is that we want to exploit to the
fullest all the stochastic cancellations coming from the special structure of
the process $B$, similarly to what we did in the construction of the Wiener
integral. Like therein, we will in fact obtain an exact isometry
between $L^2$-spaces.

We will present the construction of stochastic integrals for the much richer
class of continuous (local) martingales, which requires to understand the key
role played by their quadratic variation. In view of this, let us
first run some preliminary computations, starting from candidate Stjeltes-type
integrals: given a filtration $\pi = \{ 0 = t_0 < t_1 < \ldots < t_n = t \}$,
and a collection of bounded random variables $\{ H_{t_k} \}_{k = 1}^n$ such
that $H_{t_k}$ is $\mathcal{F}_{t_k}$-measurable, consider
\[ (H \cdot B)_t = \sum_{k = 0}^{n - 1} H_{t_k} B_{t_k, t_{k + 1}} =
   \text{``} \int_0^t \sum_{k = 0}^n H_{t_k} \1_{[t_k, t_{k + 1})} (s)
   \mathrm{d} B_s \text{''} \]
and let's try to compute its $L^2$-norm:

\begin{align*}
  \mathbb{E} [(H \cdot B)_t^2] & = \sum_{k = 0}^{n - 1} \mathbb{E} [| H_{t_k}
  |^2  | B_{t_k, t_{k + 1}} |^2] + 2 \sum_{k \neq l} \mathbb{E} [H_{t_k}
  B_{t_k, t_{k + 1}} H_{t_l} B_{t_l, t_{l + 1}}] .
\end{align*}

By the martingale property, like in
Remark~\ref{rem:mart.orthogonal.increments}, the terms with $k \neq l$ vanish:
suppose wlog $k < l$, then
\[ \mathbb{E} [H_{t_k} B_{t_k, t_{k + 1}} H_{t_l} B_{t_l, t_{l + 1}}]
   =\mathbb{E} [H_{t_k} B_{t_k, t_{k + 1}} H_{t_l} \mathbb{E} [B_{t_l, t_{l +
   1}} | \mathcal{F}_{t_l}]] = 0. \]
Combined with the independence of increments and stationarity properties of
$B$, we get

\begin{align*}
  \mathbb{E} [(H \cdot B)_t^2] & = \sum_{k = 0}^{n - 1} \mathbb{E} [| H_{t_k}
  |^2 ] (t_{k + 1} - t_k)\\
  & =\mathbb{E} \left[ \sum_{k = 0}^{n - 1} | H_{t_k} |^2 (t_{k + 1} - t_k)
  \right]\\
  & =\mathbb{E} \left[ \int_0^t \sum_{k = 0}^n H_{t_k}^2  \1_{[t_k,
  t_{k + 1})} (s) \mathrm{d} s \right] =\mathbb{E} \left[ \left\| \sum_{k = 0}^n
  H_{t_k}  \1_{[t_k, t_{k + 1})} \right\|_{L^2 ([0, t])}^2 \right]
\end{align*}

which already looks very promising, since all passages were exact equalities!

For general square integrable martingales $M$, if we similarly define $(H
\cdot M)_t$, the same procedure however will not reach a conclusion. We can
still push it as far as possible given our current theory:

\begin{align*}
  \mathbb{E} [(H \cdot M)_t^2] & = \sum_{k = 0}^{n - 1} \mathbb{E} [| H_{t_k}
  |^2  (M_{t_k, t_{k + 1}})^2]\\
  & = \sum_{k = 0}^{n - 1} \mathbb{E} [| H_{t_k} |^2 \mathbb{E} [(M_{t_k,
  t_{k + 1}})^2 | \mathcal{F}_{t_k}]]\\
  & =\mathbb{E} \left[ \sum_{k = 0}^{n - 1} | H_{t_k} |^2 \mathbb{E}
  [(M_{t_k, t_{k + 1}})^2 | \mathcal{F}_{t_k}] \right] .
\end{align*}

Notice again that, by the martingale property, it holds

\begin{align*}
  \mathbb{E} [(M_{t_k, t_{k + 1}})^2 | \mathcal{F}_{t_k}] & =\mathbb{E}
  [M_{t_{k + 1}}^2 | \mathcal{F}_{t_k}] - 2\mathbb{E} [M_{t_{k + 1}} M_{t_k} |
  \mathcal{F}_{t_k}] +\mathbb{E} [M_{t_k}^2 | \mathcal{F}_{t_k}]\\
  & =\mathbb{E} [M_{t_{k + 1}}^2 | \mathcal{F}_{t_k}] - 2 M_{t_k} \mathbb{E}
  [M_{t_{k + 1}} | \mathcal{F}_{t_k}] + M_{t_k}^2\\
  & =\mathbb{E} [M_{t_{k + 1}}^2 | \mathcal{F}_{t_k}] - M_{t_k}^2\\
  & =\mathbb{E} [M_{t_{k + 1}}^2 - M_{t_k}^2 | \mathcal{F}_{t_k}] .
\end{align*}

Inserting this identity in the above we arrive at

\begin{align*}
  \mathbb{E} [(H \cdot M)_t^2] & =\mathbb{E} \left[ \sum_{k = 0}^{n - 1} |
  H_{t_k} |^2 \mathbb{E} [M_{t_{k + 1}}^2 - M_{t_k}^2 | \mathcal{F}_{t_k}]
  \right] .
\end{align*}

Even though $M$ is not of finite variation, the process $t \mapsto M_t^2$
seems to have some monotonicity property, at least w.r.t. conditional
expectation: we just saw that
\[ \mathbb{E} [M^2_{t_{k + 1}} | \mathcal{F}_{t_k}] = M_{t_k}^2 +\mathbb{E}
   [(M_{t_k, t_{k + 1}})^2 | \mathcal{F}_{t_k}] \geqslant M_{t_k}^2 . \]
Based on this intuition, if we could} replace $\mathbb{E [M_{t_{k +
1}}^2 - M_{t_k}^2 | \mathcal{F}_{t_k}]$ with $\mathbb{E} [A_{t_k, t_{k + 1}} |
\mathcal{F}_{t_k}]$, where $A_{t_k, t_{k + 1}}$ denote the increments of a
stochastic process $A \in \mathcal{A}_+$, we would get
\[ \mathbb{E} \left[ (H \cdot M)_t^2 \, \right] =\mathbb{E} \left[ \sum_{k =
   0}^{n - 1} | H_{t_k} |^2 A_{t_k, t_{k + 1}} \right] =\mathbb{E} \left[
   \int_0^t H_{t_k}^2  \1_{[t_k, t_{k + 1})} (s) \mathrm{d} A_s \right] \]
which would somewhat restore the desired isometry property, at the price of
replacing the standard Lebesgue integration $\mathrm{d} t$ we got in the Brownian
case with $\mathrm{d} A_t$. The goal of the next section is to show the existence
of $A$ for a large class of continuous martingales.

\subsection{Continuous martingales and quadratic variations}

It turns out that $L^p$-bounded, continuous martingales have a nice Banach
space structure, at least for $p \in (1, \infty)$. To this end, let us define
\[ \mathcal{H}^{p, c} \coloneq \left\{ (M_t)_{t \geqslant 0} : \, M \text{is a
   continuous martingale, } \| M \|_{\mathcal{H}^{p, c}} \coloneq \sup_{t
   \geqslant 0} \mathbb{E} [| M_t |^p]^{\frac{1}{p}} < \infty \right\} ; \]
notice that, if $M \in \mathcal{H}^{p, c}$, then it is $L^1$-bounded, so that
by the martingale convergence theorem its $\mathbb{P}$-a.s. limit $M_{\infty}$
exists almost surely.

\begin{proposition}
  \label{prop:martingale.space.Hpc}For any $p \in (1, \infty)$,
  $(\mathcal{H}^{p, c}, \| \cdot \|_{\mathcal{H}^{p, c}})$ is a Banach space;
  moreover it is isometric to a closed linear subspace of $L^p (\Omega)$, with
  linear isometry $J$ given by $J M \coloneq M_{\infty}$:
  \[ \| M \|_{\mathcal{H}^{p, c}}^p \coloneq \sup_{t \geqslant 0} \mathbb{E} [|
     M_t |^p] =\mathbb{E} [| M_{\infty} |^p] = \| M_{\infty} \|_{L^p} . \]
  Moreover, $M_t \rightarrow M_{\infty}$ in $L^p$ as $t \rightarrow \infty$.
  An equivalent norm $\| \, \cdot \, \tilde{\|}_{\mathcal{H}^{p, c}}$ for
  $\mathcal{H}^{p, c}$ is given by
  \[ \|M \tilde{\|}_{\mathcal{H}^{p, c}}^p \, \coloneq \mathbb{E} [\| M \|_{C_b
     (\mathbb{R}_+)}^p] \coloneq \mathbb{E} [\sup_{t \geqslant 0} | M_t |^p] .
  \]
  For $p = 2$, $\mathcal{H}^{2, c}$ has a Hilbert space structure, with inner
  product given by
  \begin{equation}
    (M, N)_{\mathcal{H}^{2, c}} \coloneq \mathbb{E} [M_{\infty} N_{\infty}] .
    \label{eq:inner.product.H2c}
  \end{equation}
\end{proposition}

\begin{proof}
  Exercise Sheet 7.
\end{proof}

We will see later that, due to its Hilbert structure and the nice scalar
product given by~\eqref{eq:inner.product.H2c}, the space $\mathcal{H}^{2, c}$
is a natural one where to develop a stochastic integration theory. Convergence
in $\mathcal{H}^{2, c}$ is however very strong, and it implies weaker (but
still extremely useful) notions of convergence like the following.

\begin{definition}[UCP convergence]
  \label{defn:ucp}Let $\{ f^n \}_n$, $f$ be deterministic functions from
  $\mathbb{R}_+$ to $\mathbb{R}$; we say that $f^n$ converge to $f$
  {\emph{uniformly on compact sets}} if
  \[ \lim_{n \rightarrow \infty} \, \sup_{t \in [0, T]} | f^n_t - f_t | = 0
     \quad \forall \, T \in (0, + \infty) . \]
  Let $\{ X^n \}_n$, $X$ be jointly measurable real-valued stochastic
  processes; we say that $X^n$ convergence to $X$ {\emph{uniformly on compacts
  in probability}} if
  \[ \lim_{n \rightarrow \infty} \mathbb{P} (\sup_{t \in [0, T]} | X^n_t - X_t
     | > \varepsilon) = 0 \]
  for all $\varepsilon > 0$ and $T \in (0, + \infty)$. In this case, we write
  $X^n \rightarrow X$ in {\emph{ucp}}, and we refere to above as {\emph{ucp
  convergence}}.
\end{definition}

The space of continuous stochastic processes (possibly adapted to some
reference filtration), endowed to the ucp convergence, has a complete metric
structure.

\begin{lemma}
  \label{lem:ucp.metric}The space of continuous stochastic processes (possibly
  adapted to a reference filtration $\mathbb{F}$) is a complete metric space
  when endowed with the distance
  \[ D^{\operatorname{ucp}} (X, Y) \coloneq \mathbb{E} [D (X, Y)] \coloneq \sum_{k =
     1}^{\infty} \mathbb{E} [2^{- k} \wedge \sup_{t \in [0, k]} | X_t - Y_t |]
  \]
  which induces the ucp convergence.
  
  Moreover if $X^n \rightarrow X$ in ucp, then there exists a subsequence $\{
  X^{n_j} \}_j$ such that, for $\mathbb{P}$-a.e. $\omega$, $X^{n_j} (\omega)
  \rightarrow X (\omega)$ uniformly on compact sets.
\end{lemma}

\begin{proof}
  \begin{tabular}{l}
    We skipped the proof in the lectures, it is included here for
    completeness.
  \end{tabular}
  
  It's easy to check that by construction $D$ (resp. $D^{\operatorname{ucp}}$) is a
  metric on the space $C (\mathbb{R}_+)$ (resp. the space of continuous
  processes); moreover $D$ induces the uniform convergence on compact sets.
  
  Notice that $D (\cdot, \cdot) \leqslant 1$ by construction and that
  \[ \mathbb{E} [1 \wedge \sup_{t \in [0, k]} | X_t - Y_t |] \leqslant 2^k
     D^{\operatorname{ucp}} (X, Y) \quad \forall \, k \in \mathbb{N}. \]
  By Markov's inequality, if $D^{\operatorname{ucp}} (X^n, X) \rightarrow 0$, then
  $\sup_{t \in [0, k]} | X^n_t - X_t | \rightarrow 0$ in probability; as the
  argument holds for any $k$, it follows that $X^n \rightarrow X$ in ucp.
  Conversely, if $X^n \rightarrow X$ in ucp, then each $k$-term in the series
  defining $D^{\operatorname{ucp}} (X^n, X)$ converges to $0$, and by dominated
  convergence so does the whole series.
  
  Suppose now that $\{ X^n \}_n$ is a Cauchy series w.r.t. $D^{\operatorname{ucp}}$,
  then we can extract a subsequence such that $D^{\operatorname{ucp}} (X^{n_j},
  X^{n_{j + 1}}) \leqslant 2^{- j}$, so that
  \[ \mathbb{E} \left[ \sum_{j = 1}^{\infty} D (X^{n_j}, X^{n_{j + 1}})
     \right] = \sum_{j = 1}^{\infty} D^{\operatorname{ucp}} (X^{n_j}, X^{n_{j + 1}})
     \leqslant 1. \]
  It follows that, for $\mathbb{P}$-a.e. $\omega$, $\{ X^{n_j} (\omega) \}_{j
  \in \mathbb{N}}$ is a Cauchy sequence in $(C (\mathbb{R}_+), D)$ and
  therefore admits a unique limit in $C (\mathbb{R}_+)$, which we denote by $X
  (\omega)$:
  \[ \lim_{j \rightarrow \infty} D (X^{n_j} (\omega), X (\omega)) = 0 \quad
     \text{ for } \mathbb{P} \text{-a.e. } \omega . \]
  $X$ is a stochastic process since it is the $\mathbb{P}$-a.s. limit of
  processes, and has continuous trajectories (up to relabelling it on a zero
  probability set) since $(C (\mathbb{R}_+), D)$ is a complete metric space.
  Again by the definition of $D^{\operatorname{ucp}}$ and dominated convergence it's
  easy to see that
  \[ \lim_{j \rightarrow \infty} D^{\operatorname{upc}} (X^{n_j}, X) = \lim_{j
     \rightarrow \infty} \mathbb{E} [D (X^{n_j}, X)] = 0 \]
  and then using the fact that $\{ X^n \}_n$ is Cauchy one can deduce by
  triangular inequality that $\lim_{n \rightarrow \infty} D^{\operatorname{upc}} (X^n,
  X) = 0$. 
\end{proof}

\begin{definition}[$\mathcal{M}^{2, c}$, quadratic variation]
  \label{defn:quadratic.variation}We denote by $\mathcal{M}^{2, c}$ the space
  of continuous, square integrable martingales $(M_t)_{t \geqslant 0}$. Given
  $M \in \mathcal{M}^{2, c}$, {\underline{IF}} there exists a process $A \in
  \mathcal{A}_+$ such that
  \[ M^2_t - M^2_0 - A_t \]
  is a martingale, then we refer to $A$ as the {\emph{quadratic variation}} of
  $M$, and denote it by $\langle M \rangle$.
\end{definition}

\begin{remark}
  \label{rem:qv.first.properties}If $M \in \mathcal{M}^{2, c}$ and $\langle M
  \rangle$ exists, then it is an integrable process: setting $N_t = M^2_t -
  M^2_0 - \langle M \rangle_t$, it holds $\langle M \rangle_t \leqslant M_t^2
  + M_0^2 + | N_t |$, where $M^2$ is integrable since $M \in \mathcal{M}^{2,
  c}$ and $N$ is integrable by definition of being a martingale. Moreover if
  $M_0 = 0$, then
  \[ \mathbb{E} [N_t] =\mathbb{E} [N_0] = 0 \quad \Rightarrow \quad \mathbb{E}
     [M_t^2] =\mathbb{E} [\langle M \rangle_t] \quad \forall \, t \geqslant 0.
  \]
\end{remark}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Show that, if $\langle M \rangle$ exists, so does $\langle M - M_0 \rangle$
  and we have $\langle M - M_0 \rangle = \langle M \rangle$.
\end{exercise*}}}{\ }

\

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on December 4}
  \hrulefill\hrulefill
\end{center}

\

The next basic result guarantees that
Definition~\ref{defn:quadratic.variation} is meaningful.

\begin{lemma}
  \label{lem:qv.basic}Let $M \in \mathcal{M}^{2, c}$. If $\langle M \rangle$
  exists, then it is unique (up to indistinguishability). Moreover, for any
  stopping time $\tau$ it holds that
  \[ \langle M \rangle^{\tau} = \langle M^{\tau} \rangle . \]
\end{lemma}

\begin{proof}
  Like in Lemma~\ref{lem:Brownian-qv}, if $A$ and $\tilde{A}$ are both
  processes in $\mathcal{A}_+$ satisfying the definition of $\langle M
  \rangle$, then
  \[ A - \tilde{A} = (M^2 - M^2_0 - \tilde{A} ) - (M^2 - M^2_0 - A) \]
  is both a continuous martingale and a process in $\mathcal{A}$, thus it is
  $\mathbb{P}$-a.s. identically zero by Lemma~\ref{lem:mart not fv}; namely $A
  \equiv \tilde{A}$ $\mathbb{P}$-a.s.
  
  If $M \in \mathcal{M}^{2, c}$ is such that $\langle M \rangle$ exists, then
  \[ (M^2 - M^2_0 - \langle M \rangle)^{\tau} = (M^{\tau})^2 - M^2_0 - \langle
     M \rangle^{\tau} \]
  is a martingale by the stopping theorem, which by uniqueness implies
  $\langle M^{\tau} \rangle = \langle M \rangle^{\tau}$.
\end{proof}

The main goal of this section is to ensure the existence of $\langle M
\rangle$ and to provide a practical way to construct it. To this end, we need
to introduce some terminology.

We can identify a partition $\pi$ of the real line $\mathbb{R}_+$ with an
increasing (possibly unbounded) sequence of ordered points $0 = t_0 < t_1 <
\ldots < t_n < \ldots$ and thus we can regard $\pi$ as a (finite or countable)
subset of $\mathbb{R}_+$. We will say that $\pi$ is {\emph{locally bounded}}
if $\pi \cap [0, T]$ is a finite set for every $T \in (0, + \infty)$,
equivalently if $\pi$ has no accumulation points (apart from possibly $+
\infty$). The {\emph{mesh}} of a partition $\pi$ is defined by $| \pi | =
\sup_{k \geqslant 0} | t_{k + 1} - t_k |$. Given two partitions $\pi^1$ and
$\pi^2$, we say that $\pi^2$ is a {\emph{refinement}} of $\pi^1$ if $\pi^1
\subset \pi^2$.

Given a sequence of partitions $\{ \pi^n \}_n$ of $\mathbb{R}_+$, we say that:
i) the sequence is {\emph{increasing}} if $\pi^n \subset \pi^{n + 1}$ for all
$n$; ii) the sequence is of {\emph{infinitesimal mesh}} if $\lim_{n
\rightarrow \infty} | \pi^n | = 0$.

\begin{theorem}
  \label{thm:quadratic.variation.existence}Let $M \in \mathcal{M}^{2, c}$,
  then its quadratic variation $\langle M \rangle$ exists. Moreover, for any
  deterministic sequence of locally finite partitions $\{ \pi_n \}_n$ of
  $\mathbb{R}_+$ with infinitesimal mesh, upon defining (for $\pi_n = \{ t^n_k
  \}_{k \geqslant 0}$)
  \[ A^n_t \coloneq \sum_{k \geqslant 0} (M_{t \wedge t^n_k, t \wedge t^n_{k +
     1}})^2 \]
  it holds that
  \begin{equation}
    A^n \rightarrow \langle M \rangle \quad \operatorname{in} \, \tmop{upc} \,
    \operatorname{as} n \rightarrow \infty . \label{eq:existence.qv.upc}
  \end{equation}
  For any locally finite partition $\pi = \{ t_k \}_{k \geqslant 0}$ with $|
  \pi | < \infty$, setting $A^{\pi} \coloneq \sum_{k \geqslant 0} (M_{t \wedge
  t_k, t \wedge t_{k + 1}})^2$, it holds
  \begin{equation}
    \mathbb{E} [\sup_{t \in [0, T]} | A^{\pi}_t - \langle M \rangle_t |^2]
    \lesssim \mathbb{E} [(\sup_{s, t \in [0, T] : | t - s | \leqslant | \pi |}
    | M_{s, t} |^2) \langle M \rangle_T] \label{eq:existence.qv.main.estim}
  \end{equation}
  for any $T \in (0, + \infty)$ (up to allowing both sides
  in~\eqref{eq:existence.qv.main.estim} to take value $+ \infty$).
\end{theorem}

In order to give the proof, we need some preliminary lemmas.

\begin{lemma}
  \label{lem:quadratic.existence.lemma1}Let $M \in \mathcal{M}^{2, c}$, $\pi =
  \{ t_k \}_{k \in \mathbb{N}}$ deterministic and locally finite. Then
  \begin{equation}
    M^2_t - M^2_0 - A^{\pi}_t = 2 \sum_{k = 0}^{\infty} M_{t \wedge t_k} \,
    (M_{t \wedge t_k, t \wedge t_{k + 1}}) \eqqcolon 2 J^{\pi}_t
    \label{eq:quadratic.existence.lemma1}
  \end{equation}
  for all $t \geqslant 0$, where the process $J^{\pi}$ is a continuous
  martingale.
\end{lemma}

\begin{proof}
  In the case of a finite partition of the interval $[0, T]$, this is the
  content of Exercise Sheet 8; the proof here proceeds identically. Notice in
  particular that, under the assumption that $\pi$ is locally finite, the
  series appearing in~\eqref{eq:quadratic.existence.lemma1} is finite for any
  fixed $t \geqslant 0$.
\end{proof}

\begin{lemma}
  \label{lem:quadratic.existence.lemma2}Let $M \in \mathcal{H}^{4, c}$, $0 =
  t_0 < t_1 < \ldots < t_n = t$. Then
  \[ \left\| M_0 M_{0, t} - \sum_{i = 0}^{n - 1} M_{t_i} (M_{t_i, t_{i + 1}})
     \right\|_{L^2}^2 \lesssim \mathbb{E} \left[ \sup_{s \in [0, t]} | M_{0,
     s} |^2 \, \sum_{i = 0}^{n - 1} (M_{t_i, t_{i + 1}})^2 \right] . \]
\end{lemma}

\begin{proof}
  Notice tha all terms appearing have above have the right integrability under
  the assumption $M \in \mathcal{H}^{4, c}$. It holds
  
  \begin{align*}
    (*) \coloneq M_0 M_{0, t} - \sum_{i = 0}^{n - 1} M_{t_i} (M_{t_i, t_{i +
    1}}) & = - \sum_{i = 0}^{n - 1} M_{0, t_i} (M_{t_i, t_{i + 1}})
  \end{align*}
  
  so that
  
  \begin{align*}
    \| (*) \|_{L^2}^2 & = \sum_{i = 0}^{n - 1} \mathbb{E} [(M_{0, t_i})^2
    (M_{t_i, t_{i + 1}})^2] + 2 \sum_{i < j} \mathbb{E} [M_{0, t_i} (M_{t_i,
    t_{i + 1}}) M_{0, t_j} (M_{t_j, t_{j + 1}})]
  \end{align*}
  
  By the martingale property, for any fixed $i < j$, it holds
  \begin{equation}
    \mathbb{E} [M_{0, t_i} (M_{t_i, t_{i + 1}}) M_{0, t_j} (M_{t_j, t_{j +
    1}})] =\mathbb{E} [M_{0, t_i} (M_{t_i, t_{i + 1}}) M_{0, t_j} \mathbb{E}
    [M_{t_j, t_{j + 1}} | \mathcal{F}_{t_j}]] = 0.
    \label{eq:higher.orthogonality}
  \end{equation}
  Combined with the trivial estimate $| M_{0, t_i} |^2 \leqslant \sup_{s \in
  [0, t]} | M_{0, s} |^2$, this yields the conclusion.
\end{proof}

With these preparations, we can now present the

\begin{proof*}{Proof of Theorem~\ref{thm:quadratic.variation.existence}}
  We divide the proof in several steps. To avoid being too repetitive,
  whenever partitions $\pi$ appear in the following, they are taken
  deterministic and locally finite partitions of $\mathbb{R}_+$.
  
  \textbf{Step 1.} We first assume $M$ to be a bounded martingale, namely
  that there exists a deterministic $C > 0$ such that $\mathbb{P}$-a.s.
  $\sup_{t \geqslant 0}  | M_t | \leqslant C$; we will remove this assumption
  at the very end of the proof. Let $\pi_1$, $\pi_2$ be partitions with $\pi^1
  \subset \pi^2$ and consider $A^{\pi_i}$ as defined above. By
  Lemma~\ref{lem:quadratic.existence.lemma1}, taking the difference of the two
  identities given by~\eqref{eq:quadratic.existence.lemma1}, we have
  \[ A^{\pi_1}_t - A^{\pi_2}_t = - 2 (J^{\pi_1}_t - J^{\pi_2}_t) \]
  where $J^{\pi_1} - J^{\pi_2}$ is a continous martingale. By Doob's
  inequality, we have
  \[ \mathbb{E} [\sup_{t \in [0, T]} | J^{\pi_1}_t - J^{\pi_2}_t |^2] \lesssim
     \mathbb{E} [| J^{\pi_1}_T - J^{\pi_2}_T |^2]  \quad \forall \, T \in (0,
     + \infty) . \]
  {\hspace{1.5em}}\textbf{Step 2.} For fixed $T$, we now want to estimate
  the above quantity. Since $\pi^1 \subset \pi^2$, without loss of generality
  we can assume $T \in \pi^1$ (easy to see if you draw a picture). Notice
  that, since $\pi^1 \subset \pi^2$, for any interval $[t_k, t_{k + 1}]$
  coming from $\pi^1$, we find a finite partition by considering
  \[ [t_k, t_{k + 1}] \cap \pi^2 = \{ t_k = s^k_0 < s^k_1 < \ldots < s^k_{n_k}
     = t_{k + 1} \} . \]
  Therefore
  
  \begin{align*}
    J^{\pi_1}_T - J^{\pi_2}_T & = \sum_k J_k \coloneq \sum_k \left( M_{t^n_k}
    \, M_{t^n_k, t^n_{k + 1}} - \sum_{j = 0}^{n_k - 1} M_{s^k_j} \, M_{s^k_j,
    s^k_{j + 1}} \right) .
  \end{align*}
  
  Arguing as in~\eqref{eq:higher.orthogonality}, it's easy to check that
  $\mathbb{E} [J_k J_{\ell}] = 0$ whenever $k \neq \ell$. On the other hand,
  for fixed $k$, by Lemma~\ref{lem:quadratic.existence.lemma2} (for
  $\tilde{M}_s = M_{t^n_k + s}$, w.r.t. the shifted filtration
  $\widetilde{\mathcal{F}_s} = \mathcal{F}_{s + t}$) we get
  
  \begin{align*}
    \| J_k \|_{L^2}^2 & \leqslant \mathbb{E} \left[ \sup_{s \in [t^n_k, t^n_{k
    + 1}]} | M_{t^n_k, s} |^2 \, \sum_{j = 0}^{n_k - 1} | M_{s^k_j, s^k_{j +
    1}} |^2 \right]\\
    & \leqslant \mathbb{E} \left[ \sup_{u, s \in [0, T] : | u - s | \leqslant
    | \pi^1 |}   | M_{u, s} |^2  \sum_{j = 0}^{n_k - 1} | M_{s^k_j, s^k_{j +
    1}} |^2 \right]
  \end{align*}
  
  so that
  \begin{eqnarray}
    \| J^{\pi_1}_T - J^{\pi_2}_T \|_{L^2}^2 & = & \sum_k \| J_k \|^2
    \nonumber\\
    & \leqslant & \mathbb{E} \left[ \sup_{u, s \in [0, T] : | u - s |
    \leqslant | \pi^1 |}   | M_{u, s} |^2  \sum_k \sum_{j = 0}^{n_k - 1} |
    M_{s^k_j, s^k_{j + 1}} |^2 \right] \nonumber\\
    & = & \mathbb{E} [\sup_{u, s \in [0, T] : | u - s | \leqslant | \pi^1 |} 
    | M_{u, s} |^2 A^{\pi_2}_T] .  \label{eq:intermediate.qv}
  \end{eqnarray}
  \textbf{{\hspace{1.5em}}Step 3.} Consider now the increasing sequence of
  dyadic partitions $\pi^n = \{ 2^{- n} k \}_{k \in \mathbb{N}}$, which is of
  infinitesimal mesh. We want to show that $\{ A^{\pi_n} \}_n$ is a Cauchy
  sequence in the ucp topology; in fact we will check something slightly
  stronger, namely that
  \begin{equation}
    \lim_{n \rightarrow \infty} \sup_{m \geqslant n} \mathbb{E} [\sup_{t \in
    [0, T]} | A^{\pi_n}_t - A^{\pi_m}_t |^2] = 0 \quad \forall \, T \in (0, +
    \infty) . \label{eq:intermediate.qv.goal}
  \end{equation}
  By the previous manipulations, Doob's inequality
  and~\eqref{eq:intermediate.qv} we arrive at
  
  \begin{align*}
    \mathbb{E} [\sup_{t \in [0, T]} | A^{\pi_n}_t - A^{\pi_m}_t |^2] &
    \lesssim \mathbb{E} [\sup_{u, s \in [0, T] : | u - s | \leqslant 2^{- n}} 
    | M_{u, s} |^2 A^{\pi_{n + m}}_T]\\
    & \leqslant \mathbb{E} [\sup_{u, s \in [0, T] : | u - s | \leqslant 2^{-
    n}}   | M_{u, s} |^4]^{1 / 2} \mathbb{E} [ (A^{\pi_{n + m}}_T)^2]^{1 / 2}
    .
  \end{align*}
  
  The first term is bounded and thus infinitesimal by dominated convergence,
  since $M$ is bounded by assumption and uniformly continuous on compact sets;
  so we only need to provide a uniform-in-$m$ estimate for the second term.
  
  Since $M$ is bounded and (again by
  Lemma~\ref{lem:quadratic.existence.lemma1}) $A^{\pi_{n + m}}_T = M^2_T -
  M^2_0 - 2 J^{\pi_{n + m}}_T$, by triangular inequality this is the same as
  bounding $J^{n + m}_T$ in $L^2$. By the ``orthogonality of increments''
  property~\eqref{eq:higher.orthogonality}, we have
  
  \begin{align*}
    \mathbb{E} [| J^{\pi_{n + m}}_T |^2] & =\mathbb{E} \left[ \sum_{k
    \geqslant 0} | M_{t^{n + m}_k \wedge T} |^2 | M_{t^{n + m}_k \wedge T,
    t^{n + m}_{k + 1} \wedge T} |^2 \right]\\
    & \leqslant C^2 \mathbb{E} \left[ \sum_{k \geqslant 0} | M_{t^{n + m}_k
    \wedge T, t^{n + m}_{k + 1} \wedge T} |^2 \right]\\
    & = C^2 \mathbb{E} [| M_T - M_0 |^2] \lesssim C^4
  \end{align*}
  
  where in the intermediate passage we
  used~\eqref{eq:sum.square.mart.increments}. Overall we conclude that
  \[ \sup_{m \geqslant n} \mathbb{E} [\sup_{t \in [0, T]} | A^{\pi_n}_t -
     A^{\pi_m}_t |^2] \lesssim C^4 \mathbb{E} [\sup_{u, s \in [0, T] : | u - s
     | \leqslant 2^{- n}}   | M_{u, s} |^4]^{1 / 2} \]
  which yields~\eqref{eq:intermediate.qv.goal}. Therefore $(A^{\pi_n})_n$ is
  Cauchy and admits a unique limit in ucp, as well as in $L^2 (\Omega ; C ([0,
  T]))$ for any fixed $T \in (0, + \infty)$; denote it by $A$. For fixed $n$,
  by construction
  \[ A^{\pi_m}_0 = 0, \quad A^{\pi_{n + m}}_{(k + 1) 2^{- n}} \geqslant
     A^{\pi_{n + m}}_{k 2^{- n}} \quad \forall \, m \geqslant 0 \]
  therefore passing to the limit the same properties hold true for $A$; since
  dyadic points densify on $\mathbb{R}_+$ and $A$ is continuous, we deduce
  that $A$ is increasing and so $A \in \mathcal{A}_+$.
  
  \textbf{Step 4.} Since $A^{\pi_n}_t \rightarrow A_t$ in $L^2$ and $M^2 -
  M^2_0 - A^{\pi_n}$ is a martingale for each $n$, by passing to the limit we
  deduce that $M^2 - M^2_0 - A$ is a martingale as well. Since $A \in
  \mathcal{A}_+$, this proves that $A$ is the (unique) quadratic variation of
  $M$, $A = \langle M \rangle$.
  
  \textbf{Step 5.} Proof of~\eqref{eq:existence.qv.main.estim}: given a
  partition $\pi$, we can always find an increasing sequence $\{ \pi^n \}_n$
  with infinitesimal mesh with $\pi^1 = \pi$; the previous estimates
  (cf.~\eqref{eq:intermediate.qv}) yield
  \[ \mathbb{E} [\sup_{t \in [0, T]} | A^{\pi}_t - A^{\pi_n}_t |^2] \lesssim
     \mathbb{E} [(\sup_{s, t \in [0, T] : | t - s | \leqslant | \pi |} | M_{s,
     t} |^2)  | A^{\pi_n}_T |] \]
  and we can now pass to the limit as $n \rightarrow \infty$, since $A^{\pi_n}
  \rightarrow \langle M \rangle$, to deduce
  that~\eqref{eq:existence.qv.main.estim} holds. As a consequence
  of~\eqref{eq:existence.qv.main.estim}, given any sequence of partitions
  $\pi^n$ of infinitesimal mesh, not necessarily increasing, we have
  \[ \limsup_{n \rightarrow \infty} \mathbb{E} [\sup_{t \in [0, T]} |
     A^{\pi_n}_t - \langle M \rangle_t |^2] \lesssim \limsup_{n \rightarrow
     \infty} \mathbb{E} [(\sup_{s, t \in [0, T] : | t - s | \leqslant | \pi^n
     |} | M_{s, t} |^2) \langle M \rangle_T] = 0. \]
  {\hspace{1.5em}}\textbf{Step 6.} Finally, we remove the assumption that
  $M$ is bounded by a {\emph{localization argument}}. Let $M \in
  \mathcal{M}^{2, c}$ and define the stopping times $\tau_n = \inf \{ t
  \geqslant 0 : | M_t | \geqslant n \}$. Clearly $\tau_n$ is an increasing
  sequence, and moreover for $\mathbb{P}$-a.e. $\omega$ we have $\tau_n
  (\omega) \uparrow + \infty$ since $M (\omega)$ is continuous (thus bounded
  on compact sets). By the stopping theorem, $M^{\tau_n}$ is a bounded
  continuous martingale, so the previous steps apply and $\langle M^{\tau_n}
  \rangle \in \mathcal{A}_+$ is well-defined. Moreover, for $m \geqslant n$,
  by Remark~\ref{rem:qv.first.properties} it holds $\langle M^{\tau_m}
  \rangle^{\tau_n} = \langle M^{\tau_n} \rangle$ and so we can consistently
  define
  \[ \langle M \rangle_t (\omega) = \left\{\begin{array}{l}
       \langle M^{\tau_n} \rangle_t (\omega)  \quad \text{if there exists $n$
       such that } t \leqslant \tau_n (\omega)\\
       0 \hspace{5.1em} \operatorname{otherwise} .
     \end{array}\right. . \]
  It's easy to check that $\langle M^{\tau_n} \rangle \rightarrow \langle M
  \rangle$ in ucp since
  \[ \mathbb{P} (\sup_{t \in [0, T]} | \langle M \rangle_t - \langle
     M^{\tau_n} \rangle_t | > \varepsilon) \leqslant \mathbb{P} (\tau_n < T)
     \rightarrow 0 \text{ as } n \rightarrow \infty . \]
  By properties of ucp convergence, $\langle M \rangle \in \mathcal{A}_+$
  since $\langle M \rangle^{\tau_n}$ do so. Taking $m \rightarrow \infty$ in
  the above relation, we also get $\langle M \rangle^{\tau_n} = \langle
  M^{\tau_n} \rangle$; since $\langle M \rangle$ is increasing, by monotone
  convergence and Remark~\ref{rem:qv.first.properties} we get
  \[ \mathbb{E} [\langle M \rangle_t] = \lim_{n \rightarrow \infty} \mathbb{E}
     [\langle M \rangle_{t \wedge \tau_n}] = \lim_{n \rightarrow \infty}
     \mathbb{E} [\langle M \rangle^{\tau_n}_t] = \lim_{n \rightarrow \infty}
     \mathbb{E} [M^2_{\tau_n \wedge t}] =\mathbb{E} [M^2_t] \]
  where in the last step we used the fact that $(M^2_{\tau_n \wedge t})_n$ is
  uniformly integrable since by Doob's inequality
  \[ M^2_{\tau_n \wedge t} \leqslant \sup_{s \in [0, t]} M^2_s  \quad \forall
     \, n, \quad \mathbb{E} [\sup_{s \in [0, t]} M^2_s] \lesssim \mathbb{E}
     [M^2_t] < \infty . \]
  The same arguments show that, for any fixed $t$, $\langle M
  \rangle^{\tau_n}_t \rightarrow \langle M \rangle_t$ and $(M^{\tau_n}_t)^2
  \rightarrow M_t^2$ in $L^1$, so that from
  \[ \mathbb{E} [(M^{\tau_n}_t)^2 - M_0^2 - \langle M \rangle^{\tau_n}_t |
     \mathcal{F}_s] = (M^{\tau_n}_s)^2 - M_0^2 - \langle M \rangle^{\tau_n}_s
  \]
  we can pass to the limit to conclude that $M^2 - M_0^2 - \langle M \rangle$
  is a martingale.
\end{proof*}

{\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
  \textbf{Extra comment:} The proof actually yields the relation
  \begin{equation}
    M^2_t - M^2_0 - \langle M \rangle_t = \lim_{n \rightarrow \infty} 2 \sum_k
    M_{t^n_k} (M_{t^n_{k + 1} \wedge t} - M_{t^n_k}) = \tmcolor{blue}{2
    \int_0^t M_s \mathrm{d} M_s} \label{eq:baby.ito}
  \end{equation}
  where the last term is a stochastic integral, as we will see
  later; equation~\eqref{eq:baby.ito} will be a prototypical example of the
  It\^{o} formula.
  
  Equation~\eqref{eq:baby.ito} can also be interpreted as a failure of the
  classical chain rule: if $M$ were classically differentiable, by
  the fundamental theorem of calculus we should have found
  \[ M^2_t - M^2_0 = 2 \int_0^t M_s M'_s \mathrm{d} s = 2 \int_0^t M_s \mathrm{d} M_s
  \]
  without any term $\langle M \rangle$ appearing. The fact that $M$ is not
  $C^1$ is not surprising (if it were, it would be of finite variation, thus
  $M \equiv 0$ by Lemma~\ref{lem:mart not fv}), but~\eqref{eq:baby.ito}
  actually tells us that {\emph{standard rules of calculus}} do not apply for
  martingales. This is the reason why we will need to develop a theory of
  {\emph{stochastic calculus}} instead, which is nontrivial and truly requires
  to exploit the cancellations coming from a probabilistic framework (i.e. the
  martingale property).
  
  In the proof, in order to show that $(A^n)_n$ is Cauchy, it was actually
  easier to work with $(J^n)_n$, the corresponding approximations of the
  stochastic integral. With the combined information coming from $(M, \langle
  M \rangle)$ at hand, \ we will be able to set up a far reaching theory of
  stochastic integration.
  
  This fact bears a strong similarity with much more recent and pathwise
  theories of integration coming from {\emph{rough path theory}}, see the
  monographs {\cite{Friz2010,Friz2014}}: loosely speaking, given some signal
  $X$, in order to rigorously define objects of the form $\int_0^{\cdot} F
  (X_s) \mathrm{d} X_s$, one first needs to {\emph{enhance}} the signal by
  {\emph{postulating}} (or, in our case, proving) the existence of the
  iterated integral $\mathbb{X}_t \coloneq \int_0^{\cdot} X_s \mathrm{d} X_s$; once
  the pair $(X, \mathbb{X})$ is fixed, then the integrals $\int_0^{\cdot} F
  (X_s) \mathrm{d} X_s$ are also uniquely determined for any smooth bounded
  function $F$.
\end{tabularx}

\

\

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on December 5}
  \hrulefill\hrulefill
\end{center}

\begin{definition}[Quadratic covariation]
  \label{defn:quadratic.covariation}Let $M, N \in \mathcal{M}^{2, c}$. We
  define the {\emph{quadratic covariation}} of $M$ and $N$ as the
  process
  \[ \langle M, N \rangle \coloneq \frac{1}{4} \langle M + N \rangle -
     \frac{1}{4} \langle M - N \rangle . \label{eq:quadratic.covariation} \]
\end{definition}

Notice the analogy of~\eqref{eq:quadratic.covariation} with a polarization
formula (recall the discussion in the proof of Lemma~\ref{lem:wiener-int}).

\begin{proposition}
  \label{prop:properties.quadratic.covariation}Let $M$, $N \in \mathcal{M}^{2,
  c}$. Then:
  \begin{enumerate}
    \item $\langle M, N \rangle$ is the unique (up to indistinguishability)
    process in $\mathcal{A}$ such that
    \[ M N - M_0 N_0 - \langle M, N \rangle \]
    is a martingale.
    
    \item For any sequence of deterministic locally finite partitions $\pi^n =
    \{ t^n_k \}_{k \in \mathbb{N}}$ of $\mathbb{R}_+$ with infinitesimal mesh
    $\lim_{n \rightarrow \infty} | \pi^n | = 0$, it holds that
    \[ \sum_{k = 0}^{\infty} M_{t^n_k \wedge t, t^n_{k + 1} \wedge t} N_{t^n_k
       \wedge t, t^n_{k + 1} \wedge t} \rightarrow \langle M, N \rangle_t
       \qquad \text{in ucp} . \]
    \item The map $(M, N) \mapsto \langle M, N \rangle$ is bilinear and
    symmetric, and for any bounded stopping time $\tau$ it holds that
    \[ \langle M, N \rangle^{\tau} = \langle M^{\tau}, N^{\tau} \rangle =
       \langle M^{\tau}, N \rangle . \]
  \end{enumerate}
\end{proposition}

\begin{proof}
  Exercise Sheet 8.
\end{proof}

Part~a) of the above Proposition (and possibly a passage to the limit
procedure $t \rightarrow \infty$) immediately imply the following.

\begin{corollary}
  \label{cor:link.quadratic.product}If $M, N \in \mathcal{M}^{2, c}$ and
  either $M_0 = 0$ or $N_0 = 0$, then for any $t \in [0, \infty)$ it holds
  $\mathbb{E} [\langle M, N \rangle_t] =\mathbb{E} [M_t N_t]$. If additionally
  $M, N \in \mathcal{H}^{2, c}$, then
  \[ \mathbb{E} [\langle M, N \rangle_{\infty}] =\mathbb{E} [M_{\infty}
     N_{\infty}] = (M, N)_{\mathcal{H}^{2, c}} . \]
\end{corollary}

\begin{remark}
  \label{rem:qcv.independent-bm}If $B^1$ and $B^2$ are independent Brownian
  motions, we have seen in Example~\ref{ex:martingales} that $B^1 B^2$ is a
  martingale, so that
  \[ \langle B^1, B^2 \rangle \equiv 0. \]
  In fact more generally, if $M, N \in \mathcal{M}^{2, c}$ are independent,
  then necessarily $\langle M, N \rangle \equiv 0$.
\end{remark}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Let $f : \mathbb{R}_+ \rightarrow \mathbb{R}_+$ be a deterministic
  continuous increasing function and let $M_t = B_{f (t)}$ for a Brownian
  motion $B$. Show that $M$ is a continuous martingale in its own filtration
  and $\langle M \rangle_t = f (t)$.
\end{exercise*}}}{\ }

\subsection{Continuous local martingales}

We have already seen in the proofs of Lemma~\ref{lem:mart not fv} and
Theorem~\ref{thm:quadratic.variation.existence} that whenever dealing with
martingales, it is very convenient to employ some {\emph{localization
procedures}} by introducing convenient families of stopping times. It might
therefore not be surprising that several of the results presented so far can
be extended to a larger class of objects than just continuous, square
integrable martingales.

\begin{definition}[$\mathcal{M}^c$, localizing sequence, local martingale]
  \begin{enumerate}
    \item We write $\mathcal{M}^c$ for the set of all continuous martingales.
    
    \item A {\emph{localizing sequence}} is an increasing sequence of stopping
    times $(\tau_n)_n$ with $\lim_{n \rightarrow \infty} \tau_n = \infty$
    almost surely.
    
    \item An adapted process $M$ is called a {\emph{local martingale}} if
    there exists a localizing sequence $(\tau_n)_n$ such that, for each $n \in
    \mathbb{N}$, the stopped process
    \[ (M - M_0)^{\tau_n} = M^{\tau_n} - M_0 = (M^{\tau_n} - M_0)
       \1_{\tau_n > 0} \]
    is a martingale. If in addition $M$ is continuous, we say that $M$ is a
    {\emph{continuous local martingale}}, we write $M \in
    \mathcal{M}^c_{\operatorname{loc}}$ and we call $(\tau_n)_n$ a {\emph{localizing
    sequence for }}$M$.
  \end{enumerate}
\end{definition}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Show that every martingale is a local martingale.
\end{exercise*}}}{}

\begin{remark}
  \label{rem:first.properties.local.mart}{\tmdummy}
  
  \begin{enumerate}
    \item We do not require local martingales to be integrable. Indeed, not
    even $M_0$ needs to be integrable, and even in the case $M_0 = 0$, it
    might happen that $M_t$ is not integrable.
    
    \item Every martingale is a local martingale. (Exercise above)
    
    \item {\emph{Stability under stopping}}: if $M \in
    \mathcal{M}^c_{\operatorname{loc}}$ (respectively $M \in \mathcal{M}^c$) and
    $\tau$ is a stopping time, then $M^{\tau} \in \mathcal{M}^c_{\operatorname{loc}}$
    (respectively $M^{\tau} \in \mathcal{M}^c$). Indeed note that
    $(M^{\tau})^{\tau_n} = (M^{\tau_n})^{\tau} = M^{\tau_n \wedge \tau}$ and
    then apply the stopping theorem.
    
    \item Linear combinations of local martingales are martingales: if $M, N
    \in \mathcal{M}^c_{\operatorname{loc}}$, then $\lambda M + N \in
    \mathcal{M}^c_{\operatorname{loc}}$ for all $\lambda \in \mathbb{R}$.
    (\tmcolor{blue}{Exercise!})
    
    \item For every $M \in \mathcal{M}^c_{\operatorname{loc}}$ there exists a
    localizing sequence of stopping times $(\tau_n)_n$ such that $(M -
    M_0)^{\tau_n}$ is a uniformly integrable martingale for all $n \in
    \mathbb{N}$: just replace $\tau_n$ by $\tau_n \wedge n$. The same argument
    shows that we can assume $\tau_n$ to be a bounded stopping time for each
    fixed $n$.
  \end{enumerate}
\end{remark}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Show that $M$ is a local martingale if and only if there exists (another)
  localizing sequence $(\tilde{\tau}^n)_n$ such that $M^{\tilde{\tau}_n} 
  \1_{\tilde{\tau}_n > 0}$ is a martingale.
\end{exercise*}}}{\ }

\begin{lemma}
  \label{lem:locmart-properties}Let $M \in \mathcal{M}^c_{\operatorname{loc}}$.
  \begin{enumerate}
    \item If $M$ is non-negative (i.e. $\mathbb{P}$-a.s. $M_t \geqslant 0$ for
    every $t \geqslant 0$) and $M_0 \in L^1$, then $M$ is a supermartingale.
    
    \item If $\sup_{t \geqslant 0} |M_t | \in L^1$, then $M$ is a uniformly
    integrable martingale.
    
    \item If $M \in \mathcal{M}^c_{\operatorname{loc}}$, then $\tilde{\tau}_n \coloneq
    \tau_n \wedge n$, where $\tau_n \coloneq \inf \{t \geqslant 0 : |M_t - M_0
    | \geqslant n\}$, is a localizing sequence for $M$.
    
    \item If $X_0$ is $\mathcal{F}_0$-measurable, then $\tilde{M}_t = M_t X_0$
    satisfies $\tilde{M} \in \mathcal{M}^c_{\operatorname{loc}}$.
    
    \item If $M \in \mathcal{M}^c_{\operatorname{loc}}$ and $X_0$ is
    $\mathcal{F}_0$-measurable, then $M - X_0 \in \mathcal{M}^c_{\operatorname{loc}}$.
  \end{enumerate}
\end{lemma}

\begin{proof}
  Exercise Sheet~9.
\end{proof}

\begin{remark}
  \label{rem:locmart.vs.mart}Given point~ii. of
  Lemma~\ref{lem:locmart-properties}, we might feel tempted to guess that
  every uniformly integrable local martingale is a martingale. But this is not
  true. In fact, one can even
  construct example of $M \in \mathcal{M}^c_{\operatorname{loc}}$ such that $\sup_{t
  \geqslant 0} \mathbb{E} [| M_t |^2] < \infty$ but $M \notin \mathcal{M}^c$.
\end{remark}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}[hard]
  Show that, if $\{ M^n \}_n$ is a sequence in $\mathcal{M}^c_{\operatorname{loc}}$
  such that $M^n \rightarrow M$ in ucp, then $M \in
  \mathcal{M}^c_{\operatorname{loc}}$. In other words, $\mathcal{M}^c_{\tmop{loc}}$ is
  closed under convergence in ucp. (Hint: Lemma~\ref{lem:ucp.metric
  might come in handy})
\end{exercise*}}}{\ }

Several of the results we have presented so far for martingales readily extend
to local martingales by localization arguments.

\begin{lemma}
  \label{lem:locmart not fv}Let $M \in \mathcal{A} \cap
  \mathcal{M}^c_{\operatorname{loc}}$, then $\mathbb{P}$-almost surely $M_t = 0$ for
  all $t \geqslant 0$ (which we write compactly as $\mathbb{P}$-a.s. $M \equiv
  0$).
\end{lemma}

\begin{proof}
  It follows from the corresponding result for martingales
  (Lemma~\ref{lem:mart not fv}) by localization. Indeed, let $(\tau_n)_n$ be a
  localizing sequence for $M$, then $M^{\tau_n} \in \mathcal{A} \cap
  \mathcal{M}^c$ (recall that $V (M^{\tau_n}) = V (M)^{\tau_n}$) and thus
  $M^{\tau_n} \equiv 0$ for all $n \in \mathbb{N}$. Letting $\tau_n
  \rightarrow \infty$ we get $M \equiv 0$.
\end{proof}

\begin{proposition}
  \label{prop:qvlocMG}Let $M \in \mathcal{M}^c_{\mathrm{loc}}$. Then there
  exists an increasing process $\langle M \rangle \in \mathcal{A}^+$ with
  $\langle M \rangle_0 = 0$, unique up to indistinguishability, such that
  \begin{equation}
    M^2 - M^2_0 - \langle M \rangle \in \mathcal{M}^c_{\mathrm{loc}}
    \label{eq:qvlocMG}
  \end{equation}
  which we call the {\emph{quadratic variation}} of $M$. Moreover for any
  sequence of deterministic locally finite partitions $\pi^m = \{ t^m_k \}_{k
  \in \mathbb{N}}$ of $\mathbb{R}_+$ with infinitesimal mesh, it holds that
  \begin{equation}
    \sum_{k = 0}^{\infty} (M_{t^m_k \wedge t, t^m_{k + 1} \wedge t})^2
    \rightarrow \langle M \rangle_t \qquad \text{in ucp} . \label{eq:qvlocMG2}
  \end{equation}
\end{proposition}

\begin{proof}
  The proof is mostly a variation on the one of
  Theorem~\ref{thm:quadratic.variation.existence}, up to localization
  arguments (already contained therein).
  
  It suffices to consider the case $M_0 = 0$, as the general one follows from
  the relation $\langle M - M_0 \rangle = \langle M \rangle$, cf. Exercise
  Sheet~9. Let $(\tau_n)_n$ be a localizing sequence for $M$, which we may
  assume wlog to be such that $M^{\tau_n} \in \mathcal{M}^{2, c}$ by
  Lemma~\ref{lem:locmart-properties}-iii. Then for each $\tau_n$, $\langle
  M^{\tau_n} \rangle$ exists and by monotonicity of $\tau_n$ it provides an
  increasing-in-$n$ family of processes, so that
  \[ \langle M \rangle_t = \lim_{n \rightarrow \infty} \langle M^{\tau_n}
     \rangle_t \]
  exists and satisfies $\langle M \rangle^{\tau_n} = \langle M^{\tau_n}
  \rangle$; from this property and the fact that
  \[ (M^{\tau_n})^2 - \langle M^{\tau_n} \rangle = (M^2 - \langle M
     \rangle)^{\tau_n} \]
  is a martingale, we conclude that $\langle M \rangle$ is the desired
  quadratic variation. By Theorem~\ref{thm:quadratic.variation.existence} we
  also get
  \[ \sum_{k = 0}^{\infty} (M^{\tau_n}_{t^m_k \wedge t, t^m_{k + 1} \wedge
     t})^2 = \sum_{k = 0}^{\infty} (M_{t^m_k \wedge t \wedge \tau_n, t^m_{k +
     1} \wedge t \wedge \tau_n})^2 \rightarrow \langle M^{\tau_n} \rangle_t =
     \langle M \rangle_{t \wedge \tau_n} \qquad \text{in ucp} \]
  from which we can deduce~\eqref{eq:qvlocMG2} thanks to the property that
  $\mathbb{P}$-a.s. $\tau_n \uparrow + \infty$ (for any fixed interval $[0,
  T]$, we can find $n$ large enough such that $\mathbb{P} (\tau_n < T) <
  \varepsilon$, and apply the ucp convergence for $\langle M^{\tau_n} \rangle$
  on the event $\{ \tau_n \geqslant T \}^{}$).
\end{proof}

As in the case of square integrable $M$, $N \in \mathcal{M}^c$, we define the
quadratic covariation of $M, N \in \mathcal{M}^c_{\operatorname{loc}}$ by formula
\[ \langle M, N \rangle \coloneq \frac{1}{4}  (\langle M + N \rangle - \langle
   M - N \rangle) \in \mathcal{A}. \]
In analogy with Proposition~\ref{prop:properties.quadratic.covariation}, we
have the following result.

\begin{proposition}
  \label{prop:qcv.local.mart}Let $M, N \in \mathcal{M}_{\operatorname{loc}}^c$.
  \begin{enumerate}
    \item $\langle M, N \rangle$ is the unique (up to indistinguishability)
    process in $\mathcal{A}$ such that $MN - M_0 N_0 - \langle M, N \rangle$
    is a local martingale.
    
    \item The map $(M, N) \mapsto \langle M, N \rangle$ is bilinear and
    symmetric.
    
    \item For any sequence of deterministic locally finite partitions $\pi^m =
    \{ t^m_k \}_{k \in \mathbb{N}}$ of $\mathbb{R}_+$ with infinitesimal mesh,
    $\sum_{k = 0}^{\infty} (M_{t^m_k \wedge t, t^m_{k + 1} \wedge t})
    (N_{t^m_k \wedge t, t^m_{k + 1} \wedge t}) \rightarrow \langle M, N
    \rangle_t$ in ucp.
    
    \item If $\tau$ is a stopping time, we have $\langle M, N \rangle^{\tau} =
    \langle M^{\tau}, N^{\tau} \rangle = \langle M^{\tau}, N \rangle$.
    
    \item $\langle M, N \rangle = \langle M - M_0, N - N_0 \rangle$.
  \end{enumerate}
\end{proposition}

\begin{proof}
  The proof is almost identical to that of
  Proposition~\ref{prop:properties.quadratic.covariation}, up to localization
  arguments. Only notice the key differences: in~i. we can only
  deduce that we still have a local martingale, while in iv. we can
  allow any stopping time $\tau$, not necessarily bounded (because we don't
  have the problem of possible failure of integrability, coming from the
  requirement of martingality). Part~v. is new and based on the
  basic property that $\langle M - M_0 \rangle = \langle M \rangle$ (which
  holds true for martingales, cf. the exercise after
  Remark~\ref{rem:qv.first.properties}, thus also true for local martingales
  by localization); cf. also Exercise Sheet 9.
\end{proof}

\begin{lemma}[Kunita-Watanabe inequality, first version]
  \label{lem:kunita-wanatabe.v1}Let $M, N \in \mathcal{M}_{\operatorname{loc}}^c$.
  Then $\mathbb{P}$-almost surely
  \[ | \langle M, N \rangle_{s, t} | \leqslant V (\langle M, N \rangle)_{s, t}
     \leqslant \langle M \rangle_{s, t}^{1 / 2} \langle N \rangle_{s, t}^{1 /
     2}  \quad \forall \, s \leqslant t < \infty . \]
  Similarly, $\mathbb{P}$-a.s.
  \[ \limsup_{t \rightarrow \infty} | \langle M, N \rangle_t | \leqslant V
     (\langle M, N \rangle)_{\infty} \leqslant \langle M \rangle_{\infty}^{1 /
     2} \langle N \rangle_{\infty}^{1 / 2} \]
  where the second and third terms are always defined by monotonicity
  (possibly as $+ \infty$). 
\end{lemma}

\

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on December 11}
  \hrulefill\hrulefill
\end{center}

\

\begin{proof}
  Fix any $s < t$, then we can construct a series of increasing partitions
  $\pi^n$ with infinitesimal mesh such that $\pi^1 = \{ s, t \}$. In this case
  it follows that, for each fixed $n$, $\pi^n \cap [s, t]$ is a partition of
  $[s, t]$ and so by Proposition~\eqref{prop:qvlocMG} $\mathbb{P}$-a.s. it
  holds
  
  \begin{align*}
    | \langle M, N \rangle_{s, t} | & = \lim_{n \rightarrow \infty} \left|
    \sum_k M_{t^n_k, t^{n + 1}_k} N_{t^n_k, t^{n + 1}_k} \right|\\
    & \leqslant \lim_{n \rightarrow \infty} \left( \sum_k (M_{t^n_k, t^{n +
    1}_k})^2 \right)^{1 / 2} \left( \sum_k (N_{t^n_k, t^{n + 1}_k})^2
    \right)^{1 / 2}\\
    & = \langle M \rangle_{s, t}^{1 / 2} \langle N \rangle_{s, t}^{1 / 2} .
  \end{align*}
  
  Having shown the result for fixed $s < t$, we can find a set of full
  probability where the inequality holds for all rational $s < t$ and finally
  extend to all $s < t$ by continuity of the paths of $\langle M, N \rangle$,
  $\langle M \rangle$ and $\langle N \rangle$.
  
  Having established the first inequality, again by Cauchy--Schwarz, for $s =
  t_0 < \ldots < t_n = t$ it holds:
  \[ \sum_{k = 0}^{n - 1} | \langle M, N \rangle_{t_k, t_{k + 1}} | \leqslant
     \sum_{k = 0}^{n - 1} \langle M \rangle_{t_k, t_{k + 1}}^{1 / 2} \langle N
     \rangle_{t_k, t_{k + 1}}^{1 / 2} \leqslant \langle M \rangle_{s, t}^{1 /
     2} \langle N \rangle_{s, t}^{1 / 2} \]
  which by definition of total variation yields
  \[ V (\langle M, N \rangle)_{s, t} \leqslant \langle M \rangle_{s, t}^{1 /
     2} \langle N \rangle_{s, t}^{1 / 2} . \]
  The final inequality follows by taking $s = 0$ and sending $t \rightarrow
  \infty$.
\end{proof}

We will shortly see a very powerful result relating moment bounds for $M \in
\mathcal{M}^c_{\operatorname{loc}}$ to moment bounds for $\langle M \rangle$, see
Theorem~\ref{thm:BDG} below. To this end, we first need some preparations.

\begin{definition}[Lenglart's domination relation]
  \label{defn:lenglart.domination}Let $(X_t)_{t \geqslant 0}$, $(G_t)_{t
  \geqslant 0}$ be progressive, non-negative processes. We say that $X$ is
  {\emph{dominated}} by $G$ if
  \begin{equation}
    \mathbb{E} [X_{\tau}] \leqslant \mathbb{E} [G_{\tau}] \quad \text{ for all
    bounded stopping times } \tau \label{eq:lenglart.domination}
  \end{equation}
  with the convention that $+ \infty \leqslant + \infty$.
\end{definition}

In the following, given a continuous stochastic process $X$, it will be
convenient to denote by $X^{*}$ its running supremum (in modulus), namely
$X^{*}_t = \sup_{s \in [0, t]} | X_s |$.

\begin{lemma}[Lenglart's inequalities]
  \label{lem:lenglart.ineq}Let $X$ be a non-negative, continuous adapted
  process, and let $G$ be a non-negative, increasing, continuous adapted
  process; assume that $X$ is dominated by $G$, in the sense of
  Definition~\ref{defn:lenglart.domination}. Then:
  \begin{enumerate}
    \item For any $a, b > 0$, it holds
    \begin{equation}
      \mathbb{P} (\sup_{t \geqslant 0} X_t \geqslant a) \leqslant \frac{1}{a}
      \mathbb{E} [\sup_{t \geqslant 0} G_t \wedge b] +\mathbb{P} (\sup_{t
      \geqslant 0} G_t > b) . \label{eq:lenglart.ineq1}
    \end{equation}
    \item For any $\theta \in (0, 1),$it holds
    \begin{equation}
      \mathbb{E} [(X^{*}_{\infty})^{\theta}] \leqslant \frac{\theta^{-
      \theta}}{1 - \theta} \mathbb{E} [G_{\infty}^{\theta}] .
      \label{eq:lenglart.ineq2}
    \end{equation}
  \end{enumerate}
\end{lemma}

\begin{proof}
  Exercise Sheet~8.
\end{proof}

\begin{remark}
  Often inequality~\eqref{eq:lenglart.ineq1} is stated in its weaker but more
  practical version
  \begin{equation}
    \mathbb{P} (\sup_{t \geqslant 0} X_t \geqslant a) \leqslant \frac{b}{a}
    +\mathbb{P} (\sup_{t \geqslant 0} G_t > b) . \label{eq:lenglart.ineq1bis}
  \end{equation}
\end{remark}

\

We are now ready to state and partially prove the following result. It is one
of the most useful martingale inequalities, with countless applications.

\begin{theorem}[Burkholder--Davis--Gundy inequality, BDG for short]
  \label{thm:BDG}
  
  For any $p \in (0, \infty)$, there exist universal constants $c_p, C_p > 0$
  such that for any $M \in \mathcal{M}^c_{\operatorname{loc}}$ with $M_0 = 0$, setting
  $M^{*}_t = \sup_{s \leqslant t}  | M_s |$, it holds
  \begin{equation}
    c_p \mathbb{E} [\langle M \rangle_{\infty}^{p / 2}] \leqslant \mathbb{E}
    [(M^{*}_{\infty})^p] \leqslant C_p \mathbb{E} [\langle M
    \rangle_{\infty}^{p / 2}] \label{eq:BDG}
  \end{equation}
  with the convention that $+ \infty \leqslant + \infty$.
\end{theorem}

\tmtextit{Comment: It is customary to say that the constants $c_p$ and $C_p$
are ``{\emph{universal}}'' because they can be taken the same for all local
martingales on any probability space whatsoever.}

\begin{proof}
  We will only prove the inequality for $p \in (0, 4]$, see the comments after
  the proof for the case $p > 4$.
  
  We claim that, once we show the estimate for $p = 4$, all the other cases
  will follow. Indeed, by applying the inequality for $p = 4$ for $M$ replaced
  by $M^{\tau}$, with $\tau$ a finite stopping time, we obtain
  \[ \mathbb{E} [c_4 \langle M \rangle_{\tau}^2] \leqslant \mathbb{E}
     [(M^{*}_{\tau})^4] \leqslant \mathbb{E} [C_4 \langle M
     \rangle_{\tau}^2] ; \]
  in other words, $c_4 \langle M \rangle_{\tau}^2$ is dominated (in the sense
  of Definition~\ref{defn:lenglart.domination}) by $(M^{*}_{\tau})^4$,
  which in turn is dominated by $C_4 \langle M \rangle_{\tau}^2$. Therefore by
  Lenglart's inequality~\eqref{eq:lenglart.ineq2} we find
  \[ c_4^{\theta}  \left( \frac{\theta^{- \theta}}{1 - \theta} \right)^{- 1}
     \mathbb{E} [\langle M \rangle_{\infty}^{2 \theta}] \leqslant \mathbb{E}
     [(M^{*}_{\infty})^{4 \theta}] \leqslant \frac{\theta^{- \theta}}{1 -
     \theta} C_4^{\theta} \mathbb{E} [\langle M \rangle_{\infty}^{2 \theta}]
     \quad \forall \, \theta \in (0, 1) \]
  which yields the conclusion upon taking $p = 4 \theta$ for $p \in (0, 4)$.
  
  It remains to consider the case $p = 4$. Up to localization, we may assume
  $M$ and $\langle M \rangle$ to be bounded processes; arguing as in
  Lemmas~\ref{lem:quadratic.existence.lemma1}
  and~\ref{lem:quadratic.existence.lemma2}, for any fixed partition $\pi$ of
  $\mathbb{R}_+$ and any $t \geqslant 0$, we have the relation
  \[ M^2_t - A^{\pi}_t = 2 \sum_{k = 0}^{\infty} M_{t \wedge t_k} \, (M_{t
     \wedge t_k, t \wedge t_{k + 1}}) \eqqcolon 2 J^{\pi}_t \]
  with $J^{\pi}$ being a martingale, and by Doob's inequality and usual
  computations based on martingale increments we have
  
  \begin{align*}
    \mathbb{E} [\sup_{s \in [0, t]} | M^2_s - A^{\pi}_s |] & \lesssim
    \mathbb{E} [| J^{\pi}_t |^2] =\mathbb{E} \left[ \sum_{k = 0}^{\infty} |
    M_{t \wedge t_k} |^2 \, (M_{t \wedge t_k, t \wedge t_{k + 1}})^2 \right]\\
    & \leqslant \mathbb{E} \left[ | M^{*}_t |^2  \sum_{k = 0}^{\infty} \,
    (M_{t \wedge t_k, t \wedge t_{k + 1}})^2 \right]
  \end{align*}
  
  so that after passing to the limit as we take a sequence of partitions we
  find
  \[ \mathbb{E} [\sup_{s \in [0, t]} | M^2_s - \langle M \rangle_s |^2]
     \lesssim \mathbb{E} [| M^{*}_t |^2 \langle M \rangle_t] \]
  and now sending $t \rightarrow \infty$ we get
  \[ \mathbb{E} [\sup_{t \geqslant 0} | M^2_t - \langle M \rangle_t |^2]
     \leqslant C\mathbb{E} [| M^{*}_{\infty} |^2 \langle M
     \rangle_{\infty}] \]
  for some $C > 0$. We show how to get one of the estimates, the other case
  being identical upon inverting the roles of $| M^{*} |^2$ and $\langle M
  \rangle$. By the basic inequality $(a + b)^2 \leqslant 2 (a^2 + b^2)$
  \[ \begin{align*}
       \mathbb{E} [| M_{\infty}^{*} |^4] & =\mathbb{E} [\sup_{t \geqslant
       0} | M_t^2 \pm \langle M \rangle_t |^2]\\
       & \leqslant 2\mathbb{E} [\sup_{t \geqslant 0} | M^2_t - \langle M
       \rangle_t |^2] + 2\mathbb{E} [\langle M \rangle_{\infty}^2]\\
       & \leqslant 2 C\mathbb{E} [| M^{*}_{\infty} |^2 \langle M
       \rangle_{\infty}] + 2\mathbb{E} [\langle M \rangle_{\infty}^2]\\
       & \leqslant \mathbb{E} \left[ \frac{1}{2} | M^{*}_{\infty} |^4 + 2
       C^2 \langle M \rangle_{\infty}^2 \right] + 2\mathbb{E} [\langle M
       \rangle_{\infty}^2]\\
       & = \frac{1}{2} \mathbb{E} [| M^{*}_{\infty} |^4] + (2 C^2 + 2)
       \mathbb{E} [\langle M \rangle_{\infty}^2]
     \end{align*} \]
  where in the intermediate passage we used the basic inequality $a b
  \leqslant \frac{a^2}{2} + \frac{b^2}{2}$, for $a = | M^{*}_{\infty} |^2$
  and $b = 2 C \langle M \rangle_{\infty}$. After rearraging the last
  inequality so that $\mathbb{E} [| M^{*}_{\infty} |^4]$ only appears on
  the l.h.s., we get the conclusion.
\end{proof}

{\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
  \textbf{Comments and bibliography:}
  \begin{itemize}
    \item In terms of applications, the second inequality in~\eqref{eq:BDG} is
    the truly relevant one. The first inequality in~\eqref{eq:BDG} informs us
    that by estimating $\mathbb{E} [(M^{*}_{\infty})^p]$ by $\mathbb{E}
    [\langle M \rangle_{\infty}^{p / 2}]$ we are not ``losing too much
    information'' as the two quantities are comparable.
    
    \item For discontinuous martingales, the BDG inequalities are still true,
    but only for the range of exponents $p \in [1, \infty)$; note however that
    for discontinuous processes we cannot apply Lenglart's inequalities, so
    the above proof does not work.
    
    \item We might see later (possibly in Exercise sheets), once we have
    access to stochastic calculus tools, how to prove BDG inequality for $p >
    4$. For proofs not relying on stochastic calculus, see Chapter IV.42
    from~{\cite{Rogers2000Vol2}}; the proof therein, solely requires the
    existence of $\langle M \rangle$ and is based on so called ``{\emph{good
    $\lambda$ inequalities}}''. It is fairly robust as it not only holds for
    $x \mapsto | x |^p$, but more generally for {\emph{moderate}} functions $F
    (x)$.
    
    \item There exist more recent and stronger {\emph{pathwise versions}} of
    BDG inequalities, valid for both discrete and c{\`a}dl{\`a}g martingales;
    see the works~{\cite{Beiglbock2015,Siorpaes2018}}.
  \end{itemize}
\end{tabularx}

\

From Theorem~\ref{thm:BDG} and localization arguments, we immediately deduce
the following.

\begin{corollary}[Local BDG inequality]
  \label{cor:localBDG}For any $p \in (0, \infty)$ there exist universal
  constants $c_p, C_p > 0$ such that for any $M \in
  \mathcal{M}^c_{\operatorname{loc}}$ with $M_0 = 0$ and any stopping time $\tau$,
  setting $M^{*}_t = \sup_{s \leqslant t}  | M_s |$, it holds
  \[ c_p \mathbb{E} [\langle M \rangle_{\tau}^{p / 2}] \leqslant \mathbb{E}
     [(M^{*}_{\tau})^p] \leqslant C_p \mathbb{E} [\langle M
     \rangle_{\tau}^{p / 2}] \]
  with the convention that $+ \infty \leqslant + \infty$.
\end{corollary}

\begin{corollary}
  \label{cor:lp-martingale}Let $M \in \mathcal{M}_{\operatorname{loc}}^c$ with $M_0 =
  0$ and let $p \in (1, \infty)$.
  \begin{enumerate}
    \item The following are equivalent:
    \begin{enumerate}
      \item $M \in \mathcal{H}^{p, c}$;
      
      \item $\mathbb{E} [\langle M \rangle_{\infty}^{p / 2}] < \infty$;
      
      \item $\mathbb{E} [\sup_{t \geqslant 0}  | M_t |^p] < \infty$.
    \end{enumerate}
    If additionally $p \geqslant 2$, then under either of the above
    conditions, $M^2 - \langle M \rangle$ is a uniformly integrable martingale
    and in particular $\mathbb{E} [M_{\infty}^2] =\mathbb{E} [\langle M
    \rangle_{\infty}]$.
    
    \item The following are equivalent:
    \begin{enumerate}
      \item $M$ is a $p$-integrable martingale;
      
      \item $\mathbb{E} [\langle M \rangle_t^{p / 2}] < \infty$ for all $t
      \geqslant 0$;
      
      \item $\mathbb{E} [\sup_{s \in [0, t]}  | M_s |^p] < \infty$ for all $t
      \geqslant 0$.
    \end{enumerate}
    If additionally $p \geqslant 2$, then under either of the above
    conditions, $M^2 - \langle M \rangle$ is a martingale and in particular
    $\mathbb{E} [M_t^2] =\mathbb{E} [\langle M \rangle_t]$ for all $t
    \geqslant 0$.
  \end{enumerate}
\end{corollary}

\textbf{N.b.:} compare the above result with
Remark~\ref{rem:locmart.vs.mart}; note that the statement is not true anymore
if we try to replace point~c) by $\sup_{t \geqslant 0} \mathbb{E} [| M_t |^p]
< \infty$ (resp $\sup_{s \in [0, t]} \mathbb{E} [| M_s |^p] < \infty$).

\begin{proof}
  Equivalence between a) and b) in Part~i. comes from Exercise
  Sheet 9; equivalence between a) and c) was already stated
  in~Proposition~\ref{prop:martingale.space.Hpc}. Uniform integrability is
  again part of Exercise Sheet~9, while $\mathbb{E} [M_{\infty}^2] =\mathbb{E}
  [\langle M \rangle_{\infty}]$ comes from
  Corollary~\ref{cor:link.quadratic.product}. Concerning part~ii.,
  it suffices to apply i. to the uniformly integrable martingales $(M_{t
  \wedge n})_{t \geqslant 0}$, for $n \in \mathbb{N}$.
\end{proof}

Lenglart's inequality allows to derive useful criteria for convergence in the
ucp topology.

\begin{corollary}
  \label{cor:ucp.criterion.locmart}Let $\{ M^n \}_n$, $M \in
  \mathcal{M}^c_{\operatorname{loc}}$ with $M^n_0 = M_0$ for all $n$. Then $\langle
  M^n - M \rangle \rightarrow 0$ in ucp if and only if $M^n \rightarrow M$ in
  ucp.
\end{corollary}

\begin{proof}
  Exercise Sheet~9.
\end{proof}

\

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on December 12}
  \hrulefill\hrulefill
\end{center}

\subsection{Continuous semimartingales}

\begin{definition}
  An adapted process $X = (X_t)_{t \ge 0}$ is a {\emph{continuous
  semimartingale}} if it has a decomposition
  \begin{equation}
    \label{eq:semimgdec} X = X_0 + M + A
  \end{equation}
  into a continuous local martingale $M \in \mathcal{M}_{\operatorname{loc}}^c$ and a
  continuous process $A \in \mathcal{A}$ of finite variation, both with $M_0 =
  A_0 = 0$.
\end{definition}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Show that continuous semimartingales form a vector space, i.e. if $X$ and
  $Y$ are continuous semimartingales then so is $X + \lambda Y$ for every
  $\lambda \in \mathbb{R}$.
\end{exercise*}}}{\ }

\begin{lemma}
  \label{lem:decomposition.semimartingale}The decomposition
  (\ref{eq:semimgdec}) of a continuous semimartingale $X$ into $M$ and $A$ is
  unique (up to indistinguishability).
\end{lemma}

\begin{proof}
  If $X - X_0 = M + A = N + B$ are two decompositions, then $M - N = B - A$ is
  in $\mathcal{M}_{\operatorname{loc}}^c \cap \mathcal{A}$ and hence indistinguishable
  from the $0$ process by Lemma~\ref{lem:locmart not fv}.
\end{proof}

\begin{definition}
  If $X = X_0 + M + A$ and $Y = Y_0 + N + B$ are continuous semimartingales,
  we define the quadratic covariation of $X$ and $Y$ as $\langle X, Y \rangle
  \coloneq \langle M, N \rangle$. In particular, the quadratic variation of $X$
  is $\langle X \rangle \coloneq \langle M \rangle$.
\end{definition}

Note that $\langle X \rangle$ is uniquely defined thanks to
Lemma~\ref{lem:decomposition.semimartingale}, it is consistent with our
definition for the quadratic covariation for local martingales, and
\[ \langle X, Y \rangle = \langle X - X_0, Y - Y_0 \rangle, \qquad \langle X,
   Y \rangle^{\tau} = \langle X^{\tau}, Y^{\tau} \rangle = \langle X^{\tau}, Y
   \rangle \]
in agreement with Proposition~\ref{prop:qcv.local.mart}.

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  According to the above definition, deduce from the Kunita--Watanabe
  inequality (Lemma~\ref{lem:kunita-wanatabe.v1}) that
  \[ | \langle X, Y \rangle_{s, t} | \leqslant V (\langle X, Y \rangle)_{s, t}
     \leqslant \langle X \rangle_{s, t}^{1 / 2} \langle Y \rangle_{s, t}^{1 /
     2}  \quad \forall \, s \leqslant t < \infty \]
  holds in this case we well.
\end{exercise*}}}{\ }

\begin{lemma}
  \label{lem:qvlocSMG}For any continuous semimartingales $X$, $Y$ and any
  sequence of deterministic locally finite partitions $\pi^m = \{ t^m_k \}_{k
  \in \mathbb{N}}$ of $\mathbb{R}_+$ with infinitesimal mesh, it holds that
  \begin{equation}
    \sum_{k = 0}^{\infty} X_{t^m_k \wedge t, t^m_{k + 1} \wedge t} Y_{t^m_k
    \wedge t, t^m_{k + 1} \wedge t} \rightarrow \langle X, Y \rangle_t \qquad
    \text{in ucp} . \label{eq:qvlocSMG}
  \end{equation}
\end{lemma}

\begin{proof}
  By polarization we can reduce to $X = Y$; we can also assume $X_0 = 0$, so
  that $X = M + A$. We already know that
  \[ \sum_{k = 0}^{\infty} (M_{t^m_k \wedge t, t^m_{k + 1} \wedge t})^2
     \rightarrow \langle M \rangle_t \qquad \text{in ucp} \]
  so by developing the square it only remaines to show that
  \begin{equation}
    \sum_{k = 0}^{\infty} M_{t^m_k \wedge t, t^m_{k + 1} \wedge t} A_{t^m_k
    \wedge t, t^m_{k + 1} \wedge t} + \sum_{k = 0}^{\infty}  (A_{t^m_k \wedge
    t, t^m_{k + 1} \wedge t})^2 \rightarrow 0 \qquad \text{in ucp} .
    \label{eq:qvlocSMG.proof}
  \end{equation}
  Notice that by Cauchy
  \[ \sum_{k = 0}^{\infty} M_{t^m_k \wedge t, t^m_{k + 1} \wedge t} A_{t^m_k
     \wedge t, t^m_{k + 1} \wedge t} \leqslant \left( \sum_{k = 0}^{\infty}
     (M_{t^m_k \wedge t, t^m_{k + 1} \wedge t})^2 \right)^{1 / 2}  \left(
     \sum_{k = 0}^{\infty} (A_{t^m_k \wedge t, t^m_{k + 1} \wedge t})^2
     \right)^{1 / 2} \]
  where we already have convergence in upc to $\langle M \rangle$ for the
  first term; so~\eqref{eq:qvlocSMG.proof} follows one we show that the second
  term is infinitesimal. This is actually a result which you already solved in
  Exercise Sheet 7, but let us give the proof for completeness.
  
  Fix $T \in (0, + \infty)$. Since $A$ is continuous, it is uniformly
  continuous on $[0, T]$; on the other hand it is of finite variation,
  therefore for any $t \in [0, T]$ we have
  
  \begin{align*}
    \sum_{k = 0}^{\infty} (A_{t^m_k \wedge t, t^m_{k + 1} \wedge t})^2 &
    \leqslant \, \sup_k | A_{t^m_k \wedge t, t^m_{k + 1} \wedge t} |  \sum_{k
    = 0}^{\infty} | A_{t^m_k \wedge t, t^m_{k + 1} \wedge t} |\\
    & \leqslant \left( \sup_{\tmscript{\begin{array}{l}
      0 \leqslant u \leqslant s \leqslant T\\
      | u - s | \leqslant | \pi^m |
    \end{array}}} | A_{u, s} | \right)  \| A \|_{\operatorname{TV} ([0, T])}
  \end{align*}
  
  where the estimate holds $\omega$-wise, is uniform in $t \in [0, T]$, and
  the first term vanishes as $m \rightarrow \infty$ by the assumption and
  uniform continuity.
\end{proof}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Let $M \in \mathcal{M}^c_{\operatorname{loc}}$. Show that $M^2$ is a continuous
  semimartingale.
\end{exercise*}}}{\ }

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}[very hard given our current
tools at disposal]
  Let $X$ be a continuous semimartingale. Show that $X^2$ is a semimartingale.
\end{exercise*}}}{\ }

\section{Stochastic integration}

We now have in place all the ingredients to finally construct the stochastic
It{\^o} integral $\int_0^{\cdot} H_s \mathrm{d} X_s$, for suitable stochastic
integrands $H$ and with respect to (henceforth abbreviated {\emph{w.r.t.}})
continuous semimartingales $X$ as integrators. Although the resulting theory
is already quite rich under these assumptions, requiring continuity of $X$ is
mostly for technical convenience; see for example Protter~{\cite{Protter2004}}
for a theory of stochastic integration w.r.t. c{\`a}dl{\`a}g semimartingales.

To develop the theory, we will proceed by steps: we first define
$\int_0^{\cdot} H_s \mathrm{d} M_s$ for {\emph{elementary processes}} $H$ and
martingales $M \in \mathcal{M}^{2, c}$, then extend the definition to general
$H$ by {\emph{It\^{o} isometry}}, and then further extend it to $M \in
\mathcal{M}^c_{\operatorname{loc}}$ by {\emph{localization}}. We finally extend the
definition to continuous semimartingales $X = M + A$ by linearity. Along the
way, special attention will be given to the case where $M = B$ Brownian
motion.

Recall that in the following we are always on a filtered probability space
$(\Omega, \mathcal{F}, \mathbb{F}, \mathbb{P})$ satisfying the usual
conditions.

\subsection{Stochastic integrals of simple processes}

We start by defining stochastic integrals in the simplest possible case, where
we can ``guess'' a meaningful definition just by enforcing linearity of the
integration and the property that $\int_s^t \mathrm{d} M_u = M_{s, t}$ whenever $s
< t$.

\begin{definition}[Bounded elementary processes]
  We denote by $b\mathcal{E}$ the set of {\emph{bounded elementary
  processes}}, namely processes $H$ of the form
  \begin{equation}
    H_t (\omega) = \sum_{k = 0}^{n - 1} h_k (\omega) \1_{(t_k, t_{k +
    1}]} (t) \label{eq:defn.elementary.process}
  \end{equation}
  for some given $n \in \mathbb{N}$, $0 \leqslant t_0 < t_1 < \ldots < t_n$,
  and random variables $\{ h_k \}_{k = 0}^{n - 1}$ such that $h_k \in
  L^{\infty} (\mathcal{F}_{t_k})$ for all $k \le n$.
\end{definition}

\begin{remark}
  Note that $H$ is left-continuous and adapted, and therefore progressively
  measurable. Moreover, it is easy to check that $b\mathcal{E}$ is a linear
  vector space.
\end{remark}

Recall previously introduced notations: $\mathcal{M}^{2, c}$ denote square
integrable continuous martingales, while $\mathcal{H}^{2, c}$ denote
$L^2$-bounded continuous martingales (the latter is a Hilbert space by
Proposition~\ref{prop:martingale.space.Hpc}.

\begin{proposition}[It{\^o} isometry for bounded elementary processes]
  \label{prop:ito.isometry.elementary}Let $M \in \mathcal{M}^{2, c}$ and $H
  \in b\mathcal{E}$; we define the {\emph{stochastic integral}} of $H$ with
  respect to $M$ as the process
  \[ \int_0^t H_s \mathrm{d} M_s \coloneq \sum_{k = 0}^{n - 1} h_k M_{t_k \wedge t,
     t_{k + 1} \wedge t} \qquad \forall \, t \geqslant 0.
     \label{eq:defn.stoch.integral.elementary} \]
  The process $\int_0^{\cdot} H_s \mathrm{d} M_s \in \mathcal{H}^{2, c}$ and has
  quadratic variation given by
  \begin{equation}
    \left\langle \int_0^{\cdot} H_s \mathrm{d} M_s \right\rangle_t = \sum_{k =
    0}^{n - 1} h_k^2 \, \langle M \rangle_{t_k \wedge t, t_{k + 1} \wedge t} =
    \int_0^t H_s^2 \mathrm{d} \langle M \rangle_s .
    \label{eq:ito.isometry.quadratic.elementary}
  \end{equation}
  In particular, we have the {\emph{It\^{o} isometry}}
  \begin{equation}
    \left\| \int_0^{\cdot} H_s \mathrm{d} M_s \right\|_{\mathcal{H}^{2, c}}^2
    =\mathbb{E} \left[ \left( \int_0^{\infty} H_s \mathrm{d} M_s \right)^2 \right]
    =\mathbb{E} \left[ \int_0^{\infty} H_s^2 \mathrm{d} \langle M \rangle_s
    \right] =\mathbb{E} \left[ \sum_{k = 0}^{n - 1} h_k^2 \, \langle M
    \rangle_{t_k, t_{k + 1}} \right] . \label{eq:ito.isometry.elementary}
  \end{equation}
\end{proposition}

\begin{remark}
  \label{rem:stoch.int.elementary.basic}Note that the definition of
  $\int_0^{\cdot} H_s \mathrm{d} M_s$
  in~\eqref{eq:defn.stoch.integral.elementary} does not depend on the specific
  choice of the representation~\eqref{eq:defn.elementary.process} (namely if
  we change the choice of $\{ t_k \}_{k = 0}^n$ by further refining the
  partition, we get the same
  process~\eqref{eq:defn.stoch.integral.elementary}). Moreover, it is easy to
  check that the stochastic integral is {\emph{linear in $H$}}, in the sense
  that (as stochastic processes)
  \[ \int_0^{\cdot} (\lambda H_s + K_s) \mathrm{d} M_s = \lambda \int_0^{\cdot}
     H_s \mathrm{d} M_s + \int_0^{\cdot} K_s \mathrm{d} M_s \]
  for all $\lambda \in \mathbb{R}$ and $H$, $K \in b \mathcal{E}$.
\end{remark}

\begin{proof}
  It is clear from the definition that $N_t \coloneq \int_0^t H_s \mathrm{d} M_s$
  is continuous. Noticing that $h_k \in L^{\infty}$, the sum
  in~\eqref{eq:defn.stoch.integral.elementary} is finite and by construction
  $N_t = N_{t_k}$ for $t \geqslant t_n$, it follows that $N$ is integrable and
  $L^2$-bounded (since $M \in \mathcal{M}^{2, c}$). Adaptedness is also
  immediate.
  
  Once we show that $N$ is a martingale
  and~\eqref{eq:ito.isometry.quadratic.elementary} holds, the
  isometry~\eqref{eq:ito.isometry.elementary} follows by taking expectation
  since $N_0 = 0$ (cf. Corollary~\ref{cor:link.quadratic.product}).
  
  To verify the martingale property, by linearity it suffices to show that the
  process $N^k_t \coloneq h_k M_{t_k \wedge t, t_{k + 1} \wedge t}$ is a
  martingale, for each fixed $k \in \{ 0, \ldots, n - 1 \}$. To this end, fix
  $s \leqslant t$. If $t \leqslant t_k$, then $N^k_t = N^k_s = 0$ and there is
  nothing to prove. If $s \geqslant t_k$, then
  
  \begin{align*}
    \mathbb{E} [N^k_t | \mathcal{F}_s] =\mathbb{E} [h_k M_{t_k \wedge t, t_{k
    + 1} \wedge t} | \mathcal{F}_s] & = h_k \mathbb{E} [M_{t_{k + 1} \wedge t}
    - M_{t_k \wedge t} | \mathcal{F}_s]\\
    & = h_k (M_{t_{k + 1} \wedge t \wedge s} - M_{t_k \wedge t \wedge s}) =
    N^k_s
  \end{align*}
  
  where in the intermediate passage we used the stopping theorem. If $s
  \leqslant t_k < t$, then by the tower property and the previous step
  
  \begin{align*}
    \mathbb{E} [N^k_t | \mathcal{F}_s] & =\mathbb{E} [\mathbb{E} [N^k_t |
    \mathcal{F}_{t_k}] | \mathcal{F}_s] =\mathbb{E} [N^k_{t_k} |
    \mathcal{F}_s] = 0 = N^k_s .
  \end{align*}
  
  Overall this shows that $N^k$ is a martingale and by linearity so is $N$.
  
  It remains to show~\eqref{eq:ito.isometry.quadratic.elementary}, namely that
  
  \begin{align*}
    \tilde{N}_t & \coloneq \left( \sum_{k = 0}^{n - 1} h_k M_{t_k \wedge t,
    t_{k + 1} \wedge t} \right)^2 - \sum_{k = 0}^{n - 1} h_k^2 \, \langle M
    \rangle_{t_k \wedge t, t_{k + 1} \wedge t}\\
    & = \sum_{k = 0}^{n - 1} h_k^2 \left[ (M_{t_k \wedge t, t_{k + 1} \wedge
    t})^2 - \, \langle M \rangle_{t_k \wedge t, t_{k + 1} \wedge t} \right] +
    2 \sum_{j < k} h_k h_j M_{t_k \wedge t, t_{k + 1} \wedge t} M_{t_j \wedge
    t, t_{j + 1} \wedge t}
  \end{align*}
  
  is again a martingale. We will show that, for each $k$, the process
  \[ \tilde{N}^k_t \coloneq h_k^2 \left[ (M_{t_k \wedge t, t_{k + 1} \wedge
     t})^2 - \, \langle M \rangle_{t_k \wedge t, t_{k + 1} \wedge t} \right]
  \]
  is a martingale; a similar argument works for the cross-terms related to $j
  < k$, which by linearity implies that $\tilde{N}$ is a martingale.
  
  As before, if $s \leqslant t \leqslant t_k$, $\tilde{N}^k_t = \tilde{N}^k_s
  = 0$; once we have shown the martingale property for $t_k \leqslant s
  \leqslant t$, the intermediate case $s \leqslant t_k \leqslant t$ follows by
  conditioning w.r.t. $\mathcal{F}_{t_k}$ first. So we may assume $t_k
  \leqslant s \leqslant t$. Notice that in this case
  
  \begin{align*}
    (M_{t_k \wedge t, t_{k + 1} \wedge t})^2 - \, \langle M \rangle_{t_k
    \wedge t, t_{k + 1} \wedge t} & = (M_{t_{k + 1} \wedge t} - M_{t_{k + 1}
    \wedge t_k})^2 - \langle M \rangle_{t_{k + 1} \wedge t} + \langle M
    \rangle_{t_{k + 1} \wedge t_k}\\
    & = (M^{t_{k + 1}}_{t_k, t})^2 - \langle M^{t_{k + 1}} \rangle_{t_k, t}
  \end{align*}
  
  where we used the fact that $\langle M \rangle_{t_{k + 1} \wedge u} =
  \langle M^{t_{k + 1}} \rangle_u$ by Lemma~\ref{lem:qv.basic}. $\tilde{M}_t
  \coloneq M^{t_{k + 1}}_t$ is again a continuous martingale by the stopping
  theorem, therefore for $t_k \leqslant s \leqslant t$ we have
  
  \begin{align*}
    \mathbb{E} [\tilde{N}^k_t | \mathcal{F}_s] & = h_k^2 \mathbb{E}
    [(\tilde{M}_{t_k, t})^2 - \langle \tilde{M} \rangle_{t_k, t} |
    \mathcal{F}_s]\\
    & = h_k^2 \mathbb{E} [\tilde{M}_t^2 - \langle \tilde{M} \rangle_t - 2
    \tilde{M}_t  \tilde{M}_{t_k} + \tilde{M}_{t_k}^2 + \langle \tilde{M}
    \rangle_{t_k} | \mathcal{F}_s]\\
    & = h_k^2  [\tilde{M}^2_s - \langle \tilde{M} \rangle_s - 2
    \tilde{M}_{t_k} \mathbb{E} [\tilde{M}_t | \mathcal{F}_s] +
    \tilde{M}_{t_k}^2 + \langle \tilde{M} \rangle_{t_k}]\\
    & = h_k^2  [\tilde{M}^2_s - 2 \tilde{M}_{t_k} \tilde{M}_s +
    \tilde{M}_{t_k}^2 - \langle \tilde{M} \rangle_s + \langle \tilde{M}
    \rangle_{t_k}] = \tilde{N}^k_s
  \end{align*}
  
  which concludes the proof.
\end{proof}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Complete the proof of Proposition~\ref{prop:ito.isometry.elementary}, i.e.
  show similarly that the processes
  \[ t \mapsto h_k h_j M_{t_k \wedge t, t_{k + 1} \wedge t} M_{t_j \wedge t,
     t_{j + 1} \wedge t} \]
  with $j < k$ are martingales.
\end{exercise*}}}{\ }

\

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on December 18}
  \hrulefill\hrulefill
\end{center}

\subsection{Stochastic integration w.r.t. Brownian motion}

We now specialize the previous result to the case where $M = B$ Brownian
motion. \ Recall the concept of progressively measurable processes coming from
Definition~\ref{defn:progressively.measurable}, and its link to measurability
w.r.t. to the $\sigma$-algebra Prog of progressive events coming from
Remark~\ref{rem:progressive.sets}.

\begin{definition}
  Let $\overline{\Omega} \coloneq \Omega \times \mathbb{R}_+$ and set
  \[ \mathbb{P}_B (\mathrm{d} \omega, \mathrm{d} t) \coloneq \mathrm{d} t \otimes
     \mathbb{P} (\mathrm{d} \omega), \qquad L^2 (B) \coloneq L^2
     (\overline{\Omega}, \operatorname{Prog}, \mathbb{P}_B) ; \]
  namely
  \[ L^2 (B) = \left\{ H : \Omega \times \mathbb{R}_+ \rightarrow \mathbb{R}
     \left| H \text{ is progressive, } \|H\|_{L^2 (B)}^2 \coloneq \mathbb{E}
     \left[ \int_0^{\infty} H^2_t \mathrm{d} t \right] < \infty \right. \right\} .
  \]
\end{definition}

As usual with $L^p$ spaces, we identify two processes $H$, $\tilde{H}$ if $\|
H - \tilde{H} \|_{L^2 (B)} = 0$.

Note that the definition of $L^2 (B)$ is meaningful, since trajectories of $H$
are measurable by Lemma~\ref{lem:progr mb trajectories} and so
$\int_0^{\infty} H^2_t \mathrm{d} t$ is a well-defined random variable (with
values in $[0, + \infty]$). Since $L^2 (B) = L^2 \left( \overline{\Omega},
\operatorname{Prog}, \mathbb{P}_B \right)$ is an $L^2$-space, it is complete and
Hilbert; it is immediate to check that, if $H \in b \mathcal{E}$, then $H \in
L^2 (B)$ as well, namely
\[ b \mathcal{E} \subset L^2 (B) . \]
Since $\langle B \rangle_t = t$,
Proposition~\ref{prop:ito.isometry.elementary} can be restated as follows: the
stochastic integral
\[ I_B : b\mathcal{E} \ni H \mapsto I_B H \coloneq \int_0^{\cdot} H_s \mathrm{d}
   B_s \in \mathcal{H}^{2, c} \]
is a linear isometry between $(b\mathcal{E}, \| \cdot \|_{L^2 (B)})$ and
$\mathcal{H}^{2, c}$, since by~\eqref{eq:ito.isometry.elementary} we have
\[ \| I_B H \|_{\mathcal{H}^{2, c}}^2 =\mathbb{E} \left[ \int_0^{\infty} H_s^2
   \mathrm{d} \langle B \rangle_s \right] =\mathbb{E} \left[ \int_0^{\infty} H_s^2
   \mathrm{d} s \right] = \| H \|_{L^2 (B)}^2 . \]
Since $\mathcal{H}^{2, c}$ is a Hilbert space (in particular it is complete,
cf. Proposition~\ref{prop:martingale.space.Hpc}), it follows that $I_B$
extends uniquely to a isometry defined on the closure of $b\mathcal{E}$ in
$L^2 (B)$; compare to the construction of Wiener integral from
Lemma~\ref{lem:wiener-int}. It remains to identify such closure.

\begin{lemma}
  \label{lem:bE-dense}The space $b\mathcal{E}$ is dense in $L^2 (B)$.
\end{lemma}

\begin{proof}
  To show it, we invoke the following result from functional analysis:
  
  {\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
    \textbf{Criterion for density in Hilbert spaces:} Let $E$ be a Hilbert
    space, $V$ be a linear subspace of $E$. Then $V$ is dense in $E$ if and
    only if, for any element $w \in E$ {\emph{orthogonal}} to $V$, namely such
    that $(w, v)_E = 0$ for all $v \in V$, it must hold $w = 0$. In other
    words, $V$ is dense if and only if $V^{\perp} = \{ 0 \} .$
  \end{tabularx}
  
  \
  
  Since $L^2 (B)$ is Hilbert and $b\mathcal{E} \subset L^2 (B)$ is a linear
  subspace, it suffices to show that $b \mathcal{E}^{\perp} = \{ 0 \}$. So let
  $K \in b \mathcal{E}^{\perp}$ and consider
  \[ X \coloneq \int_0^{\cdot} K_r \mathrm{d} r ; \]
  noting that $K \in L^2 (B)$, so that $\mathbb{P}$-a.s. $\int_0^{+ \infty} |
  K_t |^2 \mathrm{d} t < \infty$, Cauchy's inequality implies that
  $\mathbb{P}$-a.s. $\int_0^T | K_t | \mathrm{d} t < \infty$ for all $T < \infty$.
  In particular, $X \in \mathcal{A}$.
  
  We claim that $X$ is a (continuous) martingale. If that is the case, then by
  Lemma~\ref{lem:locmart not fv}, $X \equiv 0$ $\mathbb{P}$-a.s., namely there
  exists a null set $\mathcal{N} \subset \Omega$ such that for all $\omega \in
  \mathcal{N}^c$
  \[ \int_s^t K_r (\omega) \mathrm{d} r = 0 \qquad \forall \, 0 \leqslant s < t.
  \]
  Since intervals $[s, t]$ generale $\mathcal{B} (\mathbb{R}_+)$, it then
  follows from Dynkin's lemma that for such $\omega$ we have $K_t (\omega) =
  0$ for Lebesgue-almost all $t \geqslant 0$, hence $K = 0$ in $L^2 (B)$ by
  Fubini.
  
  It remains to show the claim that $X$ is a martingale. $X$ is adapted (since
  $K$ is progressively and integrable), and integrable by the Cauchy-Schwarz
  inequality (applied twice):
  
  \begin{align*}
    \mathbb{E} [| X_t |] & \leqslant \mathbb{E} \left[ \int_0^t K_s^2 \mathrm{d} s
    \right]^{1 / 2} \sqrt{t} \leqslant \| K \|_{L^2 (B)} \sqrt{t} .
  \end{align*}
  
  Consider now $H =\1_{(s, t]} \1_A$ with $s < t$ and $A \in
  \mathcal{F}_s$. Then $H \in b\mathcal{E}$ and since $K \bot b\mathcal{E}$,
  we have
  \[ 0 = (H, K)_{L^2 (B)} =\mathbb{E} \left[ \int_0^{\infty} H_r K_r \mathrm{d} r
     \right] =\mathbb{E} [\1_A (X_t - X_s)] . \]
  Since $A \in \mathcal{F}_s$ was arbitrary, this proves that $X$ is a
  martingale, concluding the proof.
\end{proof}

\begin{theorem}[It{\^o} integral and It\^{o} isometry w.r.t. Brownian motion]
  \label{thm:ito-Bm}Let $H \in L^2 (B)$. Then there exists a unique (up to
  indistinguishability) element of $\mathcal{H}^{2, c}$, which we denote by
  $\left( \int_0^t H_s \mathrm{d} B_s \right)_{t \geqslant 0}$, such that for any
  sequence $(H^{(n)})_n \subset b\mathcal{E}$ with $H^{(n)} \rightarrow H$ in
  $L^2 (B)$ we have
  \[ \lim_{n \rightarrow \infty} \mathbb{E} \left[ \sup_{t \geqslant 0} \left|
     \int_0^t H_s \mathrm{d} B_s - \int_0^t H_s^{(n)} \mathrm{d} B_s \right|^2 \right]
     = 0. \]
  We call $\int_0^{\cdot} H_s \mathrm{d} B_s$ the {\emph{It{\^o} integral}}, or
  the {\emph{stochastic integral}}, of $H$ w.r.t. $B$. Moreover, the map $L^2
  (B) \ni H \mapsto \int_0^{\cdot} H_s \mathrm{d} B_s \in \mathcal{H}^{2, c}$ is
  a linear isometry, namely {\emph{It{\^o}'s isometry}} holds:
  \begin{equation}
    \mathbb{E} \left[ \left( \int_0^{\infty} H_s \, \mathrm{d} B_s \right)^2
    \right] =\mathbb{E} \left[ \int_0^{\infty} H_s^2 \, \mathrm{d} s \right] .
    \label{eq:ito.isometry.Bm}
  \end{equation}
  Moreover the quadratic variation of $\int_0^{\cdot} H_s \mathrm{d} B_s$ is
  given by
  \begin{equation}
    \left\langle \int_0^{\cdot} H_s \mathrm{d} B_s \right\rangle_t = \int_0^t
    H_s^2 \mathrm{d} s \qquad \forall \, t \in [0, \infty] .
    \label{eq:ito.isometry.quadratic.Bm}
  \end{equation}
\end{theorem}

\begin{proof}
  Let $(H^{(n)})_n \subset b\mathcal{E}$ be such that $\| H - H^{(n)} \|_{L^2
  (B)} \rightarrow 0$ (since $b\mathcal{E}$ is dense in $L^2 (B)$, such a
  sequence must exist). Since the stochastic integral on $b\mathcal{E}$ is
  linear
  \[ \mathbb{E} \left[ \sup_{t \geqslant 0} \left( \int_0^t H_s^{(n)} \mathrm{d}
     B_s - \int_0^t H_s^{(m)} \mathrm{d} B_s \right)^2 \right] \leqslant 4 \|
     H^{(n)} - H^{(m)} \|_{L^2 (B)} \rightarrow 0 \]
  as $m, n \rightarrow \infty$. As a consequence, the sequence $(I _B
  H^{(n)})_n$ is Cauchy in $\mathcal{H}^{2, c}$, which is complete, and so it
  must admit a limit point in $\mathcal{H}^{2, c}$; denote it by
  $\int_0^{\cdot} H_s \, \mathrm{d} B_s$.
  
  It then holds
  
  \begin{align*}
    \left\| \int_0^{\cdot} H_s \, \mathrm{d} B_s \right\|_{\mathcal{H}^{2, c}}^2 &
    = \lim_{n \rightarrow \infty} \left\| \int_0^{\cdot} H^n_s \, \mathrm{d} B_s
    \right\|_{\mathcal{H}^{2, c}}^2 = \lim_{n \rightarrow \infty} \| H^n
    \|_{L^2 (B)} = \| H \|_{L^2 (B)}
  \end{align*}
  
  proving~\eqref{eq:ito.isometry.Bm}. We now want to show that the definition
  of $\int_0^{\cdot} H_s \, \mathrm{d} B_s$ does not depend on the chosen sequence
  $(H^{(n)})_n \subset b\mathcal{E}$; to this end, let $(\tilde{H}^{(n)})_n
  \subset b\mathcal{E}$ be another sequence converging to $H$ in $L^2 (B)$
  (possibly $\tilde{H}^{(n)} = H^{(n)}$). Then by linearity of the stochastic
  integral and It\^{o} isometry (valid on $b \mathcal{E}$)
  
  \begin{align*}
    \lim_{n \rightarrow \infty} \left\| \int_0^{\cdot} H^{(n)}_s \, \mathrm{d} B_s
    - \int_0^{\cdot} \tilde{H}^{(n)}_s \, \mathrm{d} B_s \right\|_{\mathcal{H}^{2,
    c}}^2 & = \lim_{n \rightarrow \infty} \left\| \int_0^{\cdot} (H^{(n)}_s -
    \tilde{H}^{(n)}_s) \, \mathrm{d} B_s \right\|_{\mathcal{H}^{2, c}}^2\\
    & = \lim_{n \rightarrow \infty} \| H^{(n)} - \tilde{H}^{(n)} \|_{L^2
    (B)}^2\\
    & \leqslant \lim_{n \rightarrow \infty} (\| H^{(n)} - H \|_{L^2 (B)} + \|
    H - \tilde{H}^{(n)} \|_{L^2 (B)})^2\\
    & = 0.
  \end{align*}
  
  Since $I_B H^{(n)} \rightarrow \int_0^{\cdot} H_s \, \mathrm{d} B_s$, by the
  above estimate the same must hold for $I_B \tilde{H}^{(n)}$ as well.
  Linearity of the map $H \mapsto \int_0^{\cdot} H_s \, \mathrm{d} B_s$ is a
  consequence of the same linearity on $b \mathcal{E}$, and a passage to the
  limit procedure. So it only remains to
  show~\eqref{eq:ito.isometry.quadratic.Bm}.
  
  Notice that, if $H^{(n)} \rightarrow H$ in $L^2 (B)$, then by Cauchy
  
  \begin{align*}
    \sup_{t \geqslant 0} \left| \int_0^t H_s^2 \mathrm{d} s - \int_0^t
    (H^{(n)}_s)^2 \mathrm{d} s \right| & \leqslant \int_0^{+ \infty} | H_s^2 -
    (H^{(n)}_s)^2 | \mathrm{d} s\\
    & = \int_0^{+ \infty} | H_s - H^{(n)}_s |  | H_s + H^{(n)}_s | \mathrm{d} s\\
    & \leqslant \| H - H^{(n)} \|_{L^2 (\mathbb{R}_+)} (\| H \|_{L^2
    (\mathbb{R}_+)} + \| H^{(n)} \|_{L^2 (\mathbb{R}_+)}) .
  \end{align*}
  
  Taking expectation and applying another Cauchy inequality, we get
  
  \begin{align*}
    \mathbb{E} \left[ \sup_{t \geqslant 0} \left| \int_0^t H_s^2 \mathrm{d} s -
    \int_0^t (H^{(n)}_s)^2 \mathrm{d} s \right| \right] & \leqslant \mathbb{E} [\|
    H - H^{(n)} \|_{L^2 (\mathbb{R}_+)} (\| H \|_{L^2 (\mathbb{R}_+)} + \|
    H^{(n)} \|_{L^2 (\mathbb{R}_+)})]\\
    & \leqslant \| H - H^{(n)} \|_{L^2 (B)}  (\| H \|_{L^2 (B)} + \| H^{(n)}
    \|_{L^2 (B)})\\
    & \leqslant (\| H \|_{L^2 (B)} + \sup_n \| H^{(n)} \|_{L^2 (B)})  \| H -
    H^{(n)} \|_{L^2 (B)} \rightarrow 0
  \end{align*}
  
  as $n \rightarrow \infty$; this is because, if $H^{(n)} \rightarrow H$ in
  $L^2 (B)$, then $\| H^{(n)} \|_{L^2 (B)} \rightarrow \| H \|_{L^2 (B)}$ and
  so $\sup_n \| H^{(n)} \|_{L^2 (B)} < \infty$. Therefore the martingales $M^n
  = I_B H^{(n)}, \, M = I_B H \in \mathcal{H}^{2, c}$ are such that (recall
  the equivalent norm on $\mathcal{H}^{2, c}$ coming from
  Proposition~\ref{prop:martingale.space.Hpc})
  \[ \lim_{n \rightarrow \infty} \left( \mathbb{E} [\sup_{t \geqslant 0} |
     M^n_t - M_t |^2] +\mathbb{E} \left[ \sup_{t \geqslant 0} \left| \langle
     M^n \rangle_t - \int_0^t H_s^2 \mathrm{d} s \right|^2 \right] \right) = 0. \]
  Since $(M^n)^2 - \langle M^n \rangle$ is a martingale for each $n$, passing
  to the limit $M^2 - \int_0^t H_s^2 \mathrm{d} s$ is also a martingale, so that
  $\langle I_B H \rangle_{\cdot} = \int_0^{\cdot} H_s^2 \mathrm{d} s$,
  proving~\eqref{eq:ito.isometry.quadratic.Bm}.
\end{proof}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Compute $\mathbb{E} \left[ \left( \int_0^t B_s \mathrm{d} B_s \right)^2 \right]$
  for a Brownian motion $B$ (i.e. you must get an explicitly number at the
  end).
\end{exercise*}}}{\ }

\subsection{Stochastic integration w.r.t. $M \in \mathcal{H}^{2, c}$}

Our next aim is to define the stochastic integral $\int_0^t H_s \mathrm{d} M_s$
for $M \in \mathcal{H}^{2, c}$ and for suitable integrands $H$. This can be
accomplished very similarly to the Brownian case. Recall from
Proposition~\ref{prop:ito.isometry.elementary} that, for any $H = \sum_{k =
0}^{n - 1} h_k \1_{(t_k, t_{k + 1}]} \in b\mathcal{E}$ and $M \in
\mathcal{H}^{2, c}$, the process $\int_0^{\cdot} H_s \mathrm{d} M_s$ is also in
$\mathcal{H}^{2, c}$ and
\begin{equation}
  \left\| \int_0^{\cdot} H_s \mathrm{d} M_s \right\|_{\mathcal{H}^{2, c}}^2
  =\mathbb{E} \left[ \int_0^{\infty} H^2_s \mathrm{d} \langle M \rangle_s \right]
  . \label{eq:ito.isometry.recap}
\end{equation}
Let now again $\overline{\Omega} \coloneq \Omega \times \mathbb{R}_+$,
$\operatorname{Prog}$ be the progressive $\sigma$-algebra, and set
\[ \mathbb{P}_M (\mathrm{d} \omega, \mathrm{d} t) \coloneq \langle M \rangle (\omega,
   \mathrm{d} t) \mathbb{P} (\mathrm{d} \omega), \qquad \]
By the above we mean that, for any $(\omega, t)$-measurable and bounded
function $F : \bar{\Omega} \rightarrow \mathbb{R}$,
\[ \int_{\bar{\Omega}} F (\omega, t) \mathbb{P}_M (\mathrm{d} \omega, \mathrm{d} t) =
   \int_{\Omega} \int_0^{+ \infty} F (\omega, t)  \langle M \rangle (\omega,
   \mathrm{d} t) \mathbb{P} (\mathrm{d} \omega) =\mathbb{E} \left[ \int_0^{+ \infty}
   F_t \mathrm{d} \langle M \rangle_t \right] \]
where the last identity comes from interpreting $F$ as a stochastic process
with measurable trajectories (which is why we omit the $\omega \in \Omega$
inside $\mathbb{E}$ as usual). Notice that, for bounded $F$, the above
quantity is finite since
\[ \mathbb{E} \left[ \int_0^{+ \infty} | F_t | \mathrm{d} \langle M \rangle_t
   \right] \leqslant \| F \|_{L^{\infty} (\bar{\Omega})} \mathbb{E} \left[
   \int_0^{+ \infty} 1 \mathrm{d} \langle M \rangle_t \right] = \| F
   \|_{L^{\infty} (\bar{\Omega})} \mathbb{E} [\langle M \rangle_{\infty}] <
   \infty \]
since $\mathbb{E} [\langle M \rangle_{\infty}] = \| M \|_{\mathcal{H}^{2, c}}
< \infty$ by Corollary~\ref{cor:link.quadratic.product}. Moreover set $L^2 (M)
\coloneq L^2 (\overline{\Omega}, \operatorname{Prog}, \mathbb{P}_M)$, namely
\[ L^2 (M) = \left\{ H : \Omega \times \mathbb{R}_+ \rightarrow \mathbb{R}
   \left| H \text{ is progressive and } \|H\|_{L^2 (M)}^2 \coloneq \mathbb{E}
   \left[ \int_0^{\infty} H^2_t \mathrm{d} \langle M \rangle_t \right] < \infty
   \right. \right\}, \]
which is a Hilbert space with inner product
\[ (H, K)_{L^2 (M)} =\mathbb{E} \left[ \int_0^{\infty} H_t K_t \mathrm{d} \langle
   M \rangle_t \right] . \]

\begin{remark}
  As before, we identify processes $H, \tilde{H}$ as the same element in $L^2
  (M)$ if $\| H - \tilde{H} \|_{L^2 (M)} = 0$. This condition is now slightly
  more subtle than in the Brownian case: if ${u \mapsto \langle M \rangle_u} $
  is constant on some interval $[s, t]$, then $H$ can take any value therein
  and yet it will be identified with $0$ on $[s, t]$. In the extreme case
  where $M$ is constant and $\langle M \rangle \equiv 0$, any process will be
  identified with $0$. The point is exactly that we only care about the result
  stochastic integral $\int_0^{\cdot} H_s \mathrm{d} M_s$, and if $M$ is constant
  then formally ``$\mathrm{d} M \equiv 0$''. 
\end{remark}

With these notations in mind, the It{\^o}
isometry~\eqref{eq:ito.isometry.recap} shows that the map
\[ I_M : b\mathcal{E} \ni H \mapsto I_M H \coloneq \int_0^{\cdot} H_s \mathrm{d}
   M_s \in \mathcal{H}^{2, c} \]
is an isometry between $(b\mathcal{E}, \| \cdot \|_{L^2 (M)})$ and
$\mathcal{H}^{2, c}$, and thus it can be uniquely extended to an isometry on
the closure of $b\mathcal{E}$ in $L^2 (M)$.

Going through the same proof line-by-line as in Lemma~\ref{lem:bE-dense}, one
can then shows that $b\mathcal{E}$ is dense in $L^2 (M)$; we only have to
redefine $X \coloneq \int_0^{\cdot} K_r \mathrm{d} \langle M \rangle_r$ in that
proof (before we took $X = \int_0^{\cdot} K_r \mathrm{d} r = \int_0^{\cdot}
K_r \mathrm{d} \langle B \rangle_r$).

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Prove by yourself density of $b \mathcal{E}$ in $L^2 (M)$ by following the
  above guidelines.
\end{exercise*}}}{\ }

This leads to the following result:

\begin{theorem}[It{\^o} integral for $M \in \mathcal{H}^{2, c}$]
  \label{thm:ito-H2}For $M \in \mathcal{H}^{2, c}$, there is a unique linear
  isometry
  \[ L^2 (M) \ni H \mapsto \int_0^{\cdot} H_s \mathrm{d} M_s \in \mathcal{H}^{2,
     c} \]
  which is an extension of $I_M$. We call $\int_0^{\cdot} H_s \mathrm{d} M_s$
  the {\emph{stochastic integral}} or {\emph{It{\^o} integral}} of $H$ with
  respect to $M$.
  
  In other words, for any $H \in L^2 (M)$, there exists a sequence $(H^n)
  \subset b\mathcal{E}$ such that $H^n \to H$ in $L^2 (M)$, and for any
  approximating sequence $H^n \to H$ in $L^2 (M)$, we have $\int_0^{\cdot}
  H^n_s \mathrm{d} M_s \to \int_0^{\cdot} H_s \mathrm{d} M_s$ in $\mathcal{H}^{2,
  c}$.
  
  The quadratic variation of $\int_0^{\cdot} H_s \mathrm{d} M_s$ is given by
  \begin{equation}
    \left\langle \int_0^{\cdot} H_s \mathrm{d} M_s \right\rangle_t = \int_0^t
    H_s^2 \mathrm{d} \langle M \rangle_s \quad \forall \, t \in [0, + \infty]
    \label{eq:ito.isometry.quadratic.H2}
  \end{equation}
  and we have the {\emph{It\^{o} isometry}}
  \begin{equation}
    \mathbb{E} \left[ \left( \int_0^{\tau} H_s \mathrm{d} M_s \right)^2 \right]
    =\mathbb{E} \left[ \int_0^{\tau} H_s^2 \mathrm{d} \langle M \rangle_s \right] 
    \label{eq:ito.isometry.H2}
  \end{equation}
  for all stopping times $\tau$ (including e.g. $\tau \equiv + \infty$).
\end{theorem}

\begin{proof}
  The first part follows immediately from the fact that $I_M$ is an isometry,
  $b\mathcal{E}$ is dense in $L^2 (M)$, and $\mathcal{H}^{2, c}$ is complete;
  the second part follows arguing like in Theorem~\ref{thm:ito-Bm}. Finally,
  \eqref{eq:ito.isometry.H2} follows from Corollary~\ref{cor:localBDG}.
\end{proof}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Find another formula for $\mathbb{E} \left[ \left( \int_0^t M_s \mathrm{d} M_s
  \right)^2 \right]$ when $M \in \mathcal{H}^{2, c}$; compare this to the case
  $M = B$ by a previous exercise.
\end{exercise*}}}{\ }

Next, we want to discuss a characterizing property of the stochastic integral
(which in fact can be used to provide an alternative, more functional analytic
way of constructing it). As a preparation, we need to upgrade
Lemma~\ref{lem:kunita-wanatabe.v1} to a version which is more suitable for
stochastic integrals; as therein, one should think of it as a version of the
Cauchy-Schwarz inequality for stochastic integrals.

\begin{lemma}[Kunita--Watanabe inequality, v2]
  Let $M, N \in \mathcal{M}_{\operatorname{loc}}^c$ and let $H, K$ be measurable
  processes such that almost surely $\int_0^{\infty} |H_t K_t | \mathrm{d} V
  (\langle M, N \rangle)_t < \infty$. Then almost surely
  
  \begin{align*}
    \left| \int_0^{\infty} H_t K_t \mathrm{d} \langle M, N \rangle_t \right| &
    \leqslant \int_0^{\infty} |H_t K_t | \mathrm{d} V (\langle M, N \rangle)_t\\
    & \leqslant \left( \int_0^{\infty} |H_t |^2 \mathrm{d} \langle M \rangle_t
    \right)^{1 / 2} \left( \int_0^{\infty} |K_t |^2 \mathrm{d} \langle N \rangle_t
    \right)^{1 / 2} .
  \end{align*}
\end{lemma}

\begin{proof}
  {\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
    We skipped the proof in the lectures for lack of time and because it's
    mostly a technical extension of Lemma~\ref{lem:kunita-wanatabe.v1} which
    was already shown; the full proof is included anyway in the lecture notes
    for completeness.
  \end{tabularx}
  
  \
  
  Recall from Lemma~\ref{lem:kunita-wanatabe.v1} that we already showed the
  inequality for $H = K = 1$, i.e.
  \[ | \langle M, N \rangle_{s, t} | \leqslant V (\langle M, N \rangle)_{s, t}
     \leqslant \langle M \rangle_{s, t}^{1 / 2} \langle N \rangle_{s, t}^{1 /
     2} . \]
  If now $H, K$ are elementary processes (not necessarily
  $\mathbb{F}$-progressive), in the sense that
  \[ H = \sum_{j = 0}^{n - 1} h_j \1_{(t_j, t_{j + 1}]}, \quad K =
     \sum_{j = 0}^{n - 1} k_j \1_{(t_j, t_{j + 1}]}, \]
  then by definition of Lebesgue--Stjeltes integrals and Cauchy inequality we
  find
  
  \begin{align*}
    \left| \int_0^{\infty} H_t K_t \mathrm{d} \langle M, N \rangle_t \right| & =
    \left| \sum_{j = 0}^{n - 1} h_j k_j \langle M, N \rangle_{t_j, t_{j + 1}}
    \right|\\
    & \leqslant \sum_{j = 0}^{n - 1} | h_j |  | k_j | | \langle M, N \rangle
    |_{t_j, t_{j + 1}}\\
    & \leqslant \sum_{j = 0}^{n - 1} | h_j |  | k_j | \langle M \rangle_{s,
    t}^{1 / 2} \langle N \rangle_{s, t}^{1 / 2}\\
    & \leqslant \left( \sum_{j = 0}^{n - 1} | h_j |^2 \langle M \rangle_{s,
    t} \right)^{1 / 2} \left( \sum_{j = 0}^{n - 1} | k_j |^2 \langle N
    \rangle_{s, t} \right)^{1 / 2}\\
    & = \left( \int_0^{\infty} |H_t |^2 \mathrm{d} \langle M \rangle_t \right)^{1
    / 2} \left( \int_0^{\infty} |K_t |^2 \mathrm{d} \langle N \rangle_t \right)^{1
    / 2} .
  \end{align*}
  
  By the usual approximation arguments, we can extend the inequalities to be
  valid e.g. for all bounded measurable processes $H, K$. As usual, we can
  then relax the boundedness assumption to almost sure finiteness of
  $\int_0^{\infty} |H_t K_t | \mathrm{d} V (\langle M, N \rangle)_t$.
\end{proof}

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on December 19}
  \hrulefill\hrulefill
\end{center}

\begin{theorem}[Characterization of the stochastic integral]
  \label{thm:ito-H2-char}Let $M \in \mathcal{H}^{2, c}$ and $H \in L^2 (M)$.
  The stochastic integral $\int_0^{\cdot} H_s \mathrm{d} M_s$ is the unique
  element in $\mathcal{H}^{2, c}$ starting at~0 such that
  \begin{equation}
    \left\langle \int_0^{\cdot} H_s \mathrm{d} M_s, N \right\rangle =
    \int_0^{\cdot} H_s \mathrm{d} \langle M, N \rangle_s \quad \text{for all } N
    \in \mathcal{H}^{2, c} . \label{eq:SIchar}
  \end{equation}
\end{theorem}

\begin{proof}
  Let us first show that there can be at most one process starting at 0
  satisfying~\eqref{eq:SIchar}: if $X, Y \in \mathcal{H}^{2, c}$
  satisfy~\eqref{eq:SIchar} with $\int_0^{\cdot} H_s \mathrm{d} M_s$ replaced by
  $X$ or $Y$, then for all $N \in \mathcal{H}^{2, c}$ it holds
  
  \begin{align*}
    \langle X - Y, N \rangle & = \langle X, N \rangle - \langle Y, N \rangle =
    \int_0^{\cdot} H_s \mathrm{d} \langle M, N \rangle_s - \int_0^{\cdot} H_s
    \mathrm{d} \langle M, N \rangle_s = 0 ;
  \end{align*}
  
  taking $N = X - Y$, we deduce that $X - Y = 0$.
  
  Notice that, in the existence part, we may assume wlog that $M_0 = 0$.
  Indeed, otherwise we may replace $M$ by $M - M_0$, and it holds $\langle M -
  M_0, N \rangle = \langle M, N \rangle$; therefore the uniqueness part shows
  that the stochastic integrals with respect to $M$ and $M - M_0$ have to
  agree (loosely speaking, ``$\mathrm{d} M = \mathrm{d} (M - M_0)$'').
  
  To see that $\int_0^{\cdot} H_s \mathrm{d} M_s$ satisfies~\eqref{eq:SIchar},
  we divide the proof in two steps. Notice that we can assume wlog $M_0 = 0$,
  since $M_0$ does not play any role in the definition of $\int_0^{\cdot}
  H_s \mathrm{d} M_s$.
  
  Step 1: $H \in b \mathcal{E}$.} Let $H = \sum_{k = 0}^{n - 1 h_k
  \1_{(t_k, t_{k + 1}]} \in b\mathcal{E}$ and let $N \in
  \mathcal{H}^{2, c}$. We claim that $\left( \int_0^{\cdot} H_s \mathrm{d} M_s
  \right) N - \int_0^{\cdot} H_s \mathrm{d} \langle M, N \rangle_s$ is a
  martingale, which by definition of $\langle \cdot, \cdot \rangle$
  yields~\eqref{eq:SIchar}. Since $\langle \cdot, \cdot \rangle$ is linear in
  each entry, $H \mapsto \int_0^{\cdot} H \mathrm{d} M$ is linear and so is
  relation~\eqref{eq:SIchar}, it suffices to verify the claim for $h_k
  \1_{(t_k, t_{k + 1}]}$; therefore we only need to show that
  \[ \left( \int_0^t H_s \mathrm{d} M_s \right) N_t - \int_0^t H_s \mathrm{d} \langle
     M, N \rangle_s = h_k  (M_{t_k \wedge t, t_{k + 1} \wedge t} N_t - \langle
     M, N \rangle_{t_k \wedge t, t_{k + 1} \wedge t}) \]
  is a martingale. Let us set
  \[ J_t \coloneq M_{t_k \wedge t, t_{k + 1} \wedge t} N_t - \langle M, N
     \rangle_{t_k \wedge t, t_{k + 1} \wedge t} ; \]
  By Proposition~\ref{prop:properties.quadratic.covariation}-c), we have
  \[ M_{t_{k + 1} \wedge t} N_t - \langle M, N \rangle_{t_{k + 1} \wedge t} =
     M_t^{t_{k + 1}} N_t - \langle M^{t_{k + 1}}, N \rangle_t \]
  which is a martingale by the definition of $\langle \cdot, \cdot \rangle$;
  the same argument holds for $t_{k + 1}$ replaced by $t_k$, and so by
  linearity $J$ is a martingale.
  
  We now want to show that $h_k J$ is a martingale as well, where $h_k \in
  \mathcal{F}_{t_k}$ is bounded. We argue as in the proof of
  Proposition~\ref{prop:ito.isometry.elementary}: we only need to consider the
  case $t_k \leqslant s \leqslant t$, as the case $s \leqslant t_k \leqslant
  t$ reduces to this one by the tower property of conditional expectation, and
  the case $s \leqslant t \leqslant t_k$ is trivial (everything is $0$). When
  $t_k \leqslant s \leqslant t$, since $h_k$ is $\mathcal{F}_{t_k}$-measurable
  and $J$ is a martingale, we get
  \[ \mathbb{E} [h_k J_t | \mathcal{F}_s] = h_k \mathbb{E} [J_t |
     \mathcal{F}_s] = h_k J_s . \]
  Overall, this concludes the proof of~\eqref{eq:SIchar} when $H \in b
  \mathcal{E}$.
  
  Step 2: extension to $H \in L^2 (M)$ by density. Let $H \in L^2
  (M)$, then by density there exists a sequence $\{ H^{(n)} \}_n \subset b
  \mathcal{E}$ such that $H^{(n)} \rightarrow H$ in $L^2 (M)$; by Step 1, for
  each $n$,
  \[ \left( \int_0^{\cdot} H^{(n)}_s \mathrm{d} M_s \right) N - \int_0^{\cdot}
     H^{(n)}_s \mathrm{d} \langle M, N \rangle_s \]
  is a martingale; to conclude, it suffices to show that, for any fixed $t
  \geqslant 0$,
  \[ \left( \int_0^t H^{(n)}_s \mathrm{d} M_s \right) N_t - \int_0^t H^{(n)}_s
     \mathrm{d} \langle M, N \rangle_s \rightarrow \left( \int_0^t H_s \mathrm{d} M_s
     \right) N - \int_0^t H_s \mathrm{d} \langle M, N \rangle_s \quad \text{in }
     L^1 (\Omega) . \]
  Convergence of the first term is immediate, since by construction of the
  stochastic integral we have $\int_0^{\cdot} H^{(n)} \mathrm{d} M \rightarrow
  \int_0^{\cdot} H \mathrm{d} M$ in $\mathcal{H}^{2, c}$. For the second term, by
  linearity and the Kunita--Watanabe inequality (with $\tilde{H} : = (H^{(n)}
  - H)  \1_{[0, t]}$, $K = 1$) we have
  
  \begin{align*}
    \mathbb{E} \left[ \left| \int_0^t H^{(n)}_s \mathrm{d} \langle M, N \rangle_s
    - \int_0^t H_s \mathrm{d} \langle M, N \rangle_s \right| \right] & =\mathbb{E}
    \left[ \left| \int_0^{+ \infty} \tilde{H}_s \mathrm{d} \langle M, N \rangle_s
    \right| \right]\\
    & \leqslant \mathbb{E} \left[ \left( \int_0^t | H^{(n)}_s - H_s |^2
    \mathrm{d} \langle M \rangle_s \right)^{1 / 2} \langle N \rangle^{1 /
    2}_{\infty} \right]\\
    & \leqslant \mathbb{E} \left[ \int_0^t | H^{(n)}_s - H_s |^2 \mathrm{d}
    \langle M \rangle_s \right] \mathbb{E} [\langle N \rangle_{\infty}]^{1 /
    2}\\
    & \leqslant \|H^n - H\|_{L^2 (M)}  \| N \|_{\mathcal{H}^{2, c}}
    \rightarrow 0
  \end{align*}
  
  as $n \rightarrow \infty$, where in the intermediate passage we applied
  Cauchy's inequality.
\end{proof}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Find a formula for $\left\langle \int_0^{\cdot} B_s \mathrm{d} B_s, B
  \right\rangle_t$, where $B$ is a Brownian motion $B$, and compute
  $\mathbb{E} \left[ \left\langle \int_0^{\cdot} B_s \mathrm{d} B_s, B
  \right\rangle_t \right]$.
\end{exercise*}}}{\ }

\begin{corollary}
  \label{cor:ito-properties-H2}Let $M \in \mathcal{H}^{2, c}$ and $H \in L^2
  (M)$.
  \begin{enumerate}
    \item For any stopping time $\tau$, it holds that
    \[ \left( \int_0^{\cdot} H_s \mathrm{d} M_s \right)^{\tau} =
       \int_0^{\cdot} \1_{[0, \tau]} (s) H_s \mathrm{d} M_s =
       \int_0^{\cdot} H_s \mathrm{d} M_s^{\tau} . \]
    \item For any other $N \in \mathcal{H}^{2, c}$ and $K \in L^2 (N)$, we
    have
    \begin{equation}
      \left\langle \int_0^{\cdot} H_s \mathrm{d} M_s, \int_0^{\cdot} K_s
      \mathrm{d} N_s \right\rangle = \int_0^{\cdot} H_s K_s \mathrm{d} \langle M, N
      \rangle_s . \label{eq:cor.ito.properties.ii}
    \end{equation}
    Notice that, for $M = N$, $H = K$ we recover
    formula~\eqref{eq:ito.isometry.quadratic.H2}.
    
    \item {\emph{Associativity of the stochastic integral}}: Let $K$ be
    progressively measurable. Then $K H \in L^2 (M)$ if and only if $K \in L^2
    \left( \int_0^{\cdot} H_s \mathrm{d} M_s \right)$; in that case, we have
    \[ \int_0^{\cdot} K_s H_s \mathrm{d} M_s = \int_0^{\cdot} K_s \mathrm{d}
       \left( \int_0^{\cdot} H_r \mathrm{d} M_r \right)_s . \]
  \end{enumerate}
\end{corollary}

\begin{proof}
  
  \begin{enumerate}
    \item We apply our characterization of stochastic integrals,
    Theorem~\ref{thm:ito-H2-char}: for all $N \in \mathcal{H}^{2, c}$
    \begin{eqnarray*}
      \left\langle \left( \int_0^{\cdot} H_s \mathrm{d} M_s \right)^{\tau}, N
      \right\rangle & = & \left\langle \int_0^{\cdot} H_s \mathrm{d} M_s, N
      \right\rangle^{\tau} = \left( \int_0^{\cdot} H_s \mathrm{d} \langle M, N
      \rangle_s \right)^{\tau}\\
      & = & \int_0^{\cdot} \1_{[0, \tau]} (s) H_s \mathrm{d} \langle M, N
      \rangle_s\\
      & = & \int_0^{\cdot} H_s \mathrm{d} \langle M, N \rangle^{\tau}_s\\
      & = & \int_0^{\cdot} H_s \mathrm{d} \langle M^{\tau}, N \rangle_s .
    \end{eqnarray*}
    The second line shows that $\left( \int_0^{\cdot} H_s \mathrm{d} M_s
    \right)^{\tau} = \int_0^{\cdot} \1_{[0, \tau]} (s) H_s \mathrm{d} M_s$ and
    the last line shows that $\left( \int_0^{\cdot} H_s \mathrm{d} M_s
    \right)^{\tau} = \int_0^{\cdot} H_s \mathrm{d} M_s^{\tau}$.
    
    \item The Lebesgue-Stieltjes integral on the r.h.s.
    of~\eqref{eq:cor.ito.properties.ii} is well defined by the Kunita-Watanabe
    inequality. To prove~\eqref{eq:cor.ito.properties.ii}, we apply
    Theorem~\ref{thm:ito-H2-char} twice, together with the associativity of
    the Lebesgue\mbox{-}Stieltjes integral
    (Remark~\ref{rem:associativity.lebesgue-stieltjes}):
    
    \begin{align*}
      \left\langle \int_0^{\cdot} H_s \mathrm{d} M_s, \int_0^{\cdot} K_s \mathrm{d}
      N_s \right\rangle & = \int_0^{\cdot} H_s \mathrm{d} \left\langle M,
      \int_0^{\cdot} K_r \mathrm{d} N_r \right\rangle_s\\
      & = \int_0^{\cdot} H_s \mathrm{d} \left( \int_0^{\cdot} K_r \mathrm{d} \langle
      M, N \rangle_r \right)_s\\
      & = \int_0^{\cdot} H_s K_s \mathrm{d} \langle M, N \rangle_s .
    \end{align*}
    
    \item We have $\left\langle \int_0^{\cdot} H_s \mathrm{d} M_s \right\rangle
    = \int_0^{\cdot} H^2_s \mathrm{d} \langle M \rangle_s$, so again by
    Remark~\ref{rem:associativity.lebesgue-stieltjes}
    \[ \int_0^{\cdot} K^2_s \mathrm{d} \left( \int_0^{\cdot} H^2_r \mathrm{d}
       \langle M \rangle_r \right)_s = \int_0^{\cdot} (K_s H_s)^2 \mathrm{d}
       \langle M \rangle_s ; \]
    so we see that $K \in L^2 \left( \int_0^{\cdot} H_s \mathrm{d} M_s \right)$
    if and only if $K H \in L^2 (M)$. Moreover, for any $N \in \mathcal{H}^{2,
    c}$, similarly as in Part~ii. we have:
    
    \begin{align*}
      \left\langle \int_0^{\cdot} K_s H_s \mathrm{d} M_s, N \right\rangle & =
      \int_0^{\cdot} K_s H_s \mathrm{d} \langle M, N \rangle_s =
      \int_0^{\cdot} K_s \mathrm{d} \left( \int_0^{\cdot} H_r \mathrm{d} \langle
      M, N \rangle_r \right)_s\\
      & = \int_0^{\cdot} K_s \mathrm{d} \left\langle \int_0^{\cdot} H_r
      \mathrm{d} M_r, N \right\rangle_s = \left\langle \int_0^{\cdot} K_s \mathrm{d}
      \left( \int_0^{\cdot} H_r \mathrm{d} M_r \right)_s, N \right\rangle,
    \end{align*}
    
    which by Theorem~\ref{thm:ito-H2-char} implies the conclusion.
  \end{enumerate}
\end{proof}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Let $B$, $\tilde{B}$ be independent Brownian motions; show that, for any $t
  \geqslant 0$, $B \in L^2 (\tilde{B}^t)$ and $\tilde{B} \in L^2 (B^t)$, and
  compute
  \[ \left\langle \int_0^{\cdot} B_s \mathrm{d} \tilde{B}_s, \int_0^{\cdot}
     \tilde{B}_s \mathrm{d} B_s \right\rangle_t . \]
\end{exercise*}}}{\ }

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Let $B$ be a Brownian motion, let $T > 0$ and let $H \in L^2 (B^T)$. Find a
  formula for
  \[ \left\langle \int_0^{\cdot} H_r \mathrm{d} B^T_r \right\rangle_t \quad
     \text{for } t \geqslant 0. \]
\end{exercise*}}}{\ }

{\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
  \textbf{Alternative construction of stochastic integrals (not
  examinable):} The arguments from Theorem~\ref{thm:ito-H2-char} and
  Corollary~\ref{cor:ito-properties-H2}, and in particular
  formula~\eqref{eq:SIchar}, can be actually used to directly
  {\emph{construct}} stochastic integrals in a more functional analytic
  manner, completely bypassing the approximations by bounded elementary
  processes. The argument goes as follows.
  
  Given $M \in \mathcal{H}^{2, c}$ and $H \in L^2 (M)$, we can define a linear
  operator $\mathcal{I} : \mathcal{H}^{2, c} \rightarrow \mathbb{R}$ by
  \begin{equation}
    \mathcal{I} (N) \coloneq \mathbb{E} \left[ \int_0^{\infty} H_s \mathrm{d}
    \langle M, N \rangle_s \right] . \label{eq:riesz.operator}
  \end{equation}
  This is a bounded operator, since by the Yamada--Watanabe and Cauchy
  inequalities it holds
  
  \begin{align*}
    | \mathcal{I} (N) | & \leqslant \mathbb{E} \left[ \left( \int_0^{+ \infty}
    H_s^2 \mathrm{d} \langle M \rangle_s \right)^{1 / 2} \langle N
    \rangle_{\infty}^{1 / 2} \right] \leqslant \| H \|_{L^2 (M)}  \| N
    \|_{\mathcal{H}^{2, c}} .
  \end{align*}
  
  Since $\mathcal{H}^{2, c}$ is a Hilbert space, by the Riesz representation
  theorem there exists a unique element $\tilde{M} \in \mathcal{H}^{2, c}$
  such that $\mathcal{I} (N) = \langle M, N \rangle_{\mathcal{H}^{2, c}}$ for
  all $N \in \mathcal{H}^{2, c}$, namely
  \[ \mathbb{E} [\tilde{M}_{\infty} N_{\infty}] =\mathbb{E} \left[
     \int_0^{\infty} H_s \mathrm{d} \langle M, N \rangle_s \right] \quad \forall
     \, N \in \mathcal{H}^{2, c} . \]
  Let $\tau$ be any bounded stopping time; applying the above property to $N$
  replaced by $N^{\tau}$, arguing as in Corollary~\ref{cor:ito-properties-H2}
  and using the optional sampling theorem, one finds
  
  \begin{align*}
    \mathbb{E} [\tilde{M}_{\tau} N_{\tau}] & =\mathbb{E} [\tilde{M}_{\infty}
    N^{\tau}_{\infty}]\\
    & =\mathbb{E} \left[ \int_0^{\infty} H_s \mathrm{d} \langle M, N^{\tau}
    \rangle_s \right]\\
    & =\mathbb{E} \left[ \int_0^{\tau} H_s \mathrm{d} \langle M, N \rangle_s
    \right] .
  \end{align*}
  
  By Exercise Sheet~6, this implies that $\tilde{M} N - \int_0^{\cdot} H_s
  \mathrm{d} \langle M, N \rangle_s$ is a (continuous) martingale; moreover one
  can show that $\tilde{M}_0 = 0$ by taking $N_t (\omega) = \1_A
  (\omega)$ for $A \in \mathcal{F}_0$. Therefore
  \[ \langle \tilde{M}, N \rangle = \int_0^{\cdot} H_s \mathrm{d} \langle M, N
     \rangle_s \quad \forall \, N \in \mathcal{H}^{2, c}, \]
  which as we just saw characterizes the stochastic integral. In other words,
  $\tilde{M}$ coming from the application of Riesz theorem to $\mathcal{I}$
  defined by~\eqref{eq:riesz.operator} coincides with $\int_0^{\cdot} H_s
  \mathrm{d} M_s$. 
\end{tabularx}

\subsection{Stochastic integration w.r.t. $M \in \mathcal{M}^c_{\operatorname{loc}}$}

We can now use localization arguments to extend our definition of stochastic
integrals to integrands $M$ which are only continuous local martingales, not
necessarily in $\mathcal{H}^{2, c}$. And even for $M \in \mathcal{H}^{2, c}$,
the following considerations allow us to consider more general integrands than
$H \in L^2 (M)$.

\begin{definition}[$L^2_{\operatorname{loc}} (M)$]
  For $M \in \mathcal{M}^c_{\operatorname{loc}}$, we denote by $L^2_{\tmop{loc}} (M)$
  the space of progressively measurable processes $H$ which satisfy
  \[ \mathbb{P} \left( \int_0^T H_s^2 \mathrm{d} \langle M \rangle_s < \infty
     \right) = 1, \qquad \text{for all } T \geqslant 0. \]
\end{definition}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Show that any c{\`a}dl{\`a}g adapted process $H$ is in $L^2_{\operatorname{loc}}
  (M)$, for any $M \in \mathcal{M}^c_{\operatorname{loc}}$.
\end{exercise*}}}{\ }

\begin{theorem}[Localization of the stochastic integral]
  \label{th:stochintMloc}Let $M \in \mathcal{M}^c_{\operatorname{loc}}$ and let $H \in
  L^2_{\operatorname{loc}} (M)$. Then:
  \begin{enumerate}
    \item There exists a unique process $X \in \mathcal{M}^c_{\operatorname{loc}}$
    such that $X_0 = 0$ and
    \[ \langle X, N \rangle = \int_0^{\cdot} H_s \mathrm{d} \langle M, N
       \rangle_s \quad \forall \, N \in \mathcal{M}^c_{\operatorname{loc}} . \]
    We write $\int_0^{\cdot} H_s \mathrm{d} M_s \coloneq X$ and call this process
    the {\emph{It{\^o} integral}} or {\emph{stochastic integral}} of $H$
    against $M$.
    
    \item For any stopping time $\tau$, we have
    \[ \int_0^{\cdot} H_s \1_{[0, \tau]} (s) \mathrm{d} M_s = \left(
       \int_0^{\cdot} H_s \mathrm{d} M_s \right)^{\tau} = \int_0^{\cdot} H_s
       \mathrm{d} M_s^{\tau} . \]
    \item For any other $N \in \mathcal{M}^c_{\operatorname{loc}}$ and $K \in
    L^2_{\operatorname{loc}} (N)$, we have
    \begin{equation}
      \left\langle \int_0^{\cdot} H_s \mathrm{d} M_s, \int_0^{\cdot} K_s
      \mathrm{d} N_s \right\rangle = \int_0^{\cdot} H_s K_s \mathrm{d} \langle M, N
      \rangle_s . \label{eq:qcv.stochint.Mloc}
    \end{equation}
    \item For progressive $K$, we have $K \in L^2_{\operatorname{loc}} 
    (\int_0^{\cdot} H_s \mathrm{d} M_s)$ if and only $K H \in L^2_{\operatorname{loc}}
    (M)$; in that case
    \[ \int_0^{\cdot} K_s H_s \mathrm{d} M_s = \int_0^{\cdot} K_s \mathrm{d}
       \left( \int_0^{\cdot} H_r \mathrm{d} M_r \right)_s . \]
    \item If $M \in \mathcal{H}^{2, c}$ and $H \in L^2 (M)$, then
    $\int_0^{\cdot} H_s \mathrm{d} M_s$ is the same process that we constructed
    in Theorem~\ref{thm:ito-H2}; in other words, this notion of stochastic
    integral is a consistent extension of the previous one.
  \end{enumerate}
\end{theorem}

\begin{proof}
  i.: Uniqueness is clear by the usual argument: if $X, Y \in
  \mathcal{M}^c_{\operatorname{loc}}$ satisfy $X_0 = Y_0 = 0$ and $\langle X, N
  \rangle = \langle Y, N \rangle$ for all $N \in \mathcal{M}^c_{\operatorname{loc}}$,
  then $X - Y \in \mathcal{M}^c_{\operatorname{loc}}$ with $\langle X - Y \rangle =
  0$, and therefore $X - Y \equiv 0$.
  
  For the construction of $\int_0^{\cdot} H_s \mathrm{d} M_s$, as before we may
  assume that $M_0 = 0$; otherwise, we can consider $M - M_0$, which satisfies
  $\langle M, N \rangle = \langle M - M_0, N \rangle$.
  
  Let
  \[ \tau_n = \inf \left\{ t \geqslant 0 : \int_0^t (1 + H_s^2) \mathrm{d} \langle
     M \rangle_s \geqslant n \right\}, \]
  which is a localizing sequence by the definition of $H \in L^2_{\operatorname{loc}}
  (M)$. Then $M^{\tau_n} \in \mathcal{H}^{2, c}$ (by
  Corollary~\ref{cor:lp-martingale}) and $H \in L^2 (M^{\tau_n})$; therefore
  we can define the stochastic integral $\int_0^{\cdot} H_s \mathrm{d}
  M_s^{\tau_n} \in \mathcal{H}^{2, c}$ using Theorem~\ref{thm:ito-H2}. For $m
  > n$, we get
  \[ \left( \int_0^{\cdot} H_s \mathrm{d} M_s^{\tau_m} \right)^{\tau_n} =
     \int_0^{\cdot} H_s \mathrm{d} (M^{\tau_m})^{\tau_n}_s = \int_0^{\cdot}
     H_s \mathrm{d} M_s^{\tau_n}, \]
  so that we can define without ambiguity
  \[ \left( \int_0^t H_s \mathrm{d} M_s \right) \1_{\{t \leqslant \tau_n
     \}} \coloneq_{\nosymbol} \left( \int_0^t H_s \mathrm{d} M_s^{\tau_n} \right)
     \1_{\{t \leqslant \tau_n \}} \]
  to obtain a unique process $\int_0^{\cdot} H_s \mathrm{d} M_s$ such that
  $(\int_0^{\cdot} H_s \mathrm{d} M_s)^{\tau_n} = \int_0^{\cdot} H_s \mathrm{d}
  M_s^{\tau_n}$ for all $n$. In particular, $\int_0^{\cdot} H_s \mathrm{d} M_s
  \in \mathcal{M}^c_{\operatorname{loc}}$ by definition, with localizing sequence
  being given exactly by $\{ \tau_n \}_n$; we also have $\int_0^0 H_s \mathrm{d}
  M_s = 0$ by definition.
  
  Given $N \in \mathcal{M}^c_{\operatorname{loc}}$, similarly we may assume without
  loss of generality that $N_0 = 0$, since the quadratic covariation does not
  depend on $N_0$. Let $\tau_n' = \inf \{t \geqslant 0 : \langle N \rangle_t
  \geqslant n\}$ and $\sigma_n = \tau_n \wedge \tau_n'$. Then $N^{\sigma_n}
  \in \mathcal{H}^{2, c}$ and
  
  \begin{align*}
    \left\langle \int_0^{\cdot} H_s \mathrm{d} M_s, N \right\rangle^{\sigma_n} &
    = \left\langle \left( \int_0^{\cdot} H_s \mathrm{d} M_s \right)^{\sigma_n},
    N^{\sigma_n} \right\rangle = \left\langle \int_0^{\cdot} H_s \mathrm{d}
    M_s^{\sigma_n}, N^{\sigma_n} \right\rangle\\
    & = \int_0^{\cdot} H_s \mathrm{d} \langle M^{\sigma_n}, N^{\sigma_n}
    \rangle_s = \int_0^{\cdot} H_s \mathrm{d} \langle M, N \rangle^{\sigma_n}_s
    = \left( \int_0^{\cdot} H_s \mathrm{d} \langle M, N \rangle_s
    \right)^{\sigma_n},
  \end{align*}
  
  so for $n \rightarrow \infty$ we get $\left\langle \int_0^{\cdot} H_s
  \mathrm{d} M_s, N \right\rangle = \int_0^{\cdot} H_s \mathrm{d} \langle M, N
  \rangle_s .$
  
  Properties ii. and iv. of the integral $\int_0^{\cdot} H_s \mathrm{d} M_s$
  then follow via localization from Corollary~\ref{cor:ito-properties-H2};
  iii. follows from applying part i. twice together with the associativity of
  Lebesgue-Stjeltes integrals. Finally, v. comes from the characterizing
  property of Theorem~\ref{thm:ito-H2-char}.
\end{proof}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Let $B$ be a Brownian motion, $H \in L^2_{\operatorname{loc}} (B)$. What can we say
  about $\mathbb{E} \left[ \int_0^1 H_s \mathrm{d} B_s \right]$?
\end{exercise*}}}{}

\begin{remark}
  Let $M \in \mathcal{M}^c_{\operatorname{loc}}$ and $H \in L^2_{\tmop{loc}} (M)$.
  Then $\int_0^{\cdot} H_s \mathrm{d} M_s \in \mathcal{M}^c_{\operatorname{loc}}$ is a
  continuous local martingale starting from $0$ and
  by~\eqref{eq:qcv.stochint.Mloc} (with $M = N$, $H = K$), its quadratic
  variation is given by
  \begin{equation}
    \left\langle \int_0^{\cdot} H_s \mathrm{d} M_s \right\rangle_t = \int_0^t
    H_s^2 \mathrm{d} \langle M \rangle_s . \label{eq:qv.stochint.Mloc}
  \end{equation}
  By Corollary~\ref{cor:lp-martingale}, we deduce the following: if
  \[ \mathbb{E} \left[ \int_0^t H_s^2 \mathrm{d} \langle M \rangle_s \right] <
     \infty \quad \forall \, t \geqslant 0, \]
  then $\int_0^{\cdot} H_s \mathrm{d} M_s \in \mathcal{M}^{2, c}$ (and not just
  $\mathcal{M}^c_{\operatorname{loc}}$); being a genuine martingale, it satisfies
  \[ \mathbb{E} \left[ \int_0^t H_s \mathrm{d} M_s \right] = 0, \qquad \mathbb{E}
     \left[ \left( \int_0^t H_s \mathrm{d} M_s \right)^2 \right] =\mathbb{E}
     \left[ \int_0^t H_s^2 \mathrm{d} \langle M \rangle_s \right] \qquad \forall
     \, t \geqslant 0. \]
  If additionally
  \[ \mathbb{E} \left[ \int_0^{\infty} H_s^2 \mathrm{d} \langle M \rangle_s
     \right] < \infty, \]
  then $\int_0^{\cdot} H_s \mathrm{d} M_s \in \mathcal{H}^{2, c}$. In that case,
  we may write $H \in L^2 (M)$, even though $M \notin \mathcal{H}^{2, c}$.
\end{remark}

\begin{center}
  \hrulefill\hrulefill\textbf{ End of the lecture on January 8}
  \hrulefill\hrulefill
\end{center}

\

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Strengthen the above result as follows: if $M \in
  \mathcal{M}^c_{\operatorname{loc}}$, $H \in L^2_{\tmop{loc}} (M)$ are such that
  \[ \mathbb{E} \left[ \left( \int_0^t H_s^2 \mathrm{d} \langle M \rangle_s
     \right)^{1 / 2} \right] \quad \forall \, t \geqslant 0 \]
  then $\int_0^{\cdot} H_s \mathrm{d} M_s$ is a genuine martingale, and in
  particular $\mathbb{E} \left[ \int_0^t H_s \mathrm{d} M_s \right] = 0$ for all
  $t \geqslant 0$.
\end{exercise*}}}{\ }

\begin{example}
  {\tmdummy}
  
  \begin{enumerate}
    \item If $B$ is a Brownian motion and $G, H \in L^2_{\operatorname{loc}} (B)$,
    then
    \[ \left\langle \int_0^{\cdot} G_s \mathrm{d} B_s, \int_0^{\cdot} H_s
       \mathrm{d} B_s \right\rangle_t = \int_0^t G_s H_s \mathrm{d} s ; \]
    in particular, we get a natural extension of
    formula~\eqref{eq:ito.isometry.quadratic.H2}:
    \[ \left\langle \int_0^{\cdot} H_s \mathrm{d} B_s \right\rangle_t = \int_0^t
       H_s^2 \mathrm{d} s. \]
    \item Every c{\`a}dl{\`a}g adapted process $H$ belongs $L^2_{\operatorname{loc}}
    (M)$, for all $M \in \mathcal{M}^c_{\operatorname{loc}}$. But in general we do not
    have $\mathbb{E} \left[ \int_0^t H_s^2 \mathrm{d} \langle M \rangle_s \right]
    < \infty$. Consider for example a Brownian motion $B$ and the integrand
    $H_s = e^{B_s^4}$. Then
    \[ \mathbb{E} \left[ \int_0^t H_s^2 \mathrm{d} s \right] =\mathbb{E} \left[
       \int_0^t e^{2 B_s^4} \mathrm{d} s \right] = \int_0^t \left(
       \frac{1}{\sqrt{2 \pi s}} \int_{\mathbb{R}} e^{2 x^4} e^{- \frac{x^2}{2
       s}} \mathrm{d} x \right) \mathrm{d} s, \]
    and the inner integral is infinite for all $s > 0$.
  \end{enumerate}
\end{example}

\subsection{Stochastic integration w.r.t. continuous semimartingales}

Recall that a continuous semimartingale $X$ is an adapted process
\[ X = X_0 + M + A, \]
where $M \in \mathcal{M}^c_{\operatorname{loc}}$ with $M_0 = 0$ and $A \in
\mathcal{A}$ with $A_0 = 0$, and that this decomposition is unique because
$\mathcal{A} \cap \mathcal{M}^c_{\operatorname{loc}} = \{ 0 \}$ up to
indistinguishability.

\begin{definition}
  Let $X = X_0 + M + A$ be a continuous semimartingale. We define
  \[ \mathbb{L} (X) \coloneq \left\{ H \in L^2_{\operatorname{loc}} (M) : \int_0^t |
     H_s | \mathrm{d} V (A)_s < \infty \text{ almost surely for all } t \geqslant
     0 \right\}, \]
  or equivalently
  \[ \mathbb{L} (X) \coloneq \left\{ H \operatorname{progressive} : \int_0^t | H_s |
     \mathrm{d} V (A)_s + \int_0^t H_s^2 \mathrm{d} \langle M \rangle < \infty \text{
     almost surely for all } t \geqslant 0 \right\} . \]
  For $H \in \mathbb{L} (X)$, we define
  \[ \int_0^{\cdot} H_s \mathrm{d} X_s \coloneq \int_0^{\cdot} H_s \mathrm{d} M_s +
     \int_0^{\cdot} H_s \mathrm{d} A_s \]
  where the first term is interpreted as in the stochastic sense coming from
  Theorem~\ref{th:stochintMloc}, while the second term is interpreted in the
  Lebesgue-Stjeltes sense.
\end{definition}

\begin{remark}
  Let $H$ be progressively measurable and {\emph{locally bounded}}, in the
  sense that
  \[ \sup_{t \in [0, T]} | H_t (\omega) | < + \infty \quad \forall \, T \in
     (0, + \infty) \]
  for $\mathbb{P}$-a.e. $\omega$. Then $H \in \mathbb{L} (X)$ for every
  continuous semimartingale $X$.
\end{remark}

\begin{lemma}
  The following hold:
  \begin{enumerate}
    \item Let $H_s (\omega) = \sum_{k = 0}^{n - 1} h_k (\omega)
    \1_{(t_k, t_{k + 1}]} (s)$, for some real-valued
    $\mathcal{F}_{t_k}$--measurable random variables $h_k$. Then $H \in
    \mathbb{L} (X)$ for any continuous semimartingale $X$ and
    \begin{equation}
      \int_0^t H_s \mathrm{d} X_s = \sum_{k = 0}^{n - 1} h_k (X_{t_{k + 1} \wedge
      t} - X_{t_k \wedge t}) . \label{eq:identity.stochint.elementary}
    \end{equation}
    \item Let $\tau$ be a stopping time and let $h$ a real-valued,
    $\mathcal{F}_{\tau}$-measurable random variable; let $H \coloneq h
    \1_{[\tau, \infty)}$ (with the convention that $\1_{[\tau, \infty)} \equiv
    0$ when $\tau = + \infty$). Then $H \in \mathbb{L} (X)$ for any continuous
    semimartingale $X$ and
    \[ \int_0^t H_s \mathrm{d} X_s = h (X_t - X_{\tau \wedge t}) . \]
  \end{enumerate}
\end{lemma}

\begin{proof}
  Since $h_k$ are real-valued and the sum is finite, it is clear that $\sup_{t
  \geqslant 0} | H_t (\omega) | < \infty$ for every $\omega$, so that $H \in
  \mathbb{L} (X)$; similarly for $H = h \1_{[\tau, \infty)}$ in ii.
  Let $X = X_0 + M + A$; both identities are true for integration w.r.t. $A$
  by ($\omega$-wise) properties of Lebesgue-Stjeltes integral, and $X_0$ does
  not play any role, therefore wlog we may assume $X = M$ with $M \in
  \mathcal{M}^c_{\operatorname{loc}}$, $M_0 = 0$. By localization, we may further
  reduce ourselves to the case of $M \in \mathcal{H}^{2, c}$.
  
  In part ii., up to another localization/approximation procedure
  (cf. Corollary~\ref{cor:ucp.criterion.locmart}, or the upcoming
  Section~\ref{subsec:approx.stoch.int}), we may further assume that $h \in
  L^{\infty} (\Omega)$.
  
  The rest of the proof is left as an exercise in Exercise Sheet 10.
\end{proof}

Overall in this chapter we have constructed various stochastic integrals,
under different assumptions on the integrand $H$ and the integrator $M$ as
``input variables'', obtaining an integral process $\int_0^{\cdot} H_s \mathrm{d}
M_s$ in different classes of processes as an ``output''. In the following
table, we summarize these results; we write $\mathcal{S}^c$ for the space of
continuous semimartingales.
\[ \begin{array}{|l|c|c|}
     \hline
     H \in \cdot & M \in \cdot & \int_0^{\cdot} H_s \mathrm{d} M_s \in
     \cdot\\
     \hline
     L^2 (M) & \mathcal{H}^{2, c} & \mathcal{H}^{2, c}\\
     \hline
     L^2_{\operatorname{loc}} (M) & \mathcal{M}^c_{\tmop{loc}} &
     \mathcal{M}^c_{\operatorname{loc}}\\
     \hline
     L^2 (M) & \mathcal{M}^c_{\operatorname{loc}} & \mathcal{H}^{2, c}\\
     \hline
     L^2_{\operatorname{loc}} (M) \text{ + } \mathbb{E} \left[ \int_0^t H_s^2 \mathrm{d}
     \langle M \rangle_s \right] < \infty \, \forall t \geqslant 0 &
     \mathcal{M}^c_{\operatorname{loc}} & \mathcal{M}^{2, c}\\
     \hline
     \mathbb{L} (M) & \mathcal{S}^c & \mathcal{S}^c\\
     \hline
   \end{array} \]

\subsection{Approximations of stochastic
integrals}\label{subsec:approx.stoch.int}

Recall the ucp-convergence from Definition~\ref{defn:ucp}; it is a natural
notion of convergence for stochastic integrals, as the next results show.

\begin{proposition}[``Dominated convergence'' for stochastic integrals]
  \label{prop:ito-domconv}Let $X$ be a continuous semimartingale; let $\{
  H^{(n)} \}_n, H$ be progressively measurable and such that
  $\mathbb{P}$\mbox{-}almost surely
  \[ H_t^{(n)} \to H_t \qquad \forall \, t \geqslant 0. \]
  Further assume that there exists $K \in \mathbb{L} (X)$ with $K \geqslant
  0$, such that $\mathbb{P}$-almost surely
  \begin{equation}
    | H^{(n)}_t | \leqslant K_t \qquad \forall \, t \geqslant 0.
    \label{eq:ito.domconv.assumption}
  \end{equation}
  Then $(H^{(n)}), H \subset \mathbb{L} (X)$ and $\int_0^{\cdot} H^{(n)}_s
  \mathrm{d} X_s \rightarrow \int_0^{\cdot} H_s \mathrm{d} X_s$ in ucp.
\end{proposition}

\begin{remark}
  \label{rem:ito.comconv}Assumption~\eqref{eq:ito.domconv.assumption} holds in
  particular if for almost all $\omega$ and all $T \geqslant 0$ there exists
  $C_T (\omega)$ with $| K_t (\omega) | \leqslant C_T (\omega)$ for all $t \in
  [0, T]$. Indeed in this case one may take
  \[ K_t (\omega) \coloneq \sum_{n = 1}^{\infty} C_n (\omega)  \1_{[0,
     n]} (t) . \]
\end{remark}

\begin{proof}
  Since $| H^{(n)}_s | \leqslant K_s$ and $| H_s | \leqslant K_s$ with $K \in
  \mathbb{L} (X)$, we clearly have $H^{(n)}, H \in \mathbb{L} (X)$. Let $X =
  X_0 + M + A$ be the semimartingale decomposition of $X$; to show the ucp
  convergence, we similarly decompose $\int_0^{\cdot} H^{(n)}_s \mathrm{d} X_s =
  \int_0^{\cdot} H^{(n)}_s \mathrm{d} M_s + \int_0^{\cdot} H^{(n)}_s \mathrm{d}
  A_s$ and treat the two terms separately.
  
  For the finite variation terms $\int_0^{\cdot} H^{(n)}_s \mathrm{d} A_s$, the
  ucp convergence follows by the (usual) dominated convergence theorem applied
  $\omega$-wise (so that one gets $\mathbb{P}$-a.s. convergence uniformly on
  compact sets, which is stronger than ucp convergence).
  
  For the local martingale part, note that by~\eqref{eq:qv.stochint.Mloc} we
  have
  \[ \left\langle \int_0^{\cdot} H^{(n)}_s \mathrm{d} M_s - \int_0^{\cdot} H_s
     \mathrm{d} M_s \right\rangle = \left\langle \int_0^{\cdot} (H^{(n)}_s -
     H_s) \mathrm{d} M_s \right\rangle = \int_0^{\cdot} | H^{(n)}_s - H_s |^2
     \mathrm{d} \langle M \rangle_s ; \]
  as before, by the usual dominated convergence theorem applied $\omega$-wise,
  we deduce that the above quadratic variation is converging to $0$ in ucp as
  $n \rightarrow \infty$. It then follows
  from~Corollary~\ref{cor:ucp.criterion.locmart} that $\int_0^{\cdot}
  H^{(n)}_s \mathrm{d} M_s \rightarrow \int_0^{\cdot} H_s \mathrm{d} M_s$ in ucp.
\end{proof}

\begin{corollary}[``Stochastic integrals respect ucp convergence'']
  \label{cor:stoch.integr.respects.ucp}Let $X$ be a continuous semimartingale;
  let $\{ H^{(n)} \}_n, H$ be continuous, adapted processes such that
  \[ H^{(n)} \to H \quad \operatorname{in} \tmop{ucp} . \]
  Then $\int_0^{\cdot} H^{(n)}_s \mathrm{d} X_s \rightarrow \int_0^{\cdot} H_s
  \mathrm{d} X_s$ in ucp.
\end{corollary}

\begin{proof}
  Since $H^{(n)}$ is continuous and adapted, it is progressive and therefore
  (by continuity) $H^{(n)} \in \mathbb{L} (X)$; similarly for $H$.
  
  Since $H^{(n)} \rightarrow H$ in ucp, by Lemma~\ref{lem:ucp.metric} we can
  extract a subsequence $\{ H^{(n_k)} \}_k$ such that $\mathbb{P}$-a.s.
  $H^{(n_k)} (\omega) \rightarrow H (\omega)$ uniformly on compact sets. As a
  consequence of the properties of uniform convergence on compact sets (see
  exercise below), we deduce that the process
  \[ K_t \coloneq \sup_{n \in \mathbb{N}}  | H^{(n_k)}_t | + | H_t | \]
  is continuous and adapted, thus in $\mathbb{L} (X)$, and
  assumption~\eqref{eq:ito.domconv.assumption} is satisfies. We deduce from
  Proposition~\ref{prop:ito-domconv} that $\int_0^{\cdot} H^{(n_k)}_s \mathrm{d}
  X_s \rightarrow \int_0^{\cdot} H_s \mathrm{d} X_s$ in ucp.
  
  {\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
    \textbf{General fact from metric spaces:} given a metric space $(E, d)$,
    a sequence $\{ x^n \}_n \subset E$ and $x \in E$, the following are
    equivalent:
    \begin{enumerate}
      \item $x^n \rightarrow x$ in $E$, namely $d (x^n, x) \rightarrow 0$ as
      $n \rightarrow \infty$.
      
      \item Any subsequence $\{ x^{n_j} \}_j$ of $\{ x^n \}_n$ admits a
      further subsequence $\left\{ x^{n_{j_k}} \right\}_k$ such that
      $x^{n_{j_k}} \rightarrow x$ in $E$, namely $d \left( x^{n_{j_k}}, x
      \right) \rightarrow 0$ as $n \rightarrow \infty$.
    \end{enumerate}
  \end{tabularx}
  
  By the same argument as above, for any other given subsequence $\{ H^{(n_j)}
  \}_j$, we can extract a further subsequence $\left\{ H^{(n_{j_k})}
  \right\}_k$ such that $\int_0^{\cdot} H^{(\tilde{n}_{j_k})}_s \mathrm{d} X_s
  \rightarrow \int_0^{\cdot} H_s \mathrm{d} X_s$ in ucp; since the upc topology is
  induced by a distance (Lemma~\ref{lem:ucp.metric}), the above fact implies
  that the whole sequence $\left\{ \int_0^{\cdot} H^{(n)}_s \mathrm{d} X_s
  \right\}_n$ converges.
\end{proof}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Let $\{ f^n \}_n$, $f$ be deterministic continuous functions from
  $\mathbb{R}_+$ to $\mathbb{R}$ such that $f^n \rightarrow f$ uniformly on
  compact sets. Show that
  \[ t \mapsto \sup_{n \geqslant 0}  | f^n_t | \]
  is a continuous function, bounded on compact sets.
\end{exercise*}}}{\ }

\begin{corollary}
  \label{cor:ito-domconv}Let $X$ be a continuous semimartingale and let $H$ be
  a continuous, adapted process. Let $\pi^n = \{ t^n_k \}_{k \geqslant 0}$ be
  a sequence of deterministic, locally finite partitions with infinitesimal
  mesh. Then
  \[ \left( \sum_{k = 0}^{\infty} H_{t_k^n} (X_{t^n_{k + 1} \wedge t} -
     X_{t^n_k \wedge t}) \right)_{t \ge 0} \longrightarrow \int_0^{\cdot}
     H_s \mathrm{d} X_s \qquad \text{in ucp} . \]
\end{corollary}

\begin{proof}
  This is a special case of Proposition~\ref{prop:ito-domconv}, with $K_t
  \coloneq \sup_{s \in [0, t]} | H_s |$ and
  \[ H^n = \sum_{k = 0}^{\infty} H_{t^n_k}  \1_{(t^n_k, t^n_{k + 1}]}
  \]
  (cf. identity~\eqref{eq:identity.stochint.elementary}).
\end{proof}

The next result already provides one important ``rule of calculus'' for
stochastic integrals; we will see later a far reaching generalization.

\begin{theorem}[Integration by parts formula for stochastic integrals]
  \label{thm:IBP.stochint}Let $X, Y$ be continuous semimartingales. Then, up
  to indistinguishability, the following {\emph{integration by parts}} formula
  holds:
  \begin{equation}
    X_t Y_t = X_0 Y_0 + \int_0^t X_s \mathrm{d} Y_s + \int_0^t Y_s \mathrm{d} X_s +
    \langle X, Y \rangle_t \qquad \forall \, t \geqslant 0.
    \label{eq:IBP.formula.stochint}
  \end{equation}
  In particular, for $X = Y$ we find
  \begin{equation}
    X^2_t = X_0^2 + 2 \int_0^t X_s \mathrm{d} X_s + \langle X \rangle_t \qquad
    \forall \, t \geqslant 0. \label{eq:Ito.formula.square}
  \end{equation}
\end{theorem}

\begin{proof}
  Exercise Sheet~10.
\end{proof}

Formula~\eqref{eq:IBP.formula.stochint} may be formally written in
differential form as
\[ \text{``} \mathrm{d} (X Y) = X \mathrm{d} Y + Y \mathrm{d} X + \mathrm{d} \langle X, Y
   \rangle . \text{''} \]
\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Using formula~\eqref{eq:Ito.formula.square}, are you now able to show that
  if $X$ is a continuous semimartingale, then $X^2$ is a continuous
  semimartingale?
\end{exercise*}}}{\ }

\begin{corollary}
  \label{cor:polynomial.ito.formula}Let $X$ be a continuous semimartingale.
  Then for any $n \in \mathbb{N}$, up to indistinguishability, it holds that
  \[ X^n_t = X^n_0 + \int_0^t n X^{n - 1}_s \mathrm{d} X_s + \frac{1}{2} \int_0^t
     n (n - 1) X^{n - 2}_s \mathrm{d} \langle X \rangle_s \qquad \forall \, t
     \geqslant 0. \]
  With $f (x) = x^n$, we can also write the above formula as
  \[ f (X_t) = f (X_0) + \int_0^t f' (X_s) \mathrm{d} X_s + \frac{1}{2} \int_0^t
     f'' (X_s) \mathrm{d} \langle X \rangle_s . \]
\end{corollary}

\begin{proof}
  Exercise Sheet~10.
\end{proof}

For practical purposes, Corollary~\ref{cor:stoch.integr.respects.ucp} is often
very useful; but when $X = M \in \mathcal{M}^c_{\operatorname{loc}}$, ucp convergence
of the integrands can be drastically relaxed.

\begin{definition}
  Let $M \in \mathcal{M}^c_{\operatorname{loc}}$ and let $H^{(n)}, H \in
  L^2_{\operatorname{loc}} (M)$. We say that $H^{(n)} \rightarrow H$ in
  $L^2_{\operatorname{loc}} (M)$ if
  \[ \lim_{n \rightarrow \infty} \, \mathbb{P} \left( \int_0^T | H^{(n)}_s -
     H_s |^2 \mathrm{d} \langle M \rangle_s > \varepsilon \right) = 0 \quad
     \forall \, \varepsilon > 0, \, T \in (0, + \infty) . \]
\end{definition}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Show that, if $H^{(n)} \rightarrow H$ in ucp, then $H^{(n)} \rightarrow H$
  in $L^2_{\operatorname{loc}} (M)$.
\end{exercise*}}}{\ }

\begin{lemma}
  Let $M \in \mathcal{M}^c_{\operatorname{loc}}$. Then the following are equivalent:
  \begin{enumerate}
    \item $H^{(n)} \rightarrow H$ in $L^2_{\operatorname{loc}} (M)$;
    
    \item $\int_0^{\cdot} H^{(n)}_s \mathrm{d} M_s \rightarrow \int_0^{\cdot} H_s
    \mathrm{d} M_s$ in ucp.
  \end{enumerate}
\end{lemma}

\begin{proof}
  \
  
  {\noindent}\begin{tabularx}{1.0\textwidth}{@{}X@{}}
    Proof skipped in the lectures, included here for completeness.
  \end{tabularx}
  
  Set $\tilde{M}^{(n)} \coloneq \int_0^{\cdot} H^{(n)}_s \mathrm{d} M_s$,
  $\tilde{M} \coloneq \int_0^{\cdot} H_s \mathrm{d} M_s$. By
  Corollary~\ref{cor:ucp.criterion.locmart}, b) is equivalent to
  \[ \langle \tilde{M}^{(n)} - \tilde{M} \rangle = \left\langle \int_0^{\cdot}
     (H^{(n)}_s - H_s) \mathrm{d} M_s \right\rangle = \int_0^{\cdot} | H^{(n)}_s -
     H_s |^2 \mathrm{d} \langle M \rangle_s \rightarrow 0 \quad \operatorname{in}
     \operatorname{ucp} . \]
  But by definition, $\int_0^{\cdot} | H^{(n)}_s - H_s |^2 \mathrm{d} \langle M
  \rangle_s \rightarrow 0$ in ucp coincides with $H^{(n)} \rightarrow H$ in
  $L^2_{\operatorname{loc}} (M)$.
\end{proof}

\begin{center}
  \
  
  \hrulefill\hrulefill\textbf{ End of the lecture on January 9}
  \hrulefill\hrulefill
\end{center}

\begin{definition}[Stratonovich integral]
  If $X, Y$ are continuous semimartingales, then we define the
  {\emph{Stratonovich integral}} of $Y$ w.r.t. $X$ as
  \[ \int_0^{\cdot} Y_s \circ \mathrm{d} X_s \coloneq \int_0^{\cdot} Y_s \mathrm{d} X_s
     + \frac{1}{2} \langle X, Y \rangle . \]
\end{definition}

The motivation for considering this at first weird looking integral will
become clear later. For now let us just observe a couple of properties coming
from the definition; the first one may be interpreted as the fact that the
Stratonovich integral arises from the limit of Riemann-type sums obtained by
using the {\emph{trapezoidal rule}}.

\begin{proposition}
  \label{prop:strat.integr.properties}Let $X, Y$ be continuous
  semimartingales. Let $\pi^n = \{ t^n_k \}_{k \geqslant 0}$ be a sequence of
  deterministic, locally finite partitions with infinitesimal mesh. Then
  \[ \left( \sum_{k = 0}^{\infty} \frac{1}{2} (Y_{t^n_{k + 1} \wedge t} +
     Y_{t_k^n \wedge t}) (X_{t^n_{k + 1} \wedge t} - X_{t^n_k \wedge t})
     \right)_{t \ge 0} \longrightarrow \int_0^{\cdot} Y_s \circ \mathrm{d} X_s
     \qquad \text{in ucp} . \]
  Moreover the following {\emph{integration by parts}} formula for
  Stratonovich integrals holds:
  \begin{equation}
    X_t Y_t = X_0 Y_0 + \int_0^t X_s \circ \mathrm{d} Y_s + \int_0^t Y_s \circ
    \mathrm{d} X_s . \label{eq:IBP.Stratonovich}
  \end{equation}
\end{proposition}

\begin{proof}
  Exercise Sheet~11.
\end{proof}

Note that, differently from~\eqref{eq:Ito.formula.square},
formula~\eqref{eq:IBP.Stratonovich} now does not contain any quadratic
covariation term and resembles the usual integration by parts rule from
classical calculus. In the same way in which standard integration by parts
comes from integrating the product rule for derivatives $(f g)' = f g' + f'
g$, here~\eqref{eq:IBP.Stratonovich} may be formally written as
\[ \text{``} \circ \mathrm{d} (X Y) = X \circ \mathrm{d} Y + Y \circ \mathrm{d} X.
   \text{''} \]

\appendix\section{Probability theory background material}

\subsection{Gaussian random variables}\label{app:gaussian}

We recall here several fundamental facts about Gaussian random variables. We
start by considering the one-dimensional case.

\begin{definition}[Gaussian/normal distribution]
  A random variable $X$ is called {\emph{standard Gaussian}} or
  {\emph{standard normal}}, and we write $X \sim \mathcal{N} (0, 1)$, if it
  has probability density
  \[ f (x) = \frac{1}{\sqrt{2 \pi}} e^{- \frac{x^2}{2}} . \]
  Let $m \in \mathbb{R}$ and $\sigma \geqslant 0$. A random variable $Y$ has
  the {\emph{Gaussian distribution}}, or {\emph{normal distribution}},
  $\mathcal{N} (m, \sigma^2)$ if there exists a standard normal variable $Z$
  (namely $Z \sim \mathcal{N} (0, 1)$) such that
  \begin{equation}
    \label{eq:normal characterization as sum} Y = m + \sigma Z.
  \end{equation}
  Equivalently, $Y \sim \mathcal{N} (m, \sigma^2)$ if and only if its
  characteristic function is given by
  \begin{equation}
    \label{eq:normal characterization Fourier} \mathbb{E} [e^{iuY}] = e^{ium -
    \sigma^2 u^2 / 2}, \qquad u \in \mathbb{R}.
  \end{equation}
  A random variable $Y$ is a {\emph{centered Gaussian}} (or {\emph{centered
  normal}}) if it has distribution $\mathcal{N} (0, \sigma^2)$, namely $m =
  0$.
\end{definition}

\tmcolor{blue}{\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Let $X \sim \mathcal{N} (0, 1)$. By direct computation, show that
  \[ \mathbb{E} [e^{\lambda X}] = e^{\frac{\lambda^2}{2}} \quad \forall \,
     \lambda \in \mathbb{R} \]
  and that
  \[ \mathbb{E} [e^{\lambda | X |^2}] = \left\{\begin{array}{l}
       + \infty \hspace{3.2em} \operatorname{if} \lambda \geqslant 1 / 2\\
       \frac{1}{\sqrt{1 - 2 \lambda}} \qquad \operatorname{if} \lambda < 1 / 2
     \end{array}\right. . \]
\end{exercise*}}}{\ }}

Let $Y \sim \mathcal{N} (m, \sigma^2)$. Recall that if $\sigma > 0$, then $Y$
has a density
\[ f (x) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{- \frac{x^2}{2 \sigma^2}} . \]
For $\sigma = 0$ we have $\mathbb{P} (Y = m) = 1$. Recall also that
\[ m =\mathbb{E} [Y], \qquad \sigma^2 = \operatorname{Var} (Y) . \]
\begin{remark}
  \label{rmk:univariate gaussian}{\tmdummy}
  
  \begin{enumerate}
    \item If $Y \sim \mathcal{N} (m, \sigma^2)$ and $\tilde{Y} \sim
    \mathcal{N} (\tilde{m}, \tilde{\sigma}^2)$ are independent Gaussian random
    variables, then (\ref{eq:normal characterization Fourier}) yields that $Y
    + \tilde{Y} \sim \mathcal{N} (m + \tilde{m}, \sigma^2 +
    \tilde{\sigma}^2)$. Namely, sum of independent Gaussian variables is still
    Gaussian.
    
    \item If $Y \sim \mathcal{N} (m, \sigma^2)$, then $\lambda Y \sim
    \mathcal{N} (m, \lambda^2 \sigma^2)$. Moreover if $Y \sim \mathcal{N} (0,
    \sigma^2)$, so that $Y = \sigma Z$ for some $Z \sim \mathcal{N} (0, 1)$,
    then for any $p > 0$ it holds:
    \[ \mathbb{E} [| Y |^p] = \sigma^p \mathbb{E} [| Z |^p] =\mathbb{E}
       [Y^2]^{p / 2} c_p, \]
    for $c_p =\mathbb{E} [| Z |^p] \in (0, \infty)$. So up to a constant
    $c_p$, the $p$-th absolute moment of $Y$ is simply the second moment
    raised to the power $\frac{p}{2}$.
  \end{enumerate}
\end{remark}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  It is not true for general centered random variables that $\mathbb{E} [| Y
  |^p] \leqslant C\mathbb{E} [| Y |^2]^{\frac{p}{2}}$. Can you find a centered
  random variable $Y$ with $\mathbb{E} [Y^2]^{\frac{p}{2}} < \infty
  =\mathbb{E} [| Y |^p]$ for some $p > 2$?
\end{exercise*}}}{\ }

The following result shows that Gaussian random variables are in some sense
very rigid: the limit in distribution of Gaussian random variables still has
to be Gaussian.

\begin{lemma}
  \label{lem:limit.gaussians}Let $(X_n)_{n \in \mathbb{N}}$ be a sequence of
  Gaussian random variables such that $X_n \sim \mathcal{N} (m_n,
  \sigma_n^2)$. Then $(X_n)$ converges in distribution to a random variable
  $X$ if and only if there exist $m \in \mathbb{R}$ and $\sigma \geqslant 0$
  such that $m_n \rightarrow m$ and $\sigma_n \rightarrow \sigma$. In that
  case $X \sim \mathcal{N} (m, \sigma^2)$. Moreover, if $(X_n)$ converges even
  in probability to $X$, then $(X_n)$ also converges in $L^p$ to $X$, for any
  $p \geqslant 1$.
\end{lemma}

\tmfoldedplain{\begin{proof}[Sketch of proof]
  By L{\'e}vy's continuity theorem (Stochastik~1 or Theorem~15.23
  in~{\cite{Klenke2008}}), convergence in distribution is equivalent to
  pointwise convergence of the characteristic function. It is easy to see that
  if $m_n \rightarrow m$ and $\sigma_n \rightarrow \sigma$, then the
  characteristic functions converge. Conversely, assume that $X_n$ converges
  in distriution to some $X$.
  
  Step 1: Taking the absolute value of the characteristic function, we see
  that $\sigma_n^2$ converges to some $\sigma^2 \in [0, \infty]$. The case
  $\sigma^2 = \infty$ can be ruled out because then the limit of the
  characteristic function would be $\1_{u = 0}$ which is
  discontinuous, while any characteristic function is continuous.
  
  Step 2: Now that we know that $(\sigma_n)$ converges, we obtain that $(m_n)$
  is bounded: Otherwise along a subsequence $(X_n)$ would converge in
  probability to $\pm \infty$, which is incompatible with weak convergence.
  
  Step 3: $(m_n)$ has at most one limit point in $\mathbb{R}$: If there were
  two limits $m$ and $m'$, then along different subsequences $(X_n)$ would
  converge weakly to different limits $\mathcal{N} (m, \sigma^2)$ resp.
  $\mathcal{N} (m', \sigma^2)$, which is impossible because we assumed weak
  convergence.
  
  It remains to show that if $X_n \overset{\mathbb{P}}{\longrightarrow} X$ and
  $p \geqslant 1$, then even $X_n \overset{L^p}{\longrightarrow} X$. From the
  previous considerations and because convergence in probability implies
  convergence in distribution we know that $m_n \rightarrow m$ and $\sigma_n^2
  \rightarrow \sigma_n$. In particular, for any $q \geqslant 1$ there exists
  $K_q > 0$ such that
  \[ \sup_n \mathbb{E} [| X_n |^q] \leqslant \sup_n K_q (\mathbb{E} [| X_n -
     m_n |^q] + m_n^q) = \sup_n K_q (C_q \sigma_n^q + m_n^q) < \infty . \]
  Taking $q = 2 p$, we deduce from the de la Vall{\'e}e-Poussin criterion
  (Stochastics II) that $(| X_n |^p)$ is uniformly integrable. By another
  result from Stochastics II, this yields $X_n \overset{L^p}{\longrightarrow}
  X$.
\end{proof}}{\begin{proof}
  By L{\'e}vy's continuity theorem (Stochastik~1 or Theorem~15.23
  in~{\cite{Klenke2008}}), convergence in distribution is equivalent to
  pointwise convergence of the characteristic function. It is easy to see that
  if $m_n \rightarrow m$ and $\sigma_n \rightarrow \sigma$, then the
  characteristic functions converge.
  
  Conversely, assume that $X_n$ converges in distriution to some $X$.
  
  Step 1: Taking the absolute value of the characteristic function, we see
  that $\sigma_n^2$ converges to some $\sigma^2 \in [0, \infty]$. The case
  $\sigma^2 = \infty$ can be ruled out because then the limit of the
  characteristic function would be $\1_{u = 0}$ which is
  discontinuous, while any characteristic function is continuous.
  
  Step 2: Now that we know that $(\sigma_n)$ converges we obtain that $(m_n)$
  is bounded, because otherwise along a subsequence $(X_n)$ would converge to
  $\pm \infty$, which is incompatible with weak convergence.
  
  Step 3: $(m_n)$ has at most one limit point in $\mathbb{R}$: If there were
  two limits $m$ and $m'$, then along different subsequences $(X_n)$ would
  converge weakly to different limits $\mathcal{N} (m, \sigma^2)$ resp.
  $\mathcal{N} (m', \sigma^2)$, which is impossible because we assumed weak
  convergence.
  \begin{itemize}
    \item ($\Leftarrow$): So if $m_n \rightarrow m$ and $\sigma_n \rightarrow
    \sigma$, then
    \[ \mathbb{E} [e^{i u X_n}] = e^{i u m_n - u^2 \sigma_n^2 / 2}
       \longrightarrow e^{i u m - u^2 \sigma^2 / 2}, \]
    which is the characteristic function of $X \sim \mathcal{N} (m,
    \sigma^2)$. Therefore, $X_n$ converges in distribution to $X$.
    
    \item ($\Rightarrow$): Conversely, assume that $X_n$ converges in
    distribution to $X$.
    
    Step 1, $(\sigma_n)$ converges: Taking the absolute value of the
    characteristic function of $X_n$, we get for all $u \in \mathbb{R}$
    \[ e^{- u^2 \sigma_n^2 / 2} = | e^{i u m_n - u^2 \sigma_n^2 / 2} | =
       |\mathbb{E}[e^{iu X_n}] | \longrightarrow |\mathbb{E}[e^{iuX}] |, \]
    which is only possible if $(\sigma_n)_{n \in \mathbb{N}}$ converges to
    some $\sigma \in [0, \infty]$. But the case $\sigma = \infty$ can be
    excluded because then the limiting function $\1_{u = 0}$ is
    discontinuous, while any characteristic function is continuous.
    
    Step 2, $(m_n)$ is bounded: We argue by contradiction and assume that the
    sequence is unbounded, and that $m_{n_k} \rightarrow \infty$ along a
    subsequence (the case $m_{n_k} \rightarrow - \infty$ along a subsequence
    works analogously). Since $(\sigma_n)_{n \in \mathbb{N}}$ is bounded, we
    deduce that $X_{n_k} \rightarrow \infty$ as $n \rightarrow \infty$ in
    probability, in the sense that $\lim_{n \rightarrow \infty} \mathbb{P}
    (X_{n_k} > K) = 1$ for all $K > 0$. This is a contradiction to $(X_{n_k})$
    converging in distribution to a finite random variable $X$.
    
    Step 3, $(m_n)$ converges: We get from Step 1 for all $u \in \mathbb{R}$
    \[ \lim_{n \rightarrow \infty} e^{ium_n} = \lim_{n \rightarrow \infty}
       e^{u^2 \sigma_n^2 / 2} \mathbb{E} [e^{iuX_n}] = e^{u \sigma^2 / 2}
       \mathbb{E} [e^{iuX}] . \]
    Since $(m_n)$ is bounded, it must converge: any two limit points $m$ and
    $m'$ satisfy $e^{ium} = e^{ium'}$ for all $u \in \mathbb{R}$, and
    therefore $m = m'$. \ Thus, we have shown that
    \[ \lim_{n \rightarrow \infty} \mathbb{E} [e^{iuX_n}] = e^{ium - u^2
       \sigma^2 / 2} =\mathbb{E} [e^{iuX}], \]
    and thus $X \sim \mathcal{N} (m, \sigma^2)$.
  \end{itemize}
\end{proof}}

Next, we study the $\mathbb{R}^d$-valued case, which in some sense can be
reduced to the real-valued case:

\begin{definition}
  Let $d \in \mathbb{N}$ and let $X$ be a random variable with values in
  $\mathbb{R}^d$. Then we say that $X$ is {\emph{(centered) Gaussian}} or
  {\emph{(centered) normal}} if for any $u \in \mathbb{R}^d$ the linear
  combination
  \[ u \cdot X = \sum_{j = 1}^d u_j X_j \]
  of the entries of $X$ is (centered) Gaussian. We also call $(X_1, \ldots,
  X_d)$ {\emph{jointly Gaussian}}.
  
  Equivalently, there exist $m \in \mathbb{R}^d$ and a symmetric positive
  semi-definite matrix $C \in \mathbb{R}^{d \times d}$ such that $X$ has the
  characteristic function
  \[ \mathbb{E} [e^{iu \cdot X}] = e^{iu \cdot m - (u^T Cu) / 2}, \qquad u
     \in \mathbb{R}^d . \]
  Moreover,
  \[ \mathbb{E} [u \cdot X] = u \cdot m, \qquad \operatorname{var} (u \cdot X) =
     u^T Cu. \]
  We say that $X$ has {\emph{mean}} (or {\emph{expectation}}) $m$ and
  {\emph{covariance}} $C$ and write $X \sim \mathcal{N} (m, C)$. $X$ is
  centered if and only if $m = 0$.
\end{definition}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  {\tmdummy}
  
  \begin{enumerate}
    \item Easy: If $X = (X_1, \ldots, X_d)$ is Gaussian, show that $X_j$ is a
    one-dimensional Gaussian for all $j = 1, \ldots, d$.
    
    \item Easy: ``Linear functions of Gaussians are Gaussian'': Let $X$ be an
    $\mathbb{R}^d$-valued Gaussian random variable and let $A \in
    \mathbb{R}^{n \times d}$. Show that $A X$ (matrix times vector) is an
    $\mathbb{R}^n$-valued Gaussian random variable. In particular, if $X \sim
    \mathcal{N} (m, C)$, then $A X \sim \mathcal{N} (A m, A C A^T)$.
    
    \item Hard: If $X_1$ and $X_2$ are one-dimensional Gaussian random
    variables, is it true that $(X_1, X_2)$ is a two-dimensional Gaussian? Or
    can you find a counterexample?
  \end{enumerate}
\end{exercise*}}}{\ }

If $m = 0 \in \mathbb{R}^d$ and $C =\mathbb{I} \in \mathbb{R}^{d \times d}$ is
the unit matrix, $X$ is an $\mathcal{N} (0, \mathbb{I})$ variable if and only
if $(X_1, \ldots, X_d)$ are independent standard Gaussians. Indeed, for
independent standard Gaussians we get
\[ \mathbb{E} [e^{i u \cdot X}] = \prod_{j = 1}^d \mathbb{E} [e^{i u_j X_j}]
   = \prod_{j = 1}^d e^{- \frac{1}{2} u_j^2} = e^{- \frac{1}{2} u^T
   \mathbb{I}u} = e^{- \frac{1}{2} | u |^2} . \]
In particular, for any $d \in \mathbb{N}$ there exists a $d$-dimensional
$\mathcal{N} (0, \mathbb{I})$ variable.

\begin{lemma}
  \label{lemA.5}Let $m \in \mathbb{R}^d$ and let $C \in \mathbb{R}^{d \times
  d}$ be symmetric and positive semi-definite.
  \begin{enumerate}
    \item There exists (a probability space with) a random variable $X \sim
    \mathcal{N} (m, C)$: Just let $Y \sim \mathcal{N} (0, \mathbb{I})$ and
    \[ X \coloneq m + \sqrt{C} Y, \]
    where $\sqrt{C}$ is the square root of $C$, that is the unique symmetric
    and positive semi-definite matrix such that $\sqrt{C} \sqrt{C} = C$ (such
    a {\sqrt{$C$}} always exists).
    
    \item ''Uncorrelated Gaussians are independent'': Let $X \sim \mathcal{N}
    (m, C)$. Then the coordinates $(X_1, \ldots, X_d)$ are independent if and
    only if $C$ is a diagonal matrix.
    
    \item Let $X \sim \mathcal{N} (m, C)$. Then $X$ has a density $p_X$ with
    respect to the $d$-dimensional Lebesgue measure if and only if $C$ is
    invertible. In that case
    \begin{equation}
      \label{eq:gaussian density multivariate} p_X (x) = \frac{1}{(2 \pi)^{d /
      2} (\det (C))^{1 / 2}} \exp \left( - \frac{1}{2} (x - m)^T C^{- 1} (x -
      m) \right) .
    \end{equation}
  \end{enumerate}
\end{lemma}

\tmcolor{blue}{\begin{exercise*}
  {\tmdummy}
  
  \begin{enumerate}
    \item Let $(X, Y)$ be {\underline{jointly}} Gaussian and such that
    $\operatorname{cov} (X, Y) = 0$. Show that $X$ and $Y$ are independent. In
    particular, if $X$ and $Y$ are centered and jointly Gaussian, this implies
    that orthogonality is equivalent to independence.
    
    \item Formulate point iii. for the special case $d = 1$.
  \end{enumerate}
\end{exercise*}}

\tmcolor{blue}{\begin{exercise*}
  Extend point~i. of the previous exercise to the following one: if $(X_t)_{t
  \in \mathbb{T}}$ and $(Y_s)_{s \in \mathbb{T}'}$ are jointly Gaussian
  centered processes, then $(X_t)_{t \in \mathbb{T}}$ and $(Y_s)_{s \in
  \mathbb{T}'}$ are independent if and only if $\mathbb{E} [X_t Y_s] = 0$ for
  all $t \in \mathbb{T}$ and $s \in \mathbb{T}'$.
\end{exercise*}

\tmtextit{Hint: reduce to finite-dimensional distributions by Dynkin's lemma,
cf. Lemma~\ref{lem:dynkin.independence}.}}

\begin{example}
  Let $Y, Z$ be independent with $Z \sim \mathcal{N} (0, 1)$ and $\mathbb{P}
  (Y = 1) =\mathbb{P} (Y = - 1) = \frac{1}{2}$. Let $X_1 = Z$ and $X_2 = Y Z$.
  Then $X_1 \sim \mathcal{N} (0, 1)$, and
  \[ \mathbb{E} [e^{i u X_2}] =\mathbb{E} [\mathbb{E} [e^{i u Z Y} |Y]]
     =\mathbb{E} [e^{- (u Y)^2 / 2}] = e^{- u^2 / 2}, \]
  where we used that $Y^2 = 1$. So also $X_2 \sim \mathcal{N} (0, 1)$.
  Moreover,
  \[ \operatorname{cov} (X_1, X_2) =\mathbb{E} [X_1 X_2] =\mathbb{E} [Y Z^2]
     =\mathbb{E} [Y] \mathbb{E} [Z^2] = 0 \cdot 1 = 0. \]
  But of course $(X_1, X_2)$ are not independent: Knowing $X_1$, we know $|
  X_2 |$ with certainty.
\end{example}

\tmfoldedplain{\tmcolor{blue}{\begin{exercise*}
  Why does this example not contradict point ii. of the previous lemma? And
  can you solve the hard part iii. of the long blue question right before
  Lemma~\ref{lemA.5} now?
\end{exercise*}}}{\ }

\subsection{Dynkin's lemma and monotone class theorems}\label{app:dynkin}

Let us briefly discuss two versions of the monotone class theorem, which will
be useful throughout the lecture. We will often be able to verify some
property for particularly simple random variables, and then ask ourselves
whether the property holds for a larger class of random variables. This can
often be shown with the help of monotone class theorems. We follow Appendix~4
of~{\cite{Ethier1986}}.

\

Let $\Omega$ be a set. We write $2^{\Omega}$ for the subsets of $\Omega$.
Recall the following definition:

\begin{definition}
  A family $\mathcal{D} \subset 2^{\Omega}$ is called a
  {\emph{$\lambda$-system}}, or also a {\emph{Dynkin system}}, if
  \begin{enumerate}
    \item $\Omega \in \mathcal{D}$;
    
    \item if $A, B \in \mathcal{D}$ with $A \subset B$, then $B \setminus A
    \in \mathcal{D}$;
    
    \item if $(A_n)_{n \in \mathbb{N}} \subset \mathcal{D}$ are increasing,
    i.e. $A_n \subset A_{n + 1}$ for all $n$, then $\bigcup_n A_n \in
    \mathcal{D}$.
  \end{enumerate}
  A family $\mathcal{E} \subset 2^{\Omega}$ is called a {\emph{$\pi$-system}}
  if it is closed under finite intersections:
  \[ A, B \in \mathcal{E} \qquad \Rightarrow \qquad A \cap B \in \mathcal{E}.
  \]
\end{definition}

\tmcolor{blue}{\tmfoldedplain{\begin{exercise*}[elementary, but less trivial
then it looks!]
  Verify that $\mathcal{D}$ is equivalently a $\lambda$-system if the
  following hold:
  \begin{enumeratenumeric}
    \item $\Omega \in \mathcal{D}$;
    
    \item if $A \in \mathcal{D}$, then $A^c \in \mathcal{D}$;
    
    \item if $(A_n)_{n \in \mathbb{N}} \subset \mathcal{D}$ are pairwise
    disjoint, then $\bigcup_n A_n \in \mathcal{D}$.
  \end{enumeratenumeric}
\end{exercise*}}{\ }}

\begin{theorem}[Dynkin's $\pi$-$\lambda$ theorem, also called Dynkin's lemma]
  \label{thm:dynkin}Let $\mathcal{D} \subset 2^{\Omega}$ be a $\lambda$-system
  and let $\mathcal{E} \subset \mathcal{D}$ be a $\pi$-system. Then $\sigma
  (\mathcal{E}) \subset \mathcal{D}$.
\end{theorem}

\begin{proof}
  Probability~I, or Theorem~4.2 from~{\cite{Ethier1986}}.
\end{proof}

\begin{definition}
  Let $\mathcal{A}$ be a $\sigma$-algebra on $\Omega$. We say that
  $\mathcal{E}$ is a basis for $\mathcal{A}$ if $\mathcal{E}$ is a
  $\pi$\mbox{-}system and $\sigma (\mathcal{E}) = \mathcal{A}$.
\end{definition}

\tmtextit{[Comment: the terminology ``basis'' in this context is not fully
standard and not adopted by many authors, but convenient for this appendix]}

\tmcolor{blue}{\tmfoldedplain{\begin{exercise*}
  Use Dynkin's lemma to prove the following fact: if $\mu$, $\nu$ are two
  probability measures on $(\Omega, \mathcal{A})$ and $\mathcal{E}$ is a basis
  for $\mathcal{A}$, then $\mu = \nu$ on $(\Omega, \mathcal{A})$ if and only
  if $\mu (A) = \nu (A)$ for all $A \in \mathcal{A}$.
\end{exercise*}}{\ }}

Let us quickly recall some relevant cases of bases:
\begin{itemize}
  \item On $\mathbb{R}$, the collection of closed intervals $\mathcal{R}
  \coloneq \{ [a, b] : a < b \}$ form a basis for $\mathcal{B} (\mathbb{R})$;
  same for open intervals $\{ (a, b) : a < b \}$, or unbouded intervals $\{ (-
  \infty, a] : a \in \mathbb{R} \}$, etc.
  
  \item On $\mathbb{R}^d$, the collection of closed rectangles $\mathcal{R}^d
  \coloneq \{ A = \Pi_{i = 1}^d A_i |A_i \in \mathcal{R} \}$ are a basis for
  $\mathcal{B} (\mathbb{R}^d)$.
  
  \item Given a topological space $(E, \tau)$, the collection $\tau$ of open
  sets form a basis for $\mathcal{B} (E)$; same for the collection of closed
  sets.
  
  \item If $(E_1, \mathcal{A}_1)$ and $(E_2, \mathcal{A}_2)$ are measurable
  spaces, $\mathcal{E}_i$ are bases for $\mathcal{A}_i$ and we endow $E_1
  \times E_2$ with $\mathcal{A} = \sigma (\mathcal{A}_1 \times \mathcal{A}_2)$
  the product $\sigma$-algebra, then the ``rectangles''
  \[ \mathcal{R}^{E_1 \times E_2} \coloneq \{ A = A_1 \times A_2 |A_1 \in
     \mathcal{E}_1, A_2 \in \mathcal{E}_2 \} \]
  form a basis for $\mathcal{A}$.
  
  \item Given $n \in \mathbb{N}$, $t_1, \ldots, t_n \in \mathbb{R}_+$ and
  $B_1, \ldots, B_n \in \mathcal{B} (\mathbb{R})$, consider the set
  \[ E = \left\{ \omega \in \mathbb{R}^{\mathbb{R}_+} : \, \omega (t_i) \in
     B_i  \text{ for } i = 1, \ldots, n \right\} ; \]
  let $\mathcal{E}$ denote the collection of all such sets, upon varying $n$,
  $t_i$ and $B_i$. Then $\mathcal{E}$ is a basis for $\mathcal{B}
  (\mathbb{R})^{\otimes \mathbb{R}_+}$.
\end{itemize}
\tmcolor{blue}{\tmfoldedplain{\begin{exercise*}
  Let $X_1$, $X_2$ be random variables taking values in two measurable spaces
  $(E_1, \mathcal{A}_1)$ and $(E_2, \mathcal{A}_2)$ and let $\mathcal{E}_i$ be
  bases for $\mathcal{A}_i$. Using Dynkin's lemma and the last point from the
  above bullet list, show that $X_1$ and $X_2$ are independent if and only if
  \[ \mathbb{P} (X_1 \in A_1, X_2 \in A_2) =\mathbb{P} (X_1 \in A_1)
     \mathbb{P} (X_2 \in A_2) \]
  for all $A_1 \in \mathcal{E}_1$ and $A_2 \in \mathcal{E}_2$.
\end{exercise*}}{\ }}

\begin{lemma}
  \label{lem:dynkin.independence}Let $(X_t)_{t \in \mathbb{T}}$ and $(Y_s)_{s
  \in \mathbb{T}'}$ are (real-valued) stochastic processes, over (possibly
  different) index sets $\mathbb{T}$ and $\mathbb{T}'$. Then $(X_t)_{t \in
  \mathbb{T}}$ and $(Y_s)_{s \in \mathbb{T}'}$ are independent if and only if
  $(X_{t_i})_{i = 1}^n$ and $(Y_{s_j})_{j = 1}^m$ are independent, for all $n,
  m \in \mathbb{N}$ and all $(t_i)_{i = 1}^n \subset \mathbb{T}^n$, $(s_j)_{j
  = 1}^m \subset (\mathbb{T}')^m$.
\end{lemma}

\tmcolor{blue}{\begin{exercise*}
  Prove the above lemma. 
\end{exercise*}}

Theorem~\ref{thm:dynkin} only concerns sets, but naturally leads to results
concerning {\emph{monotone}} classes of functions. Such results are extremely
useful whenever one wants to establish certains properties being true for a
large class of functions $f$, upon only verifying them for simpler cases
(typically $f = \1_A$ for some ``nicely chosen'' $A$). We present two
versions of such results.

\begin{theorem}[Monotone class theorem I]
  \label{thm:monotone.class1}Let $H$ be a vector space of bounded real-valued
  functions on $\Omega$ and $\mathcal{E}$ be a $\pi$-system. Assume that
  \begin{enumerate}
    \item $H$ contains all constant functions;
    
    \item $\1_A \in H$ for all $A \in \mathcal{E}$;
    
    \item if $(h_n)_{n \in \mathbb{N}}$ is an increasing sequence of positive
    functions in $H$ such that $h \coloneq \lim_n h_n \ge 0$ is bounded, then
    $h \in H$.
  \end{enumerate}
  Then $H$ contains all bounded $\sigma (\mathcal{E})$-measurable functions.
\end{theorem}

\begin{proof}
  See Theorem~4.3 from~{\cite{Ethier1986}}.
\end{proof}

\tmcolor{blue}{\tmfoldedplain{\begin{exercise*}
  Let $X, Y$ be independent random variables taking values in $\mathbb{R}^d,
  \mathbb{R}^m$ respectively; let $f : \mathbb{R}^d \times \mathbb{R}^m
  \rightarrow \mathbb{R}$ be a measurable bounded function. Use
  Theorem~\ref{thm:monotone.class1} to prove that
  \[ \mathbb{E} [f (X, Y) |Y] (\omega) = g (Y (\omega)) \quad \operatorname{for} \quad
     g (y) \coloneq \mathbb{E} [f (X, y)] \]
  where $\mathbb{E} \left[ \, \cdot \, |Y \right]$ denotes conditional
  expectation w.r.t. $\sigma (Y)$.
\end{exercise*}}{\ }}

In the next statement, given a family of functions $C$ from $\Omega$ to
$\mathbb{R}$, we denote by $\sigma (C)$ the $\sigma$-algebra generated by $C$,
i.e. the smallest $\sigma$-algebra on $\Omega$ such that $f : (\Omega, \sigma
(C)) \rightarrow \mathbb{R}$ is measurable for all $f \in C$. Equivalently
this is the $\sigma$-algebra generated by the sets $f^{- 1} ([a, b])$, for
$[a, b] \subset \mathbb{R}$ and $f \in C$.

\tmfoldedplain{\begin{theorem}[Monotone class theorem II]
  \label{thm:monotone.class2}Let $H$ be a vector space of bounded real-valued
  functions on $\Omega$ such that
  \begin{enumerate}
    \item $H$ contains all constant functions;
    
    \item if $(h_n)_{n \in \mathbb{N}} \subset H$ converges uniformly to $h$,
    then $h \in H$;
    
    \item if $(h_n)_{n \in \mathbb{N}}$ is an increasing sequence of positive
    functions in $H$ such that $h \coloneq \lim_n h_n \ge 0$ is bounded, then
    $h \in H$.
  \end{enumerate}
  If $C \subset H$ is closed under pointwise multiplication (that is, $f g \in
  C$ whenever $f, g \in C$), then $H$ contains all bounded $\sigma
  (C)$-measurable functions.
\end{theorem}}{\begin{proof}
  
  \begin{itemize}
    \item First we show that $\Phi (f) \in H$ for any continuous $\Phi :
    \mathbb{R} \rightarrow \mathbb{R}$ and any $f \in C$. Indeed, since $f$ is
    bounded its image is contained in a compact $K \subset \mathbb{R}$. By the
    Weierstrass approximation theorem we can approximate $\Phi |_K$ uniformly
    by polynomials $(\Phi_n)$. Since polynomials of $f$ are in $H$ by
    assumption (here we need that $C$ is closed under multiplication, that $H$
    contains constants, and that $H$ is a vector space), we get $\Phi_n (f)
    \in H$. Since $H$ is closed under uniform convergence, we then obtain
    $\Phi (f) \in H$.
    
    \item Next, we show that for all $f \in C$ and all $a \in \mathbb{R}$ the
    function $\1_{\{ f > a \}}$ is in $H$. Indeed, it suffices to note that
    $\1_{(a, \infty)}$ is the limit of an increasing sequence of positive
    continuous functions and to apply our third assumption on $H$.
    
    \item Analogously we see that $\1_{\{ f_1 > a_1, \ldots, f_n > a_n \}} \in
    H$ for all $f_1, \ldots, f_n \in C$ and $a_1, \ldots, a_n \in \mathbb{R}$.
    Since the set system
    \[ \mathcal{E}= \{ \{ f_1 > a_1, \ldots, f_n > a_n \} : f_1, \ldots, f_n
       \in C, a_1, \ldots, a_n \in \mathbb{R} \} \]
    is closed under intersections, the Monotone class theorem I shows that $H$
    contains all $\sigma (\mathcal{E})$--measurable functions. But $\sigma
    (\mathcal{E}) = \sigma (C)$, so the proof is complete.
  \end{itemize}
\end{proof}}

\begin{proof}
  See Corollary~4.4 from~{\cite{Ethier1986}}.
\end{proof}

\tmcolor{blue}{\tmfoldedplain{\begin{exercise*}[hard]
  Given a probability measure $\mu$ on $\mathbb{R}_+$, we define its Laplace
  transform by
  \[ L_{\mu} (a) : = \int_{\mathbb{R}_+} e^{- a x} \mu (\mathrm{d} a) \quad
     \forall \, a \geqslant 0. \]
  Apply Theorem~\ref{thm:monotone.class2} to prove that $L_{\mu}$
  characterizes uniquely $\mu$, in the following sense: if $\mu$ and $\nu$ are
  two probability measures on $\mathbb{R}_+$ such that $L_{\mu} = L_{\nu}$,
  then $\mu = \nu$.
\end{exercise*}}{\ }}

\begin{thebibliography}{10}
  \bibitem[1]{Beiglbock2015}Mathias Beiglb{\"o}ck  and  Pietro Siorpaes.
  {\newblock}Pathwise versions of the Burkholder-Davis-Gundy inequality.
  {\newblock}Bernoulli}, 21(1):360--373, 2015.{\newblock
  
  \bibitem[2]{DaPrato2014}Giuseppe Da Prato  and  Jerzy Zabczyk.
  {\newblock}Stochastic equations in infinite dimensions,  volume 
  152  of Encyclopedia of Mathematics and its Applications.
  {\newblock}Cambridge University Press, Cambridge, Second  edition,
  2014.{\newblock}
  
  \bibitem[3]{Dellacherie1978}Claude Dellacherie  and  Paul-Andr{\'e} Meyer.
  {\newblock}Probabilities and potential,  volume~29  of
  North-Holland Mathematics Studies}. {\newblockNorth-Holland
  Publishing Co., Amsterdam, 1978.{\newblock}
  
  \bibitem[4]{DiNunno2001}G.~Di Nunno  and  Yu.~A.~Rozanov. {\newblock}On
  measurable modification of stochastic functions. {\newblock}\tmtextit{Teor.
  Veroyatnost. i Primenen.}, 46(1):175--180, 2001.{\newblock}
  
  \bibitem[5]{Durrett2010}Rick Durrett. {\newblock}\tmtextit{Probability:
  theory and examples}. {\newblock}Cambridge Series in Statistical and
  Probabilistic Mathematics. Cambridge University Press, Cambridge, Fourth 
  edition, 2010.{\newblock}
  
  \bibitem[6]{Ethier1986}Stewart~N.~Ethier  and  Thomas~G.~Kurtz.
  {\newblock}Markov processes: Characterization and convergence.
  {\newblock}John Wiley \& Sons, 1986.{\newblock}
  
  \bibitem[7]{Friz2014}Peter~K.~Friz  and  Martin Hairer.
  {\newblock}A course on rough paths}. {\newblockUniversitext.
  Springer, Cham, 2014. {\newblock}With an introduction to regularity
  structures.{\newblock}
  
  \bibitem[8]{Friz2010}Peter~K.~Friz  and  Nicolas~B.~Victoir.
  {\newblock}Multidimensional stochastic processes as rough paths, 
  volume  120  of Cambridge Studies in Advanced Mathematics.
  {\newblock}Cambridge University Press, Cambridge, 2010. {\newblock}Theory
  and applications.{\newblock}
  
  \bibitem[9]{TeXmacs:website}J.~van~der Hoeven et~al. {\newblock}GNU TeXmacs.
  {\newblock}\url{https://www.texmacs.org}, 1998.{\newblock}
  
  \bibitem[10]{Jacod2008}Jean Jacod. {\newblock}Mouvement brownien et calcul
  stochastique. {\newblock}Unpublished lecture notes,
  \url{https://www.lpsm.paris//cours/DEA-07.pdf}, 2008.{\newblock}
  
  \bibitem[11]{Jacod2003}Jean Jacod  and  Albert~N.~Shiryaev.
  {\newblock}Limit theorems for stochastic processes.
  {\newblock}Springer, 2nd  edition, 2003.{\newblock}
  
  \bibitem[12]{Karatzas1988}Ioannis Karatzas  and  Steven~E.~Shreve.
  {\newblock}Brownian motion and stochastic calculus.
  {\newblock}Springer, 1988.{\newblock}
  
  \bibitem[13]{Klenke2008}Achim Klenke. {\newblock}\tmtextit{Probability
  Theory - A Comprehensive Course}. {\newblock}Springer, 2008.{\newblock}
  
  \bibitem[14]{LeGall2016}Jean-Fran{\c c}ois Le Gall.
  {\newblock}Brownian motion, martingales, and stochastic calculus,
  volume  274  of Graduate Texts in Mathematics.
  {\newblock}Springer, 2016.{\newblock}
  
  \bibitem[15]{Liggett2010}Thomas~M.~Liggett. {\newblock}\tmtextit{Continuous
  time Markov processes},  volume  113  of \tmtextit{Graduate Studies in
  Mathematics}. {\newblock}American Mathematical Society, Providence, RI,
  2010. {\newblock}An introduction.{\newblock}
  
  \bibitem[16]{Morters2010}Peter M{\"o}rters  and  Yuval Peres.
  {\newblock}Brownian motion,  volume~30  of \tmtextit{Cambridge
  Series in Statistical and Probabilistic Mathematics}. {\newblock}Cambridge
  University Press, Cambridge, 2010. {\newblock}With an appendix by Oded
  Schramm and Wendelin Werner.{\newblock}
  
  \bibitem[17]{Norris1998}J.~R.~Norris. {\newblock}Markov chains, 
  volume~2  of \tmtextit{Cambridge Series in Statistical and Probabilistic
  Mathematics}. {\newblock}Cambridge University Press, Cambridge, 1998.
  {\newblock}Reprint of 1997 original.{\newblock}
  
  \bibitem[18]{Oksendal2003}Bernt {\O}ksendal. {\newblock}\tmtextit{Stochastic
  differential equations}. {\newblock}Universitext. Springer-Verlag, Berlin,
  Sixth  edition, 2003. {\newblock}An introduction with
  applications.{\newblock}
  
  \bibitem[19]{OndSei2013}Martin Ondrej{\'a}t  and  Jan Seidler. {\newblock}On
  existence of progressively measurable modifications.
  {\newblock}Electron. Commun. Probab.}, 18:0, 2013.{\newblock
  
  \bibitem[20]{Protter2004}Philip~E.~Protter. {\newblock}\tmtextit{Stochastic
  integration and differential equations}. {\newblock}Springer, 2nd  edition,
  2004.{\newblock}
  
  \bibitem[21]{Revuz1999}Daniel Revuz  and  Marc Yor.
  {\newblock}Continuous martingales and Brownian motion.
  {\newblock}Springer, 3rd  edition, 1999.{\newblock}
  
  \bibitem[22]{Rogers2000Vol2}L.~C.~G.~Rogers  and  David Williams.
  {\newblock}Diffusions, Markov processes, and martingales. Vol. 2.
  {\newblock}Cambridge Mathematical Library. Cambridge University Press,
  Cambridge, 2000. {\newblock}It{\^o} calculus, Reprint of the second (1994)
  edition.{\newblock}
  
  \bibitem[23]{Siorpaes2018}Pietro Siorpaes. {\newblock}Applications of
  pathwise Burkholder-Davis-Gundy inequalities.
  {\newblock}Bernoulli}, 24(4B):3222--3245, 2018.{\newblock
  
  \bibitem[24]{Stroock2011}Daniel~W.~Stroock. {\newblock}\tmtextit{Probability
  theory}. {\newblock}Cambridge University Press, Cambridge, Second  edition,
  2011. {\newblock}An analytic view.{\newblock}
  
  \bibitem[25]{Weizsacker1990}Heinrich von~Weizs{\"a}cker  and  Gerhard
  Winkler. {\newblock}Stochastic integrals}. {\newblockAdvanced
  Lectures in Mathematics. Friedr. Vieweg \& Sohn, Braunschweig, 1990.
  {\newblock}An introduction.{\newblock}
\end{thebibliography}

\

\end{document}
